{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parallelize.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPF1lG5J3MMNNzI2DWj6nDS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fluff18/ML/blob/master/Parallelize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts3Ri9-SvBC9",
        "colab_type": "code",
        "outputId": "c9fd7630-aac8-4a4f-c551-906db45e9ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from time import sleep\n",
        "from threading import *\n",
        "import time\n",
        "class Hello(Thread):\n",
        "\tdef run(self):\n",
        "\t\ta=[]\n",
        "\t\tfor i in range(5):\n",
        "\t\t\ta.append(i*5+42)\n",
        "\t\t\ta[i]=a[i]+4\n",
        "\t\t\tsleep(1)\n",
        "\n",
        "\n",
        "class Hi(Thread):\n",
        "\tdef run(self):\n",
        "\t\tb=[]\n",
        "\t\tfor i in range(5):\n",
        "\t\t\tb.append(i*5+42)\n",
        "\t\t\tb[i]=b[i]+2*3\n",
        "\t\t\tsleep(1)\n",
        "\n",
        "starttime=time.time()\n",
        "t1 = Hello()\n",
        "t2 = Hi()\n",
        "\n",
        "t1.start()\n",
        "sleep(0.2)\n",
        "t2.start()\n",
        "\n",
        "t1.join()\n",
        "t2.join()\n",
        "t22=float(time.time()-starttime)\n",
        "print(\"----\",t22)\n",
        "\n",
        "arr=[]\n",
        "arr2=[]\n",
        "newstart=time.time()\n",
        "for i in range(5):\n",
        "\tarr.append(i*4+34)\n",
        "\tarr[i]=arr[i]+54\n",
        "\n",
        "\tarr2.append(i*4+34)\n",
        "\tarr2[i]=arr[i]+54\n",
        "t23=float(time.time()-newstart)\n",
        "print(\"----\",t23)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---- 5.2072553634643555\n",
            "---- 0.000102996826171875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaHAq2dP-JiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from joblib import Parallel, delayed\n",
        "import multiprocessing\n",
        "import time\n",
        "from joblib import Parallel, delayed\n",
        "pool=multiprocessing.Pool()\n",
        "\n",
        "def f1(i,weights, gradients, first_moment, second_moment, time_step, learning_rate, beta1, beta2,number_of_datapoints,string,smoothing_term):\n",
        "        first_moment[\"dW_\"+string + str(i)] = beta1 * first_moment[\"dW_\"+string + str(i)] + (1 - beta1) * gradients['dW_'+string + str(i)]\n",
        "        first_moment_bias_correction[\"dW_\"+string + str(i)] = first_moment[\"dW_\" +string+ str(i)] / (1 - np.power(beta1*beta1, time_step))\n",
        "\n",
        "     \n",
        "        second_moment[\"dW_\"+string + str(i)] = beta2 * second_moment[\"dW_\" +string+ str(i)] + (1 - beta2) * np.power(gradients['dW_'+string + str(i)], 2)\n",
        "        second_moment_bias_correction[\"dW_\" +string+ str(i)] = second_moment[\"dW_\" +string+ str(i)] / (1 - np.power(beta2*beta2, time_step))\n",
        "     \n",
        "    \n",
        "        numerator = first_moment_bias_correction[\"dW_\"+string + str(i)]\n",
        "        denominator  = np.sqrt(second_moment_bias_correction[\"dW_\"+string + str(i)]) + smoothing_term\n",
        "    \n",
        "        weights[\"W_\"+string + str(i)] = weights[\"W_\"+string + str(i)] - (((learning_rate * numerator) / (denominator))/number_of_datapoints)\n",
        "        return weights, first_moment, second_moment\n",
        "\n",
        "\n",
        "def adam(weights, gradients, first_moment, second_moment, time_step, learning_rate, beta1, beta2,number_of_datapoints,\n",
        "         string,smoothing_term=1e-8):\n",
        "\n",
        "    \n",
        "    first_moment_bias_correction = {}  \n",
        "    second_moment_bias_correction = {}           \n",
        "    \n",
        "    res=Parallel(n_jobs=num_cores)(delayed(f1)(i,weights, gradients, first_moment, second_moment, time_step, learning_rate, beta1, beta2,number_of_datapoints,string,smoothing_term) for i in range(1,len(weights)+1))\n",
        "    weights=res[0]\n",
        "    first_moment=res[1]\n",
        "    second_moment=res[2]   \n",
        "    return weights, first_moment, second_moment\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukXYyPim93wE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def adam(weights, gradients, first_moment, second_moment, time_step, learning_rate, beta1, beta2,number_of_datapoints,\n",
        "         string,smoothing_term=1e-8):\n",
        "\n",
        "    \n",
        "    first_moment_bias_correction = {}  \n",
        "    second_moment_bias_correction = {}      \n",
        "    Parallel(n_jobs=num_cores)(delayed(func1)(i,a,b) for i in range(100))     \n",
        "    \n",
        "    for i in range(1,len(weights)+1):\n",
        "        first_moment[\"dW_\"+string + str(i)] = beta1 * first_moment[\"dW_\"+string + str(i)] + (1 - beta1) * gradients['dW_'+string + str(i)]\n",
        "        first_moment_bias_correction[\"dW_\"+string + str(i)] = first_moment[\"dW_\" +string+ str(i)] / (1 - np.power(beta1*beta1, time_step))\n",
        "\n",
        "     \n",
        "        second_moment[\"dW_\"+string + str(i)] = beta2 * second_moment[\"dW_\" +string+ str(i)] + (1 - beta2) * np.power(gradients['dW_'+string + str(i)], 2)\n",
        "        second_moment_bias_correction[\"dW_\" +string+ str(i)] = second_moment[\"dW_\" +string+ str(i)] / (1 - np.power(beta2*beta2, time_step))\n",
        "     \n",
        "    \n",
        "        numerator = first_moment_bias_correction[\"dW_\"+string + str(i)]\n",
        "        denominator  = np.sqrt(second_moment_bias_correction[\"dW_\"+string + str(i)]) + smoothing_term\n",
        "    \n",
        "        weights[\"W_\"+string + str(i)] = weights[\"W_\"+string + str(i)] - (((learning_rate * numerator) / (denominator))/number_of_datapoints)\n",
        "   \n",
        "    return weights, first_moment, second_moment\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib_UpJp1pxMz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "745ae61f-06f6-4f5b-d4dd-a94d629a748e"
      },
      "source": [
        "'''import multiprocessing\n",
        "from joblib import Parallel, delayed\n",
        "pool=multiprocessing.Pool()\n",
        "\n",
        "\n",
        "def first_m(i, weights, gradients, first_moment, second_moment, time_step, learning_rate, beta1, beta2,number_of_datapoints, string,smoothing_term=1e-8):\n",
        "        first_moment[\"dW_\"+string + str(i)] = beta1 * first_moment[\"dW_\"+string + str(i)] + (1 - beta1) * gradients['dW_'+string + str(i)]\n",
        "        first_moment_bias_correction[\"dW_\"+string + str(i)] = first_moment[\"dW_\" +string+ str(i)] / (1 - np.power(beta1*beta1, time_step))\n",
        "        numerator = first_moment_bias_correction[\"dW_\"+string + str(i)]\n",
        "        return first_moment_bias_correction,first_moment,numerator\n",
        "\n",
        "def second_m(i, weights, gradients, first_moment, second_moment, time_step, learning_rate, beta1, beta2,number_of_datapoints, string,smoothing_term=1e-8):\n",
        "        second_moment[\"dW_\"+string + str(i)] = beta2 * second_moment[\"dW_\" +string+ str(i)] + (1 - beta2) * np.power(gradients['dW_'+string + str(i)], 2)\n",
        "        second_moment_bias_correction[\"dW_\" +string+ str(i)] = second_moment[\"dW_\" +string+ str(i)] / (1 - np.power(beta2*beta2, time_step))\n",
        "        denominator  = np.sqrt(second_moment_bias_correction[\"dW_\"+string + str(i)]) + smoothing_term\n",
        "        weights[\"W_\"+string + str(i)] = weights[\"W_\"+string + str(i)] - (((learning_rate * numerator) / (denominator))/number_of_datapoints)\n",
        "        return second_moment, second_moment_bias_correction,denominator,weights\n",
        "\n",
        "def adam(weights, gradients, first_moment, second_moment, time_step, learning_rate, beta1, beta2,number_of_datapoints,string,smoothing_term=1e-8):\n",
        "        first_moment_bias_correction = {}  \n",
        "        second_moment_bias_correction = {}           \n",
        "        num_cores = multiprocessing.cpu_count()\n",
        "        fm=[]\n",
        "        fm = Parallel(n_jobs=num_cores)(delayed(first_m)((i, weights, gradients, first_moment, second_moment, time_step, learning_rate, beta1, beta2,number_of_datapoints,string,smoothing_term) for i in range(1,len(weights)+1))\n",
        "    #first_moment_bias_correction=fm[0]\n",
        "    #first_moment=fm[1]\n",
        "    #numerator=fm[2]\n",
        "        sm = Parallel(n_jobs=num_cores)(delayed(second_m)((i,weights, gradients, first_moment, second_moment, time_step, learning_rate, beta1, beta2,number_of_datapoints,string,smoothing_term) for i in range(1,len(weights)+1))\n",
        "    #second_moment=sm[0]\n",
        "    #second_moment_bias_correction=sm[1]\n",
        "    #denominator=sm[2]\n",
        "      weights=sm[3]\n",
        "   \n",
        "        return weights, first_moment, second_moment\n",
        "'''"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import multiprocessing\\nfrom joblib import Parallel, delayed\\npool=multiprocessing.Pool()\\n\\n\\ndef first_m(i, weights, gradients, first_moment, second_moment, time_step, learning_rate, beta1, beta2,number_of_datapoints, string,smoothing_term=1e-8):\\n        first_moment[\"dW_\"+string + str(i)] = beta1 * first_moment[\"dW_\"+string + str(i)] + (1 - beta1) * gradients[\\'dW_\\'+string + str(i)]\\n        first_moment_bias_correction[\"dW_\"+string + str(i)] = first_moment[\"dW_\" +string+ str(i)] / (1 - np.power(beta1*beta1, time_step))\\n        numerator = first_moment_bias_correction[\"dW_\"+string + str(i)]\\n        return first_moment_bias_correction,first_moment,numerator\\n\\ndef second_m(i, weights, gradients, first_moment, second_moment, time_step, learning_rate, beta1, beta2,number_of_datapoints, string,smoothing_term=1e-8):\\n        second_moment[\"dW_\"+string + str(i)] = beta2 * second_moment[\"dW_\" +string+ str(i)] + (1 - beta2) * np.power(gradients[\\'dW_\\'+string + str(i)], 2)\\n        second_moment_bias_correction[\"dW_\" +string+ str(i)] = second_moment[\"dW_\" +string+ str(i)] / (1 - np.power(beta2*beta2, time_step))\\n        denominator  = np.sqrt(second_moment_bias_correction[\"dW_\"+string + str(i)]) + smoothing_term\\n        weights[\"W_\"+string + str(i)] = weights[\"W_\"+string + str(i)] - (((learning_rate * numerator) / (denominator))/number_of_datapoints)\\n        return second_moment, second_moment_bias_correction,denominator,weights\\n\\ndef adam(weights, gradients, first_moment, second_moment, time_step, learning_rate, beta1, beta2,number_of_datapoints,string,smoothing_term=1e-8):\\n        first_moment_bias_correction = {}  \\n        second_moment_bias_correction = {}           \\n        num_cores = multiprocessing.cpu_count()\\n        fm=[]\\n        fm = Parallel(n_jobs=num_cores)(delayed(first_m)((i, weights, gradients, first_moment, second_moment, time_step, learning_rate, beta1, beta2,number_of_datapoints,string,smoothing_term) for i in range(1,len(weights)+1))\\n    #first_moment_bias_correction=fm[0]\\n    #first_moment=fm[1]\\n    #numerator=fm[2]\\n        sm = Parallel(n_jobs=num_cores)(delayed(second_m)((i,weights, gradients, first_moment, second_moment, time_step, learning_rate, beta1, beta2,number_of_datapoints,string,smoothing_term) for i in range(1,len(weights)+1))\\n    #second_moment=sm[0]\\n    #second_moment_bias_correction=sm[1]\\n    #denominator=sm[2]\\n      weights=sm[3]\\n   \\n        return weights, first_moment, second_moment\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlJIBP753qps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''import multiprocessing\n",
        "pool=multiprocessing.Pool()\n",
        "\n",
        "\n",
        "def first_m(i,weights, gradients, first_moment, second_moment, time_step, learning_rate, beta1, beta2,number_of_datapoints, string,smoothing_term=1e-8):\n",
        "        first_moment[\"dW_\"+string + str(i)] = beta1 * first_moment[\"dW_\"+string + str(i)] + (1 - beta1) * gradients['dW_'+string + str(i)]\n",
        "        first_moment_bias_correction[\"dW_\"+string + str(i)] = first_moment[\"dW_\" +string+ str(i)] / (1 - np.power(beta1*beta1, time_step))\n",
        "        numerator = first_moment_bias_correction[\"dW_\"+string + str(i)]\n",
        "        second_moment[\"dW_\"+string + str(i)] = beta2 * second_moment[\"dW_\" +string+ str(i)] + (1 - beta2) * np.power(gradients['dW_'+string + str(i)], 2)\n",
        "        second_moment_bias_correction[\"dW_\" +string+ str(i)] = second_moment[\"dW_\" +string+ str(i)] / (1 - np.power(beta2*beta2, time_step))\n",
        "        denominator  = np.sqrt(second_moment_bias_correction[\"dW_\"+string + str(i)]) + smoothing_term\n",
        "        weights[\"W_\"+string + str(i)] = weights[\"W_\"+string + str(i)] - (((learning_rate * numerator) / (denominator))/number_of_datapoints)\n",
        "        return first_moment_bias_correction, first_moment, numerator, second_moment, second_moment_bias_correction, denominator, weights\n",
        "\n",
        "def adam(weights, gradients, first_moment, second_moment, time_step, learning_rate, beta1, beta2,number_of_datapoints,\n",
        "         string,smoothing_term=1e-8):\n",
        "\n",
        "    \n",
        "    first_moment_bias_correction = {}  \n",
        "    second_moment_bias_correction = {}           \n",
        "    num_cores = multiprocessing.cpu_count()\n",
        "    fm = Parallel(n_jobs=num_cores)(delayed(first_m)((i,weights, gradients, first_moment, second_moment, time_step, learning_rate, beta1, beta2,number_of_datapoints,string,smoothing_term) for i in range(1,len(weights)+1))\n",
        "    #first_moment_bias_correction=fm[0]\n",
        "    #first_moment=fm[1]\n",
        "    #numerator=fm[2]\n",
        "    #sm = Parallel(n_jobs=num_cores)(delayed(first_m)((i,weights, gradients, first_moment, second_moment, time_step, learning_rate, beta1, beta2,number_of_datapoints,string,smoothing_term) for i in range(1,len(weights)+1))\n",
        "    #second_moment=sm[0]\n",
        "    #second_moment_bias_correction=sm[1]\n",
        "    #denominator=fm[2]\n",
        "    weights=fm[7]\n",
        "    return weights, first_moment, second_moment\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSLQdSShrDXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rahul2(a,b,s):\n",
        "    c=[1,2,3]\n",
        "    a=\"rahul\"\n",
        "    v=2\n",
        "    return a,c,v\n",
        "x=rahul2(1,2,3)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBEwdwGUfbm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from joblib import Parallel, delayed\n",
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "starttime=time.time()\n",
        "def rahul(a, b, c, d):\n",
        "    num_cores = multiprocessing.cpu_count()\n",
        "    results=[] \n",
        "    results = Parallel(n_jobs=num_cores)(delayed(func1)(i,a,b) for i in range(100))\n",
        "    results2=[] \n",
        "    results2 = Parallel(n_jobs=num_cores)(delayed(func2)(i,c,d) for i in range(100))\n",
        "    res=[]\n",
        "    for i in range(100):\n",
        "      res.append(results[i]+results2[i])\n",
        "    return res\n",
        "\n",
        "def func1(i, a, b):\n",
        "    return a*b+i*a\n",
        "def func2(i, c, d):\n",
        "    return c*d+i*c\n",
        "\n",
        "print(rahul(1,2,1,2))\n",
        "print(time.time()-starttime)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CheWPNHmgQf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start=time.time()\n",
        "def r(a,b,c,d):\n",
        "  res1=[]\n",
        "  res2=[]\n",
        "  for i in range(100):\n",
        "    res1.append(func1(a,b))\n",
        "    res2.append(func2(c,d))\n",
        "  res3=[]\n",
        "  for i in range(100):\n",
        "    res3.append(res1[i]+res2[i])\n",
        "  return res3\n",
        "  \n",
        "print(time.time()-start)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}