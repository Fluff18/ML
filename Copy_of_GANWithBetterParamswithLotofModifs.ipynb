{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of GANWithBetterParamswithLotofModifs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fluff18/ML/blob/master/Copy_of_GANWithBetterParamswithLotofModifs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_iaQa45ebnmi",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import gzip\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy\n",
        "from six.moves import urllib\n",
        "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
        "\n",
        "from tensorflow.python.framework import dtypes\n",
        "from tensorflow.python.framework import random_seed\n",
        "from tensorflow.python.platform import gfile\n",
        "from tensorflow.python.util.deprecation import deprecated\n",
        "\n",
        "_Datasets = collections.namedtuple('_Datasets', ['train', 'validation', 'test'])\n",
        "\n",
        "# CVDF mirror of http://yann.lecun.com/exdb/mnist/\n",
        "DEFAULT_SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\n",
        "\n",
        "\n",
        "def _read32(bytestream):\n",
        "  dt = numpy.dtype(numpy.uint32).newbyteorder('>')\n",
        "  return numpy.frombuffer(bytestream.read(4), dtype=dt)[0]\n",
        "\n",
        "\n",
        "@deprecated(None, 'Please use tf.data to implement this functionality.')\n",
        "def _extract_images(f):\n",
        "  \"\"\"Extract the images into a 4D uint8 numpy array [index, y, x, depth].\n",
        "  Args:\n",
        "    f: A file object that can be passed into a gzip reader.\n",
        "  Returns:\n",
        "    data: A 4D uint8 numpy array [index, y, x, depth].\n",
        "  Raises:\n",
        "    ValueError: If the bytestream does not start with 2051.\n",
        "  \"\"\"\n",
        "  print('Extracting', f.name)\n",
        "  with gzip.GzipFile(fileobj=f) as bytestream:\n",
        "    magic = _read32(bytestream)\n",
        "    if magic != 2051:\n",
        "      raise ValueError('Invalid magic number %d in MNIST image file: %s' %\n",
        "                       (magic, f.name))\n",
        "    num_images = _read32(bytestream)\n",
        "    rows = _read32(bytestream)\n",
        "    cols = _read32(bytestream)\n",
        "    buf = bytestream.read(rows * cols * num_images)\n",
        "    data = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
        "    data = data.reshape(num_images, rows, cols, 1)\n",
        "    return data\n",
        "\n",
        "\n",
        "@deprecated(None, 'Please use tf.one_hot on tensors.')\n",
        "def _dense_to_one_hot(labels_dense, num_classes):\n",
        "  \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n",
        "  num_labels = labels_dense.shape[0]\n",
        "  index_offset = numpy.arange(num_labels) * num_classes\n",
        "  labels_one_hot = numpy.zeros((num_labels, num_classes))\n",
        "  labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
        "  return labels_one_hot\n",
        "\n",
        "\n",
        "@deprecated(None, 'Please use tf.data to implement this functionality.')\n",
        "def _extract_labels(f, one_hot=False, num_classes=10):\n",
        "  \"\"\"Extract the labels into a 1D uint8 numpy array [index].\n",
        "  Args:\n",
        "    f: A file object that can be passed into a gzip reader.\n",
        "    one_hot: Does one hot encoding for the result.\n",
        "    num_classes: Number of classes for the one hot encoding.\n",
        "  Returns:\n",
        "    labels: a 1D uint8 numpy array.\n",
        "  Raises:\n",
        "    ValueError: If the bystream doesn't start with 2049.\n",
        "  \"\"\"\n",
        "  print('Extracting', f.name)\n",
        "  with gzip.GzipFile(fileobj=f) as bytestream:\n",
        "    magic = _read32(bytestream)\n",
        "    if magic != 2049:\n",
        "      raise ValueError('Invalid magic number %d in MNIST label file: %s' %\n",
        "                       (magic, f.name))\n",
        "    num_items = _read32(bytestream)\n",
        "    buf = bytestream.read(num_items)\n",
        "    labels = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
        "    if one_hot:\n",
        "      return _dense_to_one_hot(labels, num_classes)\n",
        "    return labels\n",
        "\n",
        "\n",
        "class _DataSet(object):\n",
        "  \"\"\"Container class for a _DataSet (deprecated).\n",
        "  THIS CLASS IS DEPRECATED.\n",
        "  \"\"\"\n",
        "\n",
        "  @deprecated(None, 'Please use alternatives such as official/mnist/_DataSet.py'\n",
        "              ' from tensorflow/models.')\n",
        "  def __init__(self,\n",
        "               images,\n",
        "               labels,\n",
        "               fake_data=False,\n",
        "               one_hot=False,\n",
        "               dtype=dtypes.float32,\n",
        "               reshape=True,\n",
        "               seed=None):\n",
        "    \"\"\"Construct a _DataSet.\n",
        "    one_hot arg is used only if fake_data is true.  `dtype` can be either\n",
        "    `uint8` to leave the input as `[0, 255]`, or `float32` to rescale into\n",
        "    `[0, 1]`.  Seed arg provides for convenient deterministic testing.\n",
        "    Args:\n",
        "      images: The images\n",
        "      labels: The labels\n",
        "      fake_data: Ignore inages and labels, use fake data.\n",
        "      one_hot: Bool, return the labels as one hot vectors (if True) or ints (if\n",
        "        False).\n",
        "      dtype: Output image dtype. One of [uint8, float32]. `uint8` output has\n",
        "        range [0,255]. float32 output has range [0,1].\n",
        "      reshape: Bool. If True returned images are returned flattened to vectors.\n",
        "      seed: The random seed to use.\n",
        "    \"\"\"\n",
        "    seed1, seed2 = random_seed.get_seed(seed)\n",
        "    # If op level seed is not set, use whatever graph level seed is returned\n",
        "    numpy.random.seed(seed1 if seed is None else seed2)\n",
        "    dtype = dtypes.as_dtype(dtype).base_dtype\n",
        "    if dtype not in (dtypes.uint8, dtypes.float32):\n",
        "      raise TypeError('Invalid image dtype %r, expected uint8 or float32' %\n",
        "                      dtype)\n",
        "    if fake_data:\n",
        "      self._num_examples = 10000\n",
        "      self.one_hot = one_hot\n",
        "    else:\n",
        "      assert images.shape[0] == labels.shape[0], (\n",
        "          'images.shape: %s labels.shape: %s' % (images.shape, labels.shape))\n",
        "      self._num_examples = images.shape[0]\n",
        "\n",
        "      # Convert shape from [num examples, rows, columns, depth]\n",
        "      # to [num examples, rows*columns] (assuming depth == 1)\n",
        "      if reshape:\n",
        "        assert images.shape[3] == 1\n",
        "        images = images.reshape(images.shape[0],\n",
        "                                images.shape[1] * images.shape[2])\n",
        "      if dtype == dtypes.float32:\n",
        "        # Convert from [0, 255] -> [0.0, 1.0].\n",
        "        images = images.astype(numpy.float32)\n",
        "        images = numpy.multiply(images, 1.0 / 255.0)\n",
        "    self._images = images\n",
        "    self._labels = labels\n",
        "    self._epochs_completed = 0\n",
        "    self._index_in_epoch = 0\n",
        "\n",
        "  @property\n",
        "  def images(self):\n",
        "    return self._images\n",
        "\n",
        "  @property\n",
        "  def labels(self):\n",
        "    return self._labels\n",
        "\n",
        "  @property\n",
        "  def num_examples(self):\n",
        "    return self._num_examples\n",
        "\n",
        "  @property\n",
        "  def epochs_completed(self):\n",
        "    return self._epochs_completed\n",
        "\n",
        "  def next_batch(self, batch_size, fake_data=False, shuffle=True):\n",
        "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
        "    if fake_data:\n",
        "      fake_image = [1] * 784\n",
        "      if self.one_hot:\n",
        "        fake_label = [1] + [0] * 9\n",
        "      else:\n",
        "        fake_label = 0\n",
        "      return [fake_image for _ in xrange(batch_size)\n",
        "             ], [fake_label for _ in xrange(batch_size)]\n",
        "    start = self._index_in_epoch\n",
        "    # Shuffle for the first epoch\n",
        "    if self._epochs_completed == 0 and start == 0 and shuffle:\n",
        "      perm0 = numpy.arange(self._num_examples)\n",
        "      numpy.random.shuffle(perm0)\n",
        "      self._images = self.images[perm0]\n",
        "      self._labels = self.labels[perm0]\n",
        "    # Go to the next epoch\n",
        "    if start + batch_size > self._num_examples:\n",
        "      # Finished epoch\n",
        "      self._epochs_completed += 1\n",
        "      # Get the rest examples in this epoch\n",
        "      rest_num_examples = self._num_examples - start\n",
        "      images_rest_part = self._images[start:self._num_examples]\n",
        "      labels_rest_part = self._labels[start:self._num_examples]\n",
        "      # Shuffle the data\n",
        "      if shuffle:\n",
        "        perm = numpy.arange(self._num_examples)\n",
        "        numpy.random.shuffle(perm)\n",
        "        self._images = self.images[perm]\n",
        "        self._labels = self.labels[perm]\n",
        "      # Start next epoch\n",
        "      start = 0\n",
        "      self._index_in_epoch = batch_size - rest_num_examples\n",
        "      end = self._index_in_epoch\n",
        "      images_new_part = self._images[start:end]\n",
        "      labels_new_part = self._labels[start:end]\n",
        "      return numpy.concatenate((images_rest_part, images_new_part),\n",
        "                               axis=0), numpy.concatenate(\n",
        "                                   (labels_rest_part, labels_new_part), axis=0)\n",
        "    else:\n",
        "      self._index_in_epoch += batch_size\n",
        "      end = self._index_in_epoch\n",
        "      return self._images[start:end], self._labels[start:end]\n",
        "\n",
        "\n",
        "@deprecated(None, 'Please write your own downloading logic.')\n",
        "def _maybe_download(filename, work_directory, source_url):\n",
        "  \"\"\"Download the data from source url, unless it's already here.\n",
        "  Args:\n",
        "      filename: string, name of the file in the directory.\n",
        "      work_directory: string, path to working directory.\n",
        "      source_url: url to download from if file doesn't exist.\n",
        "  Returns:\n",
        "      Path to resulting file.\n",
        "  \"\"\"\n",
        "  if not gfile.Exists(work_directory):\n",
        "    gfile.MakeDirs(work_directory)\n",
        "  filepath = os.path.join(work_directory, filename)\n",
        "  if not gfile.Exists(filepath):\n",
        "    urllib.request.urlretrieve(source_url, filepath)\n",
        "    with gfile.GFile(filepath) as f:\n",
        "      size = f.size()\n",
        "    print('Successfully downloaded', filename, size, 'bytes.')\n",
        "  return filepath\n",
        "\n",
        "\n",
        "@deprecated(None, 'Please use alternatives such as:'\n",
        "            ' tensorflow_datasets.load(\\'mnist\\')')\n",
        "def read_data_sets(train_dir,\n",
        "                   fake_data=False,\n",
        "                   one_hot=False,\n",
        "                   dtype=dtypes.float32,\n",
        "                   reshape=True,\n",
        "                   validation_size=5000,\n",
        "                   seed=None,\n",
        "                   source_url=DEFAULT_SOURCE_URL):\n",
        "  if fake_data:\n",
        "\n",
        "    def fake():\n",
        "      return _DataSet([], [],\n",
        "                      fake_data=True,\n",
        "                      one_hot=one_hot,\n",
        "                      dtype=dtype,\n",
        "                      seed=seed)\n",
        "\n",
        "    train = fake()\n",
        "    validation = fake()\n",
        "    test = fake()\n",
        "    return _Datasets(train=train, validation=validation, test=test)\n",
        "\n",
        "  if not source_url:  # empty string check\n",
        "    source_url = DEFAULT_SOURCE_URL\n",
        "\n",
        "  train_images_file = 'train-images-idx3-ubyte.gz'\n",
        "  train_labels_file = 'train-labels-idx1-ubyte.gz'\n",
        "  test_images_file = 't10k-images-idx3-ubyte.gz'\n",
        "  test_labels_file = 't10k-labels-idx1-ubyte.gz'\n",
        "\n",
        "  local_file = _maybe_download(train_images_file, train_dir,\n",
        "                               source_url + train_images_file)\n",
        "  with gfile.Open(local_file, 'rb') as f:\n",
        "    train_images = _extract_images(f)\n",
        "\n",
        "  local_file = _maybe_download(train_labels_file, train_dir,\n",
        "                               source_url + train_labels_file)\n",
        "  with gfile.Open(local_file, 'rb') as f:\n",
        "    train_labels = _extract_labels(f, one_hot=one_hot)\n",
        "\n",
        "  local_file = _maybe_download(test_images_file, train_dir,\n",
        "                               source_url + test_images_file)\n",
        "  with gfile.Open(local_file, 'rb') as f:\n",
        "    test_images = _extract_images(f)\n",
        "\n",
        "  local_file = _maybe_download(test_labels_file, train_dir,\n",
        "                               source_url + test_labels_file)\n",
        "  with gfile.Open(local_file, 'rb') as f:\n",
        "    test_labels = _extract_labels(f, one_hot=one_hot)\n",
        "\n",
        "  if not 0 <= validation_size <= len(train_images):\n",
        "    raise ValueError(\n",
        "        'Validation size should be between 0 and {}. Received: {}.'.format(\n",
        "            len(train_images), validation_size))\n",
        "\n",
        "  validation_images = train_images[:validation_size]\n",
        "  validation_labels = train_labels[:validation_size]\n",
        "  train_images = train_images[validation_size:]\n",
        "  train_labels = train_labels[validation_size:]\n",
        "\n",
        "  options = dict(dtype=dtype, reshape=reshape, seed=seed)\n",
        "\n",
        "  train = _DataSet(train_images, train_labels, **options)\n",
        "  validation = _DataSet(validation_images, validation_labels, **options)\n",
        "  test = _DataSet(test_images, test_labels, **options)\n",
        "\n",
        "  return _Datasets(train=train, validation=validation, test=test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3BshiewAbfPU",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "import numpy as np,sys,time\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets\n",
        "import os\n",
        "import numpy as np,sys\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZffTWt8ZbfPo",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "def ReLu(x):\n",
        "    mask = (x>0) * 1.0\n",
        "    return (mask *x).reshape(x.shape[0],x.shape[1])\n",
        "def d_ReLu(x):\n",
        "    mask = (x>0) * 1.0\n",
        "    return mask.reshape(x.shape[0],x.shape[1])\n",
        "\n",
        "def Lrelu(x):\n",
        "#    alpha = 0.0001\n",
        "#    return np.where(x > 0, x, x * alpha) \n",
        "    y1 = ((x > 0) * x)                                                 \n",
        "    y2 = ((x <= 0) * x * 0.01)                                         \n",
        "    return (y1 + y2)\n",
        "def d_Lrelu(x,alpha = 0.01):\n",
        "  dx = np.ones_like(x)\n",
        "  dx[x < 0] = alpha\n",
        "  return dx\n",
        "def arctan(x):\n",
        "    return np.arctan(x)\n",
        "def d_arctan(x):\n",
        "    return (1 / (1 + x ** 2))\n",
        "\n",
        "def log(x):\n",
        "    return (1 / ( 1+ np.exp(-1*x)))\n",
        "def d_log(x):\n",
        "    return log(x) * (1 - log(x))\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x).reshape(x.shape[0],x.shape[1])\n",
        "def d_tanh(x):\n",
        "    return (1 - np.tanh(x) ** 2)\n",
        "\n",
        "def plot(samples, title):\n",
        "    print(len(samples))\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    gs = gridspec.GridSpec(10, 10)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "    for i, sample in enumerate(samples):\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis('off')\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect('equal')\n",
        "        plt.title(title)\n",
        "        sample_resized = sample.reshape(batch_size, 28, 28)\n",
        "        # plt.imshow(sample.reshape(5, 28, 28), cmap='Greys_r')\n",
        "        plt.imshow(sample_resized[0], cmap='Greys_r')\n",
        "    plt.show()\n",
        "def plots(samples, title):\n",
        "    print(len(samples))\n",
        "    plt.figure()\n",
        "    gs = gridspec.GridSpec(4,4)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "    for i, sample in enumerate(samples):\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis('off')\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect('equal')\n",
        "        sample_resized = sample.reshape(28, 28)\n",
        "        # plt.imshow(sample.reshape(5, 28, 28), cmap='Greys_r')\n",
        "        plt.imshow(sample_resized, cmap='Greys_r')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aPAKJeiAbfP4",
        "colab": {}
      },
      "source": [
        "# random_numer = 1222 #int(input(\"Please Input a Random Number to Seed\"))\n",
        "# np.random.seed(random_numer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ulnl3-qYbfQH",
        "outputId": "6c2f3823-d8ed-4aa8-9aee-368824fc5ec3",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "# 1. Load Data and declare hyper\n",
        "print('--------- Load Data ----------')\n",
        "mnist = read_data_sets('MNIST_data', one_hot=False)\n",
        "temp = mnist.test\n",
        "images, labels = temp.images, temp.labels\n",
        "images, labels = shuffle(np.asarray(images),np.asarray(labels))\n",
        "num_epoch = 50\n",
        "learing_rate = 0.00002\n",
        "learing_rate2 = 0.00002\n",
        "G_input = 100\n",
        "hidden_input,hidden_input2,hidden_input3 = 128,256,346\n",
        "hidden_input4,hidden_input5,hidden_input6 = 480,560,686\n",
        "hidden_input7,hidden_input8,hidden_input9 = 800,1020,1400\n",
        "hidden_input10 = 1800"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------- Load Data ----------\n",
            "WARNING:tensorflow:From <ipython-input-4-7ac0ac0f4408>:2: read_data_sets (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as: tensorflow_datasets.load('mnist')\n",
            "WARNING:tensorflow:From <ipython-input-1-03a9021563ce>:267: _maybe_download (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From <ipython-input-1-03a9021563ce>:269: _extract_images (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From <ipython-input-1-03a9021563ce>:274: _extract_labels (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From <ipython-input-1-03a9021563ce>:298: _DataSet.__init__ (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/_DataSet.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nh1txYT4bfQT",
        "outputId": "ea8a3e04-4be8-499c-ff56-03746abf7f61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('--------- Declare Hyper Parameters ----------')\n",
        "D_W1 = np.random.normal(size=(784,hidden_input),scale=(1. / np.sqrt(784 / 2.)))   *0.002\n",
        "# D_b1 = np.random.normal(size=(128),scale=(1. / np.sqrt(128 / 2.)))       *0.002\n",
        "D_b1 = np.zeros(hidden_input).reshape(1,hidden_input)\n",
        "\n",
        "D_W2 = np.random.normal(size=(hidden_input,hidden_input2),scale=(1. / np.sqrt(hidden_input / 2.)))   *0.002\n",
        "# G_b1 = np.random.normal(size=(128),scale=(1. / np.sqrt(128 / 2.)))      *0.002\n",
        "D_b2 = np.zeros(hidden_input2).reshape(1,hidden_input2)\n",
        "\n",
        "D_W3 = np.random.normal(size=(hidden_input2,hidden_input3),scale=(1. / np.sqrt(hidden_input2 / 2.)))   *0.002\n",
        "# G_b1 = np.random.normal(size=(128),scale=(1. / np.sqrt(128 / 2.)))      *0.002\n",
        "D_b3 = np.zeros(hidden_input3).reshape(1,hidden_input3)\n",
        "\n",
        "D_W4 = np.random.normal(size=(hidden_input3,1),scale=(1. / np.sqrt(hidden_input / 2.)))     *0.002\n",
        "# D_b2 = np.random.normal(size=(1),scale=(1. / np.sqrt(1 / 2.)))           *0.002\n",
        "D_b4 = np.zeros(1).reshape(1,1)\n",
        "\n",
        "\n",
        "G_W1 = np.random.normal(size=(G_input,hidden_input),scale=(1. / np.sqrt(G_input / 2.)))   *0.002\n",
        "# G_b1 = np.random.normal(size=(128),scale=(1. / np.sqrt(128 / 2.)))      *0.002\n",
        "G_b1 = np.zeros(hidden_input).reshape(1,hidden_input)\n",
        "\n",
        "G_W2 = np.random.normal(size=(hidden_input,hidden_input2),scale=(1. / np.sqrt(hidden_input / 2.)))   *0.002\n",
        "# G_b1 = np.random.normal(size=(128),scale=(1. / np.sqrt(128 / 2.)))      *0.002\n",
        "G_b2 = np.zeros(hidden_input2).reshape(1,hidden_input2)\n",
        "\n",
        "G_W3 = np.random.normal(size=(hidden_input2,hidden_input3),scale=(1. / np.sqrt(hidden_input2 / 2.)))   *0.002\n",
        "# G_b1 = np.random.normal(size=(128),scale=(1. / np.sqrt(128 / 2.)))      *0.002\n",
        "G_b3 = np.zeros(hidden_input3).reshape(1,hidden_input3)\n",
        "\n",
        "G_W4 = np.random.normal(size=(hidden_input3,hidden_input4),scale=(1. / np.sqrt(hidden_input3 / 2.)))   *0.002\n",
        "# G_b1 = np.random.normal(size=(128),scale=(1. / np.sqrt(128 / 2.)))      *0.002\n",
        "G_b4 = np.zeros(hidden_input4).reshape(1,hidden_input4)\n",
        "\n",
        "G_W11 = np.random.normal(size=(hidden_input4,784),scale=(1. / np.sqrt(hidden_input4 / 2.)))  *0.002\n",
        "# G_b2 = np.random.normal(size=(784),scale=(1. / np.sqrt(784 / 2.)))      *0.002\n",
        "G_b11 = np.zeros(784).reshape(1,784)\n",
        "# 2. Declare Weights\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "grad_D_w1 = np.zeros(784*hidden_input).reshape(784,hidden_input)\n",
        "grad_D_b1 = np.zeros(hidden_input).reshape(1,hidden_input)\n",
        "\n",
        "grad_D_w2 = np.zeros(hidden_input*hidden_input2).reshape(hidden_input, hidden_input2)\n",
        "grad_D_b2 = np.zeros(hidden_input2).reshape(1,hidden_input2)\n",
        "\n",
        "grad_D_w3 = np.zeros(hidden_input2*hidden_input3).reshape(hidden_input2, hidden_input3)\n",
        "grad_D_b3 = np.zeros(hidden_input3).reshape(1,hidden_input3)\n",
        "\n",
        "grad_D_w4 = np.zeros(hidden_input3).reshape(hidden_input3,1)\n",
        "grad_D_b4 = np.zeros(1).reshape(1,1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "grad_g_w1 = np.zeros(G_input*hidden_input).reshape(G_input, hidden_input)\n",
        "grad_g_b1 = np.zeros(hidden_input).reshape(1,hidden_input)\n",
        "\n",
        "grad_g_w2 = np.zeros(hidden_input*hidden_input2).reshape(hidden_input, hidden_input2)\n",
        "grad_g_b2 = np.zeros(hidden_input2).reshape(1,hidden_input2)\n",
        "\n",
        "grad_g_w3 = np.zeros(hidden_input2*hidden_input3).reshape(hidden_input2, hidden_input3)\n",
        "grad_g_b3 = np.zeros(hidden_input3).reshape(1,hidden_input3)\n",
        "\n",
        "grad_g_w4 = np.zeros(hidden_input3*hidden_input4).reshape(hidden_input3, hidden_input4)\n",
        "grad_g_b4 = np.zeros(hidden_input4).reshape(1,hidden_input4)\n",
        "\n",
        "grad_g_w11 = np.zeros(hidden_input4*784).reshape(hidden_input4, 784)\n",
        "grad_g_b11 = np.zeros(784).reshape(1,784)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------- Declare Hyper Parameters ----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "efhLIYTtbfQn",
        "colab": {}
      },
      "source": [
        "\n",
        "# 3. For Adam Optimzier\n",
        "m1w1,m1b1 = 0,0\n",
        "m2w2,m2b2 = 0,0\n",
        "m3w3,m3b3 = 0,0\n",
        "m4w4,m4b4 = 0,0\n",
        "\n",
        "v1w1,v1b1 = 0,0\n",
        "v2w2,v2b2 = 0,0\n",
        "v3w3,v3b3 = 0,0\n",
        "v4w4,v4b4 = 0,0\n",
        "\n",
        "v5,m5 = 0,0\n",
        "v6,m6 = 0,0\n",
        "v7,m7 = 0,0\n",
        "v8,m8 = 0,0\n",
        "v9,m9 = 0,0\n",
        "v10,m10 = 0,0\n",
        "v11,m11 = 0,0\n",
        "v12,m12 = 0,0\n",
        "v13,m13 = 0,0\n",
        "v14,m14 = 0,0\n",
        "v15,m15 = 0,0\n",
        "v16,m16 = 0,0\n",
        "v17,m17 = 0,0\n",
        "v18,m18 = 0,0\n",
        "v19,m19 = 0,0\n",
        "v20,m20 = 0,0\n",
        "v21,m21 = 0,0\n",
        "v22,m22 = 0,0\n",
        "v23,m23 = 0,0\n",
        "v24,m24 = 0,0\n",
        "v25,m25 = 0,0\n",
        "v26,m26 = 0,0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iYhaQBh8bfQy",
        "colab": {}
      },
      "source": [
        "beta_1,beta_2,eps = 0.5,0.5,0.000001\n",
        "D_list_cost = []\n",
        "G_list_cost = []\n",
        "forwardPropGen1 = []\n",
        "forwardPropGen2 = []\n",
        "forwardPropDisc1 = []\n",
        "forwardPropDisc2 = []\n",
        "forwardPropDisc3 = []\n",
        "backwardPropGen = []\n",
        "backwardPropDisc = []\n",
        "gradientComputeDisc1 = []\n",
        "gradientComputeDisc2 = []\n",
        "gradientComputeGen = []\n",
        "def dropout1():\n",
        "    return np.random.normal(size=(hidden_input2,),scale=0.2)\n",
        "def dropout2():\n",
        "    return np.random.normal(size=(hidden_input3,),scale=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-BDK4OlWLGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dupli_bias(bias, batch_size):\n",
        "  return np.tile(bias, (batch_size, 1)).reshape(batch_size,bias.shape[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9TaGvlfRiKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim import Optimizer\n",
        "import torchvision.utils as vutils\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tltNk0tcR44t",
        "colab_type": "code",
        "outputId": "4320cf28-0206-4678-cb59-11ec00b84f1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "D_b1.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4-ojuMORpag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5],[0.5])])\n",
        "#Make range of image from 0-1 to -1,1. So that you can use tanh while producing fake image in Generator(tanh rules!!)\n",
        "\n",
        "###########CHANGE BATCH SIZE HERE\n",
        "batch_size = 128\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=1,pin_memory=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=1,pin_memory=True)\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sIXkEq74bfQ7",
        "outputId": "720a88a1-b687-4ddc-9125-d247bbcd480f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print('--------- Started Training ----------')\n",
        "current_images = []\n",
        "current_fake_images = []\n",
        "batch_cost = []\n",
        "\n",
        "for iter in range(1,1000):\n",
        "  for i,data in enumerate(trainloader):\n",
        "    inp,op = data\n",
        "    inp = inp.to(device)\n",
        "    current_images = np.asarray(inp.reshape(inp.shape[0],28*28))\n",
        "    # current_images = np.array([])\n",
        "    # current_fake_images = np.array([])\n",
        "    # # print(current_fake_images.shape)\n",
        "    # random_int = [ np.random.randint(len(images) - 5) for i in range(batch_size) ]\n",
        "    \n",
        "    # current_image = [np.expand_dims(images[i],axis=0) for i in random_int]\n",
        "    \n",
        "    # current_images = np.vstack(current_image)\n",
        "\n",
        "    # Func: Generate The first Fake Data\n",
        "    # fake_images = []\n",
        "    \n",
        "    # for i in range(5):\n",
        "    Z = np.random.normal(0., 1., size=[batch_size, G_input])\n",
        "    \n",
        "    tic = time.time()\n",
        "    Gl1 = Z.dot(G_W1) + dupli_bias(G_b1, batch_size)\n",
        "    Gl1A = Lrelu(Gl1)\n",
        "    Gl2 = Gl1A.dot(G_W2) + dupli_bias(G_b2, batch_size)\n",
        "    Gl2A = Lrelu(Gl2)\n",
        "    Gl3 = Gl2A.dot(G_W3) + dupli_bias(G_b3, batch_size)\n",
        "    Gl3A = Lrelu(Gl3)\n",
        "    Gl4 = Gl3A.dot(G_W4) + dupli_bias(G_b4, batch_size)\n",
        "    Gl4A = Lrelu(Gl4)\n",
        "  \n",
        "    Gl11 = Gl4A.dot(G_W11) + dupli_bias(G_b11, batch_size)\n",
        "    current_fake_data = log(Gl11)\n",
        "    toc = time.time()\n",
        "    \n",
        "    forwardPropGen1.append((toc-tic)*1000)\n",
        "    print(\"stuff: \", current_fake_data.shape)\n",
        "    # fake_images.append(current_fake_data)\n",
        "    # print(\"shape of fake image: \", current_fake_data.shape)\n",
        "    # current_fake_images.append(current_fake_data)\n",
        "\n",
        "    # current_fake_images = np.vstack((fake_images[0], fake_images[1], fake_images[2], fake_images[3], fake_images[4]))\n",
        "    # print(\"shape of fake image: \", current_fake_images.shape)\n",
        "\n",
        "    # Func: Forward Feed for Real data\n",
        "    # Dl1_r = current_image.dot(D_W1) + D_b1\n",
        "    if(iter!=1):\n",
        "      batch_size=Inp.shape[0]\n",
        "    tic = time.time()\n",
        "    Dl1_r = current_images.dot(D_W1) + dupli_bias(D_b1, batch_size)\n",
        "    Dl1_rA = Lrelu(Dl1_r)\n",
        "    Dl2_r = Dl1_rA.dot(D_W2) + dupli_bias(D_b2, batch_size)  + dropout1()\n",
        "    Dl2_rA = Lrelu(Dl2_r)\n",
        "    Dl3_r = Dl2_rA.dot(D_W3) + dupli_bias(D_b3, batch_size) + dropout2()\n",
        "    Dl3_rA = Lrelu(Dl3_r)\n",
        "    Dl4_r = Dl3_rA.dot(D_W4) + dupli_bias(D_b4, batch_size)\n",
        "    Dl4_rA = log(Dl4_r)\n",
        "    toc=time.time()\n",
        "    forwardPropDisc1.append((toc-tic)*1000)\n",
        "    # Func: Forward Feed for Fake Data\n",
        "    tic = time.time()\n",
        "    Dl1_f = current_fake_data.dot(D_W1) + dupli_bias(D_b1, batch_size)\n",
        "    Dl1_fA = Lrelu(Dl1_f)\n",
        "    Dl2_f = Dl1_fA.dot(D_W2) + dupli_bias(D_b2, batch_size) + dropout1()\n",
        "    Dl2_fA = Lrelu(Dl2_f)\n",
        "    Dl3_f = Dl2_fA.dot(D_W3) + dupli_bias(D_b3, batch_size) + dropout2()\n",
        "    Dl3_fA = Lrelu(Dl3_f)\n",
        "    Dl4_f = Dl3_fA.dot(D_W4) + dupli_bias(D_b4, batch_size)\n",
        "    Dl4_fA = log(Dl4_f)\n",
        "    toc = time.time()\n",
        "    forwardPropDisc2.append((toc-tic)*1000)\n",
        "    # Func: Cost D\n",
        "    \n",
        "\n",
        "    D_cost = np.mean(-( np.log(Dl4_rA) +  np.log(1.0- Dl4_fA)))\n",
        "    D_list_cost.append(D_cost)\n",
        "    # batch_cost.append(D_cost[0[0]])\n",
        "    fBatch = Dl4_fA\n",
        "    rBatch = Dl4_rA\n",
        "    totgradFake = 0\n",
        "    tic = time.time()\n",
        "    for batch_item in range(0,batch_size):\n",
        "\n",
        "      grad_r_w4_part_1 =  (-1/((1-rBatch[batch_item])+ eps)).reshape(1,1)\n",
        "      grad_r_w4_part_2 =  d_log(Dl4_r[batch_item]).reshape(1,1)\n",
        "      grad_r_w4_part_3 =   Dl3_rA[batch_item].reshape(1,hidden_input3)\n",
        "      grad_r_w4 =     (grad_r_w4_part_3.T.dot(grad_r_w4_part_1 * grad_r_w4_part_2)).reshape(hidden_input3,1) \n",
        "      grad_r_b4 = grad_r_w4_part_1 * grad_r_w4_part_2\n",
        "\n",
        "      grad_D_w4 = np.add(grad_D_w4,grad_r_w4)\n",
        "      grad_D_b4 = np.add(grad_D_b4,grad_r_b4)\n",
        "\n",
        "      grad_r_w3_part_1 =  (grad_r_w4_part_1 * grad_r_w4_part_2).dot(D_W4.T)\n",
        "      grad_r_w3_part_2 =  d_Lrelu(Dl3_r[batch_item])\n",
        "      grad_r_w3_part_3 =   Dl2_rA[batch_item].reshape(1,hidden_input2)\n",
        "      grad_r_w3 =       grad_r_w3_part_3.T.dot(grad_r_w3_part_1 * grad_r_w3_part_2) \n",
        "      grad_r_b3 =      grad_r_w3_part_1 * grad_r_w3_part_2\n",
        "      \n",
        "      grad_D_w3 = np.add(grad_D_w3, grad_r_w3)\n",
        "      grad_D_b3 = np.add(grad_D_b3, grad_r_b3)\n",
        "\n",
        "      grad_r_w2_part_1 = (grad_r_w3_part_1 * grad_r_w3_part_2).dot(D_W3.T)\n",
        "      grad_r_w2_part_2 = d_Lrelu(Dl2_r[batch_item])\n",
        "      grad_r_w2_part_3 = Dl1_rA[batch_item].reshape(1, hidden_input)\n",
        "      grad_r_w2 = grad_r_w2_part_3.T.dot(grad_r_w2_part_1 * grad_r_w2_part_2)\n",
        "      grad_r_b2 = (grad_r_w2_part_1 * grad_r_w2_part_2)\n",
        "\n",
        "      grad_D_w2 = np.add(grad_D_w2, grad_r_w2)\n",
        "      grad_D_b2 = np.add(grad_D_b2, grad_r_b2)\n",
        "      \n",
        "      grad_r_w1_part_1 = (grad_r_w2_part_1 * grad_r_w2_part_2).dot(D_W2.T)\n",
        "      grad_r_w1_part_2 = d_Lrelu(Dl1_r[batch_item])\n",
        "      grad_r_w1_part_3 = current_images[batch_item].reshape(1,784)\n",
        "      grad_r_w1 = grad_r_w1_part_3.T.dot(grad_r_w1_part_1 * grad_r_w1_part_2)\n",
        "      grad_r_b1 = grad_r_w1_part_1 * grad_r_w1_part_2\n",
        "\n",
        "      grad_D_w1 = np.add(grad_D_w1, grad_r_w1)\n",
        "      grad_D_b1 = np.add(grad_D_b1, grad_r_b1)\n",
        "\n",
        "    toc = time.time()\n",
        "    \n",
        "    gradientComputeDisc1.append((toc-tic)*1000)\n",
        "\n",
        "    tic = time.time()\n",
        "    for batch_item in range(0,batch_size):\n",
        "\n",
        "      grad_f_w4_part_1 =  (-1/((1-fBatch[batch_item])+ eps)).reshape(1,1)\n",
        "      grad_f_w4_part_2 =  d_log(Dl4_f[batch_item]).reshape(1,1)\n",
        "      grad_f_w4_part_3 =   Dl3_rA[batch_item].reshape(1,hidden_input3)\n",
        "      grad_f_w4 =     (grad_f_w4_part_3.T.dot(grad_f_w4_part_1 * grad_f_w4_part_2)).reshape(hidden_input3,1) \n",
        "      grad_f_b4 = grad_r_w4_part_1 * grad_r_w4_part_2\n",
        "\n",
        "      grad_D_w4 = np.add(grad_D_w4,grad_f_w4)\n",
        "      grad_D_b4 = np.add(grad_D_b4,grad_f_b4)\n",
        "\n",
        "\n",
        "      grad_f_w3_part_1 =  (grad_f_w4_part_1 * grad_f_w4_part_2).dot(D_W4.T)\n",
        "      grad_f_w3_part_2 =  d_Lrelu(Dl3_f[batch_item])\n",
        "      grad_f_w3_part_3 =   Dl2_fA[batch_item].reshape(1,hidden_input2)\n",
        "      grad_f_w3 =       grad_f_w3_part_3.T.dot(grad_f_w3_part_1 * grad_f_w3_part_2) \n",
        "      grad_f_b3 =      grad_f_w3_part_1 * grad_f_w3_part_2\n",
        "      \n",
        "      grad_D_w3 = np.add(grad_D_w3, grad_f_w3)\n",
        "      grad_D_b3 = np.add(grad_D_b3, grad_f_b3)\n",
        "\n",
        "      grad_f_w2_part_1 = (grad_f_w3_part_1 * grad_f_w3_part_2).dot(D_W3.T)\n",
        "      grad_f_w2_part_2 = d_Lrelu(Dl2_f[batch_item])\n",
        "      grad_f_w2_part_3 = Dl1_fA[batch_item].reshape(1, hidden_input)\n",
        "      grad_f_w2 = grad_f_w2_part_3.T.dot(grad_f_w2_part_1 * grad_f_w2_part_2)\n",
        "      grad_f_b2 = (grad_f_w2_part_1 * grad_f_w2_part_2)\n",
        "\n",
        "      grad_D_w2 = np.add(grad_D_w2, grad_r_w2)\n",
        "      grad_D_b2 = np.add(grad_D_b2, grad_r_b2)\n",
        "      \n",
        "      grad_f_w1_part_1 = (grad_f_w2_part_1 * grad_f_w2_part_2).dot(D_W2.T)\n",
        "      grad_f_w1_part_2 = d_Lrelu(Dl1_f[batch_item])\n",
        "      grad_f_w1_part_3 = current_images[batch_item].reshape(1,784)\n",
        "      grad_f_w1 = grad_f_w1_part_3.T.dot(grad_f_w1_part_1 * grad_f_w1_part_2)\n",
        "      grad_f_b1 = grad_f_w1_part_1 * grad_f_w1_part_2\n",
        "\n",
        "      grad_D_w1 = np.add(grad_D_w1, grad_f_w1)\n",
        "      grad_D_b1 = np.add(grad_D_b1, grad_f_b1)\n",
        "\n",
        "    toc = time.time()\n",
        "    \n",
        "    gradientComputeDisc2.append((toc-tic)*1000)\n",
        "    #LATER\n",
        "    \n",
        "    \n",
        "    tic = time.time()\n",
        "    grad_w1 = grad_D_w1\n",
        "    grad_w2 =grad_D_w2\n",
        "    grad_w3 =grad_D_w3\n",
        "    grad_w4 =grad_D_w4\n",
        "\n",
        "    grad_b1 =grad_D_b1\n",
        "    grad_b2 =grad_D_b2\n",
        "    grad_b3 =grad_D_b3\n",
        "    grad_b4 =grad_D_b4\n",
        "\n",
        "\n",
        "    print(\"W4 before\", D_W4.shape)\n",
        "    # ---- Update Gradient ----\n",
        "    m1w1 = beta_1 * m1w1 + (1 - beta_1) * grad_w1\n",
        "    v1w1 = beta_2 * v1w1 + (1 - beta_2) * grad_w1 ** 2\n",
        "    \n",
        "    m2w2 = beta_1 * m2w2 + (1 - beta_1) * grad_w2\n",
        "    v2w2 = beta_2 * v2w2 + (1 - beta_2) * grad_w2 ** 2\n",
        "    \n",
        "    m3w3 = beta_1 * m3w3 + (1 - beta_1) * grad_w3\n",
        "    v3w3 = beta_2 * v3w3 + (1 - beta_2) * grad_w3 ** 2\n",
        "    \n",
        "    m4w4 = beta_1 * m4w4 + (1 - beta_1) * grad_w4\n",
        "    v4w4 = beta_2 * v4w4 + (1 - beta_2) * grad_w4 ** 2\n",
        "    \n",
        "    m1b1 = beta_1 * m1b1 + (1 - beta_1) * grad_b1\n",
        "    v1b1 = beta_2 * v1b1 + (1 - beta_2) * grad_b1 ** 2\n",
        "    \n",
        "    m2b2 = beta_1 * m2b2 + (1 - beta_1) * grad_b2\n",
        "    v2b2 = beta_2 * v2b2 + (1 - beta_2) * grad_b2 ** 2\n",
        "    \n",
        "    m3b3 = beta_1 * m3b3 + (1 - beta_1) * grad_b3\n",
        "    v3b3 = beta_2 * v3b3 + (1 - beta_2) * grad_b3 ** 2\n",
        "    \n",
        "    m4b4 = beta_1 * m4b4 + (1 - beta_1) * grad_b4\n",
        "    v4b4 = beta_2 * v4b4 + (1 - beta_2) * grad_b4 ** 2\n",
        "\n",
        "    print(\"M$V$\",m4w4.shape)\n",
        "    D_W1 = D_W1 - (learing_rate2 / (np.sqrt(v1w1 /(1-beta_2**iter )) + eps)) * (m1w1/(1-beta_1**iter)  + eps)\n",
        "    D_b1 = D_b1 - (learing_rate2 / (np.sqrt(v1b1 /(1-beta_2**iter )) + eps)) * (m1b1/(1-beta_1**iter)  + eps)\n",
        "        \n",
        "    D_W2 = D_W2 - (learing_rate2 / (np.sqrt(v2w2 /(1-beta_2**iter )) + eps)) * (m2w2/(1-beta_1**iter)  + eps)\n",
        "    D_b2 = D_b2 - (learing_rate2 / (np.sqrt(v2b2 /(1-beta_2**iter )) + eps)) * (m2b2/(1-beta_1**iter)  + eps)\n",
        "    \n",
        "  \n",
        "    D_W3 = D_W3 - (learing_rate2 / (np.sqrt(v3w3 /(1-beta_2**iter )) + eps)) * (m3w3/(1-beta_1**iter)  + eps)\n",
        "    D_b3 = D_b3 - (learing_rate2 / (np.sqrt(v3b3 /(1-beta_2**iter )) + eps)) * (m3b3/(1-beta_1**iter)  + eps)\n",
        "\n",
        "    D_W4 = D_W4 - (learing_rate2 / (np.sqrt(v4w4 /(1-beta_2**iter )) + eps)) * (m4w4/(1-beta_1**iter)  + eps)\n",
        "    D_b4 = D_b4 - (learing_rate2 / (np.sqrt(v4b4 /(1-beta_2**iter )) + eps)) * (m4b4/(1-beta_1**iter)  + eps)\n",
        "\n",
        "    print(\"W4 after\", D_W4.shape)\n",
        "\n",
        "    toc = time.time()\n",
        "    backwardPropDisc.append((toc-tic)*1000)\n",
        "    #current_images = np.delete(current_images, [0,1,2,3,4])\n",
        "    # current_fake_images = np.delete(current_fake_images, [0,1,2,3,4])\n",
        "    # batch_cost = []\n",
        "\n",
        "    # Func: Forward Feed for G\n",
        "    # fake_images = []\n",
        "    if(i%3==0):\n",
        "        tic = time.time()\n",
        "\n",
        "        Gl1 = Z.dot(G_W1) + dupli_bias(G_b1, batch_size)\n",
        "        Gl1A = Lrelu(Gl1)\n",
        "        Gl2 = Gl1A.dot(G_W2) + dupli_bias(G_b2, batch_size)\n",
        "        Gl2A = Lrelu(Gl2)\n",
        "        Gl3 = Gl2A.dot(G_W3) + dupli_bias(G_b3, batch_size)\n",
        "        Gl3A = Lrelu(Gl3)\n",
        "        Gl4 = Gl3A.dot(G_W4) + dupli_bias(G_b4, batch_size)\n",
        "        Gl4A = Lrelu(Gl4)\n",
        "    \n",
        "        Gl11 = Gl4A.dot(G_W11) + dupli_bias(G_b11, batch_size)\n",
        "        current_fake_data = log(Gl11)\n",
        "\n",
        "        toc = time.time()\n",
        "\n",
        "        forwardPropGen2.append((toc-tic)*1000)\n",
        "\n",
        "        tic = time.time()\n",
        "        Dl1 = current_fake_data.dot(D_W1) + dupli_bias(D_b1, batch_size)\n",
        "        Dl1_A = Lrelu(Dl1)\n",
        "        Dl2 = Dl1_A.dot(D_W2) + dupli_bias(D_b2, batch_size) + dropout1()\n",
        "        Dl2_A = Lrelu(Dl2)\n",
        "        Dl3 = Dl2_A.dot(D_W3) + dupli_bias(D_b3, batch_size) + dropout2()\n",
        "        Dl3_A = Lrelu(Dl3)\n",
        "        Dl4 = Dl3_A.dot(D_W4) + dupli_bias(D_b4, batch_size)\n",
        "        Dl4_A = log(Dl4)\n",
        "        toc = time.time()\n",
        "\n",
        "        forwardPropDisc3.append((toc - tic)*1000)\n",
        "        # Func: Cost G\n",
        "        G_cost = np.mean(-np.log(Dl4_A))\n",
        "        G_list_cost.append(G_cost)\n",
        "        # batch_cost.append(G_cost[0][0])\n",
        "\n",
        "        tic = time.time()\n",
        "\n",
        "        for batch_item in range(0,batch_size):\n",
        "          grad_G_w11_part_1 = ((((((( (-1/(Dl4_A[batch_item] + eps)) * d_log(Dl4[batch_item]).dot(D_W4.T) * (d_Lrelu(Dl3[batch_item])) ).dot(D_W3.T) * (d_Lrelu(Dl2[batch_item]))).dot(D_W2.T)))* (d_Lrelu(Dl1[batch_item])))).dot(D_W1.T)).reshape(1,784)\n",
        "          grad_G_w11_part_2 = d_log(Gl11[batch_item])\n",
        "          grad_G_w11_part_3 = Gl4A[batch_item].reshape(1,hidden_input4)\n",
        "          grad_G_w11 = grad_G_w11_part_3.T.dot(grad_G_w11_part_1 * grad_G_w11_part_1)\n",
        "          grad_G_b11 = grad_G_w11_part_1 * grad_G_w11_part_2\n",
        "\n",
        "          grad_g_w11 = np.add(grad_g_w11,grad_G_w11)\n",
        "          grad_g_b11 = np.add(grad_g_b11,grad_G_b11)\n",
        "\n",
        "\n",
        "          grad_G_w4_part_1 = (grad_G_w11_part_1 * grad_G_w11_part_2).dot(G_W11.T)\n",
        "          grad_G_w4_part_2 = d_Lrelu(Gl4[batch_item])\n",
        "          grad_G_w4_part_3 = Gl3A[batch_item].reshape(1,hidden_input3)\n",
        "          grad_G_w4 = grad_G_w4_part_3.T.dot(grad_G_w4_part_1 * grad_G_w4_part_2)\n",
        "          grad_G_b4 = (grad_G_w4_part_1 * grad_G_w4_part_2)\n",
        "\n",
        "          grad_g_w4 = np.add(grad_g_w4,grad_G_w4)\n",
        "          grad_g_b4 = np.add(grad_g_b4,grad_G_b4)\n",
        "\n",
        "          grad_G_w3_part_1 = (grad_G_w4_part_1 * grad_G_w4_part_2).dot(G_W4.T)\n",
        "          grad_G_w3_part_2 = d_Lrelu(Gl3[batch_item])\n",
        "          grad_G_w3_part_3 = Gl2A[batch_item].reshape(1,hidden_input2)\n",
        "          grad_G_w3 = grad_G_w3_part_3.T.dot(grad_G_w3_part_1 * grad_G_w3_part_2)\n",
        "          grad_G_b3 = (grad_G_w3_part_1 * grad_G_w3_part_2)\n",
        "\n",
        "          grad_g_w3 = np.add(grad_g_w3,grad_G_w3)\n",
        "          grad_g_b3 = np.add(grad_g_b3,grad_G_b3)\n",
        "\n",
        "          grad_G_w2_part_1 = (grad_G_w3_part_1 * grad_G_w3_part_2).dot(G_W3.T)\n",
        "          grad_G_w2_part_2 = d_Lrelu(Gl2[batch_item])\n",
        "          grad_G_w2_part_3 = Gl1A[batch_item].reshape(1,hidden_input)\n",
        "          grad_G_w2 = grad_G_w2_part_3.T.dot(grad_G_w2_part_1 * grad_G_w2_part_2)\n",
        "          grad_G_b2 = (grad_G_w2_part_1 * grad_G_w2_part_2)\n",
        "\n",
        "          grad_g_w2 = np.add(grad_g_w2,grad_G_w2)\n",
        "          grad_g_b2 = np.add(grad_g_b2,grad_G_b2)\n",
        "\n",
        "          grad_G_w1_part_1 = (grad_G_w2_part_1 * grad_G_w2_part_2).dot(G_W2.T)\n",
        "          grad_G_w1_part_2 = d_Lrelu(Gl1[batch_item])\n",
        "          grad_G_w1_part_3 = Z[batch_item].reshape(1,100)\n",
        "          grad_G_w1 = grad_G_w1_part_3.T.dot(grad_G_w1_part_1 * grad_G_w1_part_2)\n",
        "          grad_G_b1 = grad_G_w1_part_1 * grad_G_w1_part_2\n",
        "\n",
        "          grad_g_w1 = np.add(grad_g_w1,grad_G_w1)\n",
        "          grad_g_b1 = np.add(grad_g_b1,grad_G_b1)\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "        toc = time.time()\n",
        "        gradientComputeGen.append((toc-tic)*1000)\n",
        "        # ---- Update Gradient ----\n",
        "\n",
        "        tic = time.time()\n",
        "        m5 = beta_1 * m5 + (1 - beta_1) * grad_g_w1\n",
        "        v5 = beta_2 * v5 + (1 - beta_2) * grad_g_w1 ** 2\n",
        "\n",
        "        m6 = beta_1 * m6 + (1 - beta_1) * grad_g_b1\n",
        "        v6 = beta_2 * v6 + (1 - beta_2) * grad_g_b1 ** 2\n",
        "\n",
        "        m7 = beta_1 * m7 + (1 - beta_1) * grad_g_w2\n",
        "        v7 = beta_2 * v7 + (1 - beta_2) * grad_g_w2 ** 2\n",
        "\n",
        "        m8 = beta_1 * m8 + (1 - beta_1) * grad_g_b2\n",
        "        v8 = beta_2 * v8 + (1 - beta_2) * grad_g_b2 ** 2\n",
        "\n",
        "        m9 = beta_1 * m9 + (1 - beta_1) * grad_g_w3\n",
        "        v9 = beta_2 * v9 + (1 - beta_2) * grad_g_w3 ** 2\n",
        "\n",
        "        m10 = beta_1 * m10 + (1 - beta_1) * grad_g_b3\n",
        "        v10 = beta_2 * v10 + (1 - beta_2) * grad_g_b3 ** 2\n",
        "\n",
        "        m11 = beta_1 * m11 + (1 - beta_1) * grad_g_w4\n",
        "        v11 = beta_2 * v11 + (1 - beta_2) * grad_g_w4 ** 2\n",
        "\n",
        "        m12 = beta_1 * m12 + (1 - beta_1) * grad_g_b4\n",
        "        v12 = beta_2 * v12 + (1 - beta_2) * grad_g_b4 ** 2\n",
        "\n",
        "   \n",
        "\n",
        "        m25 = beta_1 * m25 + (1 - beta_1) * grad_g_w11\n",
        "        v25 = beta_2 * v25 + (1 - beta_2) * grad_g_w11 ** 2\n",
        "\n",
        "        m26 = beta_1 * m26 + (1 - beta_1) * grad_g_b11\n",
        "        v26 = beta_2 * v26 + (1 - beta_2) * grad_g_b11 ** 2\n",
        "\n",
        "\n",
        "        G_W1 = G_W1 - (learing_rate / (np.sqrt(v5 /(1-beta_2**iter )) + eps)) * (m5/(1-beta_1**iter)  + eps)\n",
        "        G_b1 = G_b1 - (learing_rate / (np.sqrt(v6 /(1-beta_2**iter )) + eps)) * (m6/(1-beta_1**iter)  + eps)\n",
        "\n",
        "        G_W2 = G_W2 - (learing_rate / (np.sqrt(v7 /(1-beta_2**iter )) + eps)) * (m7/(1-beta_1**iter)  + eps)\n",
        "        G_b2 = G_b2 - (learing_rate / (np.sqrt(v8 /(1-beta_2**iter )) + eps)) * (m8/(1-beta_1**iter)  + eps)\n",
        "\n",
        "        G_W3 = G_W3 - (learing_rate / (np.sqrt(v9 /(1-beta_2**iter )) + eps)) * (m9/(1-beta_1**iter)  + eps)\n",
        "        G_b3 = G_b3 - (learing_rate / (np.sqrt(v10 /(1-beta_2**iter )) + eps)) * (m10/(1-beta_1**iter)  + eps)\n",
        "\n",
        "        G_W4 = G_W4 - (learing_rate / (np.sqrt(v11 /(1-beta_2**iter )) + eps)) * (m11/(1-beta_1**iter)  + eps)\n",
        "        G_b4 = G_b4 - (learing_rate / (np.sqrt(v12 /(1-beta_2**iter )) + eps)) * (m12/(1-beta_1**iter)  + eps)\n",
        "\n",
        "   \n",
        "\n",
        "        G_W11 = G_W11 - (learing_rate / (np.sqrt(v25 /(1-beta_2**iter )) + eps)) * (m25/(1-beta_1**iter)  + eps)\n",
        "        G_b11 = G_b11 - (learing_rate / (np.sqrt(v26 /(1-beta_2**iter )) + eps)) * (m26/(1-beta_1**iter)  + eps)\n",
        "\n",
        "        # random_data = np.delete(random_data,[0,1,2,3,4,5])\n",
        "        toc = time.time()\n",
        "\n",
        "        backwardPropGen.append((toc-tic)*1000)\n",
        "    print(\"Current Epoch: \",iter, \" Current Iter:\",i, \" Current D cost:\",D_cost, \" Current G cost: \", G_cost)\n",
        "    \n",
        "    if i%100 == 0:\n",
        "        Z = np.random.normal(0., 1., size=[16, G_input]) \n",
        "        Gl1 = Z.dot(G_W1) + dupli_bias(G_b1, 16)\n",
        "        Gl1A = Lrelu(Gl1)\n",
        "        Gl2 = Gl1A.dot(G_W2) + dupli_bias(G_b2, 16)\n",
        "        Gl2A = Lrelu(Gl2)\n",
        "        Gl3 = Gl2A.dot(G_W3) + dupli_bias(G_b3, 16)\n",
        "        Gl3A = Lrelu(Gl3)\n",
        "        Gl4 = Gl3A.dot(G_W4) + dupli_bias(G_b4, 16)\n",
        "        Gl4A = Lrelu(Gl4)\n",
        " \n",
        "        Gl11 = Gl4A.dot(G_W11) + dupli_bias(G_b11, 16)\n",
        "        current_fake_data = log(Gl11)\n",
        "        plots(current_fake_data,\"TITLE\")\n",
        "    # ---- Print to Out put ----\n",
        "# -- end code --"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------- Started Training ----------\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 0  Current D cost: 1.3861790355529902  Current G cost:  0.6929970823478987\n",
            "16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAADnCAYAAABv/o9IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 1  Current D cost: 1.3867666330651887  Current G cost:  0.6929970823478987\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 2  Current D cost: 1.386438179908165  Current G cost:  0.6929970823478987\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 3  Current D cost: 1.3858154345350595  Current G cost:  0.6921934341368098\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 4  Current D cost: 1.385433651258734  Current G cost:  0.6921934341368098\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 5  Current D cost: 1.3862221619735253  Current G cost:  0.6921934341368098\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 6  Current D cost: 1.3865413917651492  Current G cost:  0.691519103565715\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 7  Current D cost: 1.3857663868483598  Current G cost:  0.691519103565715\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 8  Current D cost: 1.3859553949868042  Current G cost:  0.691519103565715\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 9  Current D cost: 1.386031162766605  Current G cost:  0.6905298969364536\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 10  Current D cost: 1.3875147910019228  Current G cost:  0.6905298969364536\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 11  Current D cost: 1.3863837191067536  Current G cost:  0.6905298969364536\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 12  Current D cost: 1.3858197025564394  Current G cost:  0.6892116078926913\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 13  Current D cost: 1.3872466574884572  Current G cost:  0.6892116078926913\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 14  Current D cost: 1.3873802851789407  Current G cost:  0.6892116078926913\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 15  Current D cost: 1.386342954198085  Current G cost:  0.68782975532012\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 16  Current D cost: 1.385681835038803  Current G cost:  0.68782975532012\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 17  Current D cost: 1.3877039177388983  Current G cost:  0.68782975532012\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 18  Current D cost: 1.3869509944232787  Current G cost:  0.6867988710241176\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 19  Current D cost: 1.3873425438474163  Current G cost:  0.6867988710241176\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 20  Current D cost: 1.387635721169906  Current G cost:  0.6867988710241176\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 21  Current D cost: 1.3853289272707854  Current G cost:  0.6848105326284362\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 22  Current D cost: 1.3858587282596462  Current G cost:  0.6848105326284362\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 23  Current D cost: 1.3861523973206005  Current G cost:  0.6848105326284362\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 24  Current D cost: 1.3862711586249326  Current G cost:  0.6833434988734466\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 25  Current D cost: 1.3860123974637741  Current G cost:  0.6833434988734466\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 26  Current D cost: 1.3853051134765713  Current G cost:  0.6833434988734466\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 27  Current D cost: 1.3883385583719494  Current G cost:  0.6808780162710827\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 28  Current D cost: 1.3874975449273714  Current G cost:  0.6808780162710827\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 29  Current D cost: 1.3871801983675764  Current G cost:  0.6808780162710827\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 30  Current D cost: 1.3880229394286827  Current G cost:  0.6793888771436675\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 31  Current D cost: 1.3856795523394108  Current G cost:  0.6793888771436675\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 32  Current D cost: 1.3869188550735674  Current G cost:  0.6793888771436675\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 33  Current D cost: 1.385215860494018  Current G cost:  0.67916093169072\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 34  Current D cost: 1.3871006753762143  Current G cost:  0.67916093169072\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 35  Current D cost: 1.3889872323094044  Current G cost:  0.67916093169072\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 36  Current D cost: 1.3855936054546423  Current G cost:  0.6781877141187208\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 37  Current D cost: 1.3838141693649955  Current G cost:  0.6781877141187208\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 38  Current D cost: 1.385389267015106  Current G cost:  0.6781877141187208\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 39  Current D cost: 1.3897038723142328  Current G cost:  0.6763820571273965\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 40  Current D cost: 1.3854952367819249  Current G cost:  0.6763820571273965\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 41  Current D cost: 1.3855334373371955  Current G cost:  0.6763820571273965\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 42  Current D cost: 1.383923594318341  Current G cost:  0.6763414549346921\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 43  Current D cost: 1.3910355263705938  Current G cost:  0.6763414549346921\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 44  Current D cost: 1.3872845285154285  Current G cost:  0.6763414549346921\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 45  Current D cost: 1.3847309230607538  Current G cost:  0.6731674524276839\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 46  Current D cost: 1.3866462319464463  Current G cost:  0.6731674524276839\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 47  Current D cost: 1.3894433656942875  Current G cost:  0.6731674524276839\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 48  Current D cost: 1.382399675847777  Current G cost:  0.6701519924391892\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 49  Current D cost: 1.3817217269384283  Current G cost:  0.6701519924391892\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 50  Current D cost: 1.384326786200381  Current G cost:  0.6701519924391892\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 51  Current D cost: 1.3829448050929614  Current G cost:  0.6755122388056735\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 52  Current D cost: 1.3846909380107602  Current G cost:  0.6755122388056735\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 53  Current D cost: 1.3845887769294611  Current G cost:  0.6755122388056735\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 54  Current D cost: 1.386452051856553  Current G cost:  0.6696389175445324\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 55  Current D cost: 1.383674249411428  Current G cost:  0.6696389175445324\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 56  Current D cost: 1.382639341558161  Current G cost:  0.6696389175445324\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 57  Current D cost: 1.387236619407764  Current G cost:  0.6694350733304203\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 58  Current D cost: 1.3830359872697011  Current G cost:  0.6694350733304203\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 59  Current D cost: 1.374899834547611  Current G cost:  0.6694350733304203\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 60  Current D cost: 1.3833306669425358  Current G cost:  0.6652155011048831\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 61  Current D cost: 1.3805239474613369  Current G cost:  0.6652155011048831\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 62  Current D cost: 1.3798497588917054  Current G cost:  0.6652155011048831\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 63  Current D cost: 1.3868019458811442  Current G cost:  0.6673603183326707\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 64  Current D cost: 1.3836178099412115  Current G cost:  0.6673603183326707\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 65  Current D cost: 1.3778991644148506  Current G cost:  0.6673603183326707\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 66  Current D cost: 1.3846286537486168  Current G cost:  0.6615495389430172\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 67  Current D cost: 1.3802690842090286  Current G cost:  0.6615495389430172\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 68  Current D cost: 1.378579712836307  Current G cost:  0.6615495389430172\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 69  Current D cost: 1.373858309068091  Current G cost:  0.6663202506957819\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 70  Current D cost: 1.3808268012362421  Current G cost:  0.6663202506957819\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 71  Current D cost: 1.372263887878911  Current G cost:  0.6663202506957819\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 72  Current D cost: 1.3772479933301813  Current G cost:  0.6642214798383446\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 73  Current D cost: 1.375033923204667  Current G cost:  0.6642214798383446\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 74  Current D cost: 1.3723029622117466  Current G cost:  0.6642214798383446\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 75  Current D cost: 1.373660572922164  Current G cost:  0.6581745084965609\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 76  Current D cost: 1.3691137307787045  Current G cost:  0.6581745084965609\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 77  Current D cost: 1.3657125291628538  Current G cost:  0.6581745084965609\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 78  Current D cost: 1.3683866009761  Current G cost:  0.6537742210687639\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 79  Current D cost: 1.3623729948298937  Current G cost:  0.6537742210687639\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 80  Current D cost: 1.365988341972173  Current G cost:  0.6537742210687639\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 81  Current D cost: 1.3662922135968332  Current G cost:  0.6543566966850773\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 82  Current D cost: 1.35348763331045  Current G cost:  0.6543566966850773\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 83  Current D cost: 1.3621676189834355  Current G cost:  0.6543566966850773\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 84  Current D cost: 1.357468898819607  Current G cost:  0.6528757091093722\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 85  Current D cost: 1.3605481278855907  Current G cost:  0.6528757091093722\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 86  Current D cost: 1.3524831419255632  Current G cost:  0.6528757091093722\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 87  Current D cost: 1.3563445384582993  Current G cost:  0.6481198026078668\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 88  Current D cost: 1.350322738341803  Current G cost:  0.6481198026078668\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 89  Current D cost: 1.3406530222613888  Current G cost:  0.6481198026078668\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 90  Current D cost: 1.344851188682067  Current G cost:  0.6526150036172824\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 91  Current D cost: 1.3358595766076529  Current G cost:  0.6526150036172824\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 92  Current D cost: 1.3389550597494007  Current G cost:  0.6526150036172824\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 93  Current D cost: 1.3327140167204343  Current G cost:  0.6464016148599474\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 94  Current D cost: 1.332637515032176  Current G cost:  0.6464016148599474\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 95  Current D cost: 1.3246428770112004  Current G cost:  0.6464016148599474\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 96  Current D cost: 1.331191870439345  Current G cost:  0.642734544604141\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 97  Current D cost: 1.3192270479172405  Current G cost:  0.642734544604141\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 98  Current D cost: 1.3167980921066158  Current G cost:  0.642734544604141\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 99  Current D cost: 1.3153178661218263  Current G cost:  0.6431023033970042\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 100  Current D cost: 1.3213096081676279  Current G cost:  0.6431023033970042\n",
            "16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAADnCAYAAABv/o9IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 101  Current D cost: 1.3057671874588492  Current G cost:  0.6431023033970042\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 102  Current D cost: 1.3023639594623568  Current G cost:  0.6351088903684361\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 103  Current D cost: 1.308135407621743  Current G cost:  0.6351088903684361\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 104  Current D cost: 1.294299315052135  Current G cost:  0.6351088903684361\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 105  Current D cost: 1.2798419236675436  Current G cost:  0.6363463885643247\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 106  Current D cost: 1.271408509413945  Current G cost:  0.6363463885643247\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 107  Current D cost: 1.275782770123672  Current G cost:  0.6363463885643247\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 108  Current D cost: 1.2759721334688452  Current G cost:  0.6363110298207156\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 109  Current D cost: 1.2626643648426483  Current G cost:  0.6363110298207156\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 110  Current D cost: 1.2711131735498205  Current G cost:  0.6363110298207156\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 111  Current D cost: 1.261433430019895  Current G cost:  0.6344772363515884\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 112  Current D cost: 1.2517743254804323  Current G cost:  0.6344772363515884\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 113  Current D cost: 1.2419562168103109  Current G cost:  0.6344772363515884\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 114  Current D cost: 1.2349770830726623  Current G cost:  0.6354140916028059\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 115  Current D cost: 1.2320053732694605  Current G cost:  0.6354140916028059\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 116  Current D cost: 1.2175066673792516  Current G cost:  0.6354140916028059\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 117  Current D cost: 1.2157558781537143  Current G cost:  0.6262976891070946\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 118  Current D cost: 1.208974859633717  Current G cost:  0.6262976891070946\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 119  Current D cost: 1.2110742361492512  Current G cost:  0.6262976891070946\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 120  Current D cost: 1.209185771508949  Current G cost:  0.6303490216082734\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 121  Current D cost: 1.2144230986442304  Current G cost:  0.6303490216082734\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 122  Current D cost: 1.1898752153056205  Current G cost:  0.6303490216082734\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 123  Current D cost: 1.173503860714733  Current G cost:  0.6259259357202978\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 124  Current D cost: 1.1854434571789356  Current G cost:  0.6259259357202978\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 125  Current D cost: 1.1699450377213516  Current G cost:  0.6259259357202978\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 126  Current D cost: 1.156808890859908  Current G cost:  0.6288302514236497\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 127  Current D cost: 1.1464556144356775  Current G cost:  0.6288302514236497\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 128  Current D cost: 1.141958493357936  Current G cost:  0.6288302514236497\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 129  Current D cost: 1.1420490447040526  Current G cost:  0.6217146255134827\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 130  Current D cost: 1.120265478759785  Current G cost:  0.6217146255134827\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 131  Current D cost: 1.1188057006173842  Current G cost:  0.6217146255134827\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 132  Current D cost: 1.1071913635869894  Current G cost:  0.6196321187387682\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 133  Current D cost: 1.102134161155236  Current G cost:  0.6196321187387682\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 134  Current D cost: 1.0976584943214105  Current G cost:  0.6196321187387682\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 135  Current D cost: 1.0900473894884914  Current G cost:  0.615743261582645\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 136  Current D cost: 1.0767382628183422  Current G cost:  0.615743261582645\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 137  Current D cost: 1.0718188823840673  Current G cost:  0.615743261582645\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 138  Current D cost: 1.0709784077263111  Current G cost:  0.6133237097129871\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 139  Current D cost: 1.0641001617269237  Current G cost:  0.6133237097129871\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 140  Current D cost: 1.0401767942292879  Current G cost:  0.6133237097129871\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 141  Current D cost: 1.0479754109912527  Current G cost:  0.6075165591850373\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 142  Current D cost: 1.0434784336749625  Current G cost:  0.6075165591850373\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 143  Current D cost: 1.0261589333199752  Current G cost:  0.6075165591850373\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 144  Current D cost: 1.0280084321763687  Current G cost:  0.6087551832989957\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 145  Current D cost: 1.0097483737808426  Current G cost:  0.6087551832989957\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 146  Current D cost: 1.0144350485946592  Current G cost:  0.6087551832989957\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 147  Current D cost: 0.9882859085505009  Current G cost:  0.6192070625340992\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 148  Current D cost: 0.9895040836824045  Current G cost:  0.6192070625340992\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 149  Current D cost: 0.9855275665010501  Current G cost:  0.6192070625340992\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 150  Current D cost: 0.9665812969521365  Current G cost:  0.6067969294261961\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 151  Current D cost: 0.9826857234174793  Current G cost:  0.6067969294261961\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 152  Current D cost: 0.9635519892472892  Current G cost:  0.6067969294261961\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 153  Current D cost: 0.9603786656637725  Current G cost:  0.6000395130190144\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 154  Current D cost: 0.9457207867614489  Current G cost:  0.6000395130190144\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 155  Current D cost: 0.9380392893635314  Current G cost:  0.6000395130190144\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 156  Current D cost: 0.9296673609718714  Current G cost:  0.6095760954870337\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 157  Current D cost: 0.9528198322842851  Current G cost:  0.6095760954870337\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 158  Current D cost: 0.9058347575020949  Current G cost:  0.6095760954870337\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 159  Current D cost: 0.9257231659663018  Current G cost:  0.5996175478650323\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 160  Current D cost: 0.9274872068089548  Current G cost:  0.5996175478650323\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 161  Current D cost: 0.9232804161216477  Current G cost:  0.5996175478650323\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 162  Current D cost: 0.9015532522813479  Current G cost:  0.5879937614732812\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 163  Current D cost: 0.9115148367138852  Current G cost:  0.5879937614732812\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 164  Current D cost: 0.9004793019089238  Current G cost:  0.5879937614732812\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 165  Current D cost: 0.8967584745863406  Current G cost:  0.591560164575118\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 166  Current D cost: 0.9018152149374437  Current G cost:  0.591560164575118\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 167  Current D cost: 0.8812323523949805  Current G cost:  0.591560164575118\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 168  Current D cost: 0.8933874268319042  Current G cost:  0.5894828650952327\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 169  Current D cost: 0.8720988578288748  Current G cost:  0.5894828650952327\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 170  Current D cost: 0.8831492899165605  Current G cost:  0.5894828650952327\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 171  Current D cost: 0.8683837203691401  Current G cost:  0.596203601705003\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 172  Current D cost: 0.8658961294040294  Current G cost:  0.596203601705003\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 173  Current D cost: 0.8573006064275106  Current G cost:  0.596203601705003\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 174  Current D cost: 0.8597009877591351  Current G cost:  0.5880482588276014\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 175  Current D cost: 0.8449526139110861  Current G cost:  0.5880482588276014\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 176  Current D cost: 0.8639388530860055  Current G cost:  0.5880482588276014\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 177  Current D cost: 0.8581778107280471  Current G cost:  0.5865458444556054\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 178  Current D cost: 0.8462427295724142  Current G cost:  0.5865458444556054\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 179  Current D cost: 0.8652998751857043  Current G cost:  0.5865458444556054\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 180  Current D cost: 0.8540095298287066  Current G cost:  0.5901022697182574\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 181  Current D cost: 0.8634944955998692  Current G cost:  0.5901022697182574\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 182  Current D cost: 0.8451764344886397  Current G cost:  0.5901022697182574\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 183  Current D cost: 0.8386649864949834  Current G cost:  0.5667515322398438\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 184  Current D cost: 0.853878534811132  Current G cost:  0.5667515322398438\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 185  Current D cost: 0.8701069588615289  Current G cost:  0.5667515322398438\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 186  Current D cost: 0.8391225206130866  Current G cost:  0.5745126863482142\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 187  Current D cost: 0.8434332449079148  Current G cost:  0.5745126863482142\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 188  Current D cost: 0.8471709372735015  Current G cost:  0.5745126863482142\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 189  Current D cost: 0.835187366837365  Current G cost:  0.5772542631130994\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 190  Current D cost: 0.8165071870213273  Current G cost:  0.5772542631130994\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 191  Current D cost: 0.842298209363803  Current G cost:  0.5772542631130994\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 192  Current D cost: 0.8493897654885512  Current G cost:  0.5867325541733441\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 193  Current D cost: 0.8461294672788933  Current G cost:  0.5867325541733441\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 194  Current D cost: 0.8304261604230403  Current G cost:  0.5867325541733441\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 195  Current D cost: 0.8305389640908545  Current G cost:  0.574965990673988\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 196  Current D cost: 0.838290618964881  Current G cost:  0.574965990673988\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 197  Current D cost: 0.8292225035405221  Current G cost:  0.574965990673988\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 198  Current D cost: 0.8302366575808469  Current G cost:  0.5810036980763785\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 199  Current D cost: 0.8051694946960383  Current G cost:  0.5810036980763785\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 200  Current D cost: 0.858311634563883  Current G cost:  0.5810036980763785\n",
            "16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAADnCAYAAABv/o9IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 201  Current D cost: 0.823584384909364  Current G cost:  0.5966345195459277\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 202  Current D cost: 0.837056530581377  Current G cost:  0.5966345195459277\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 203  Current D cost: 0.8305492184481972  Current G cost:  0.5966345195459277\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 204  Current D cost: 0.8324202485441299  Current G cost:  0.5646472706144954\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 205  Current D cost: 0.8446547383656617  Current G cost:  0.5646472706144954\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 206  Current D cost: 0.8508825483896314  Current G cost:  0.5646472706144954\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 207  Current D cost: 0.8716166658560709  Current G cost:  0.5736682492738514\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 208  Current D cost: 0.829488141217912  Current G cost:  0.5736682492738514\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 209  Current D cost: 0.8487434956187676  Current G cost:  0.5736682492738514\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 210  Current D cost: 0.8296736154957024  Current G cost:  0.5556608936073535\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 211  Current D cost: 0.854217235937528  Current G cost:  0.5556608936073535\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 212  Current D cost: 0.8542484909726381  Current G cost:  0.5556608936073535\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 213  Current D cost: 0.8487187187624268  Current G cost:  0.5745320597967161\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 214  Current D cost: 0.8396920501701732  Current G cost:  0.5745320597967161\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 215  Current D cost: 0.8559257904235562  Current G cost:  0.5745320597967161\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 216  Current D cost: 0.8482530043547718  Current G cost:  0.5588932633908064\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 217  Current D cost: 0.8665836645243614  Current G cost:  0.5588932633908064\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 218  Current D cost: 0.8207970744848623  Current G cost:  0.5588932633908064\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 219  Current D cost: 0.8717754486882986  Current G cost:  0.5630767262692942\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 220  Current D cost: 0.8443963948976824  Current G cost:  0.5630767262692942\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 221  Current D cost: 0.8553829096101546  Current G cost:  0.5630767262692942\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 222  Current D cost: 0.8545076129662157  Current G cost:  0.5530466791408548\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 223  Current D cost: 0.8610781988155677  Current G cost:  0.5530466791408548\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 224  Current D cost: 0.8625128882766909  Current G cost:  0.5530466791408548\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 225  Current D cost: 0.8748751418466599  Current G cost:  0.5518047063325863\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 226  Current D cost: 0.8721075346252708  Current G cost:  0.5518047063325863\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 227  Current D cost: 0.8807059580490462  Current G cost:  0.5518047063325863\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 228  Current D cost: 0.868983991612151  Current G cost:  0.5496146004303668\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 229  Current D cost: 0.8820515897817698  Current G cost:  0.5496146004303668\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 230  Current D cost: 0.8492544864538064  Current G cost:  0.5496146004303668\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 231  Current D cost: 0.8693712071913323  Current G cost:  0.5451807764890035\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 232  Current D cost: 0.8488825383221703  Current G cost:  0.5451807764890035\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 233  Current D cost: 0.8740212459673871  Current G cost:  0.5451807764890035\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 234  Current D cost: 0.8611808184013052  Current G cost:  0.5586687256312012\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 235  Current D cost: 0.8775271591139486  Current G cost:  0.5586687256312012\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 236  Current D cost: 0.8701947227324849  Current G cost:  0.5586687256312012\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 237  Current D cost: 0.8585141679677157  Current G cost:  0.5295504164416076\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 238  Current D cost: 0.8491955655467581  Current G cost:  0.5295504164416076\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 239  Current D cost: 0.8803258159676148  Current G cost:  0.5295504164416076\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 240  Current D cost: 0.8607808686384675  Current G cost:  0.5384265519882157\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 241  Current D cost: 0.8686159431249647  Current G cost:  0.5384265519882157\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 242  Current D cost: 0.8868858024436002  Current G cost:  0.5384265519882157\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 243  Current D cost: 0.8654987199100055  Current G cost:  0.5365617971941837\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 244  Current D cost: 0.8682102551064612  Current G cost:  0.5365617971941837\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 245  Current D cost: 0.9058845283490794  Current G cost:  0.5365617971941837\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 246  Current D cost: 0.8662175844898488  Current G cost:  0.5322363476860614\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 247  Current D cost: 0.9031824402909094  Current G cost:  0.5322363476860614\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 248  Current D cost: 0.8611191859032172  Current G cost:  0.5322363476860614\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 249  Current D cost: 0.8331553344527534  Current G cost:  0.5495818472614731\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 250  Current D cost: 0.8473410771026937  Current G cost:  0.5495818472614731\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 251  Current D cost: 0.8901003102342236  Current G cost:  0.5495818472614731\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 252  Current D cost: 0.8807984044593704  Current G cost:  0.5346374710349868\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 253  Current D cost: 0.8841407318952783  Current G cost:  0.5346374710349868\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 254  Current D cost: 0.9090924012589575  Current G cost:  0.5346374710349868\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 255  Current D cost: 0.8714352709694316  Current G cost:  0.5364532477519726\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 256  Current D cost: 0.8700045292736235  Current G cost:  0.5364532477519726\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 257  Current D cost: 0.8887436032149085  Current G cost:  0.5364532477519726\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 258  Current D cost: 0.8802621977473435  Current G cost:  0.5215511396197474\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 259  Current D cost: 0.9058518872320711  Current G cost:  0.5215511396197474\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 260  Current D cost: 0.9107664471519614  Current G cost:  0.5215511396197474\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 261  Current D cost: 0.9071327241699636  Current G cost:  0.5443872995886192\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 262  Current D cost: 0.9223235127133771  Current G cost:  0.5443872995886192\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 263  Current D cost: 0.8906447762859121  Current G cost:  0.5443872995886192\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 264  Current D cost: 0.8844699630408834  Current G cost:  0.5251497483687375\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 265  Current D cost: 0.8742560964631397  Current G cost:  0.5251497483687375\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 266  Current D cost: 0.9161541032106434  Current G cost:  0.5251497483687375\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 267  Current D cost: 0.8732984973984863  Current G cost:  0.5179571073423932\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 268  Current D cost: 0.9363081459814038  Current G cost:  0.5179571073423932\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 269  Current D cost: 0.918941341024329  Current G cost:  0.5179571073423932\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 270  Current D cost: 0.9287764078147513  Current G cost:  0.5082626809114067\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 271  Current D cost: 0.9081191968670791  Current G cost:  0.5082626809114067\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 272  Current D cost: 0.9435867106011551  Current G cost:  0.5082626809114067\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 273  Current D cost: 0.894534403426863  Current G cost:  0.5142138432250516\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 274  Current D cost: 0.9067817845529427  Current G cost:  0.5142138432250516\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 275  Current D cost: 0.9151107876779043  Current G cost:  0.5142138432250516\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 276  Current D cost: 0.8867115452773571  Current G cost:  0.543469933403758\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 277  Current D cost: 0.9141803015007455  Current G cost:  0.543469933403758\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 278  Current D cost: 0.928126965707257  Current G cost:  0.543469933403758\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 279  Current D cost: 0.9309901865115118  Current G cost:  0.49963470672057864\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 280  Current D cost: 0.9301933072249137  Current G cost:  0.49963470672057864\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 281  Current D cost: 0.9284086311833839  Current G cost:  0.49963470672057864\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 282  Current D cost: 0.9117996653526877  Current G cost:  0.519885436062594\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 283  Current D cost: 0.8789193139103896  Current G cost:  0.519885436062594\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 284  Current D cost: 0.8956176467659809  Current G cost:  0.519885436062594\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 285  Current D cost: 0.927446968039128  Current G cost:  0.5054208668570659\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 286  Current D cost: 0.9202810979951681  Current G cost:  0.5054208668570659\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 287  Current D cost: 0.9390872962210932  Current G cost:  0.5054208668570659\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 288  Current D cost: 0.9261690375726499  Current G cost:  0.5128544451699764\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 289  Current D cost: 0.8910488265579318  Current G cost:  0.5128544451699764\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 290  Current D cost: 0.8751728549078945  Current G cost:  0.5128544451699764\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 291  Current D cost: 0.9029096154990759  Current G cost:  0.5175843154076826\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 292  Current D cost: 0.9371617911955461  Current G cost:  0.5175843154076826\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 293  Current D cost: 0.9189040140302707  Current G cost:  0.5175843154076826\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 294  Current D cost: 0.9436737803051403  Current G cost:  0.5182275364661302\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 295  Current D cost: 0.9723406983618018  Current G cost:  0.5182275364661302\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 296  Current D cost: 0.9134393425832609  Current G cost:  0.5182275364661302\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 297  Current D cost: 0.9567625175533286  Current G cost:  0.5064758675640327\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 298  Current D cost: 0.9059919416238149  Current G cost:  0.5064758675640327\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 299  Current D cost: 0.9477882756770255  Current G cost:  0.5064758675640327\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 300  Current D cost: 0.9303316525886332  Current G cost:  0.5047287656536246\n",
            "16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAADnCAYAAABv/o9IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAMxiAAIwiwEIwCwGIACzfgHDCcc+CLXhqQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 301  Current D cost: 0.9304705692626856  Current G cost:  0.5047287656536246\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 302  Current D cost: 0.8777560289537849  Current G cost:  0.5047287656536246\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 303  Current D cost: 0.8916928718050308  Current G cost:  0.5084719026987692\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 304  Current D cost: 0.9123535028689886  Current G cost:  0.5084719026987692\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 305  Current D cost: 0.9460324743234324  Current G cost:  0.5084719026987692\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 306  Current D cost: 0.9159924635814289  Current G cost:  0.5382858301935836\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 307  Current D cost: 0.9187281976168384  Current G cost:  0.5382858301935836\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 308  Current D cost: 0.9310116580022744  Current G cost:  0.5382858301935836\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 309  Current D cost: 0.9435960874985327  Current G cost:  0.5137485999109261\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 310  Current D cost: 0.9253821730848562  Current G cost:  0.5137485999109261\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 311  Current D cost: 0.9244237976651891  Current G cost:  0.5137485999109261\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 312  Current D cost: 0.9356073290524408  Current G cost:  0.5162444566024842\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 313  Current D cost: 0.9130616085733014  Current G cost:  0.5162444566024842\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 314  Current D cost: 0.9678341956386265  Current G cost:  0.5162444566024842\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 315  Current D cost: 0.9390877548157569  Current G cost:  0.5181149072945165\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 316  Current D cost: 0.9631405743069057  Current G cost:  0.5181149072945165\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 317  Current D cost: 0.9624303966561096  Current G cost:  0.5181149072945165\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 318  Current D cost: 0.9895478661318484  Current G cost:  0.48923498140210064\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 319  Current D cost: 0.9253099424722708  Current G cost:  0.48923498140210064\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 320  Current D cost: 0.9230354192461804  Current G cost:  0.48923498140210064\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 321  Current D cost: 0.934886105392412  Current G cost:  0.47983881221267\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 322  Current D cost: 0.9116611713985201  Current G cost:  0.47983881221267\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 323  Current D cost: 0.9739629343207679  Current G cost:  0.47983881221267\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 324  Current D cost: 0.9433977302516654  Current G cost:  0.4822678217556018\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 325  Current D cost: 0.934614675157784  Current G cost:  0.4822678217556018\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 326  Current D cost: 0.9646891900933205  Current G cost:  0.4822678217556018\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 327  Current D cost: 0.9480445060883238  Current G cost:  0.5170353377489583\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 328  Current D cost: 0.9299677249122861  Current G cost:  0.5170353377489583\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 329  Current D cost: 0.9146801710540191  Current G cost:  0.5170353377489583\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 330  Current D cost: 0.9703917287574043  Current G cost:  0.5131548633147563\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 331  Current D cost: 0.968282797075301  Current G cost:  0.5131548633147563\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 332  Current D cost: 0.9255852408841445  Current G cost:  0.5131548633147563\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 333  Current D cost: 0.9719146628511574  Current G cost:  0.5059944224333799\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 334  Current D cost: 0.9378767678885896  Current G cost:  0.5059944224333799\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 335  Current D cost: 0.9830145794685442  Current G cost:  0.5059944224333799\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 336  Current D cost: 0.9337926226834281  Current G cost:  0.5003224935261439\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 337  Current D cost: 0.9379901233172764  Current G cost:  0.5003224935261439\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 338  Current D cost: 0.9673736235538795  Current G cost:  0.5003224935261439\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 339  Current D cost: 0.9479889567512881  Current G cost:  0.4879473907837675\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 340  Current D cost: 0.940949243617768  Current G cost:  0.4879473907837675\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 341  Current D cost: 0.9794179393101571  Current G cost:  0.4879473907837675\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 342  Current D cost: 0.9479068698739077  Current G cost:  0.48541868024950907\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 343  Current D cost: 0.9789166425864373  Current G cost:  0.48541868024950907\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 344  Current D cost: 1.0010623727585184  Current G cost:  0.48541868024950907\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 345  Current D cost: 0.9964542658453596  Current G cost:  0.47044230338597204\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 346  Current D cost: 0.943178360357666  Current G cost:  0.47044230338597204\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 347  Current D cost: 0.9600634407699608  Current G cost:  0.47044230338597204\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 348  Current D cost: 0.9365928817093203  Current G cost:  0.48045751109817225\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 349  Current D cost: 0.9611141017399096  Current G cost:  0.48045751109817225\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 350  Current D cost: 0.9083127713275392  Current G cost:  0.48045751109817225\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 351  Current D cost: 0.9745202910834343  Current G cost:  0.48797944461196185\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 352  Current D cost: 0.9618015204548149  Current G cost:  0.48797944461196185\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 353  Current D cost: 0.9576923998477859  Current G cost:  0.48797944461196185\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 354  Current D cost: 0.961797262650498  Current G cost:  0.4792516971614915\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 355  Current D cost: 0.9850278659264069  Current G cost:  0.4792516971614915\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 356  Current D cost: 0.9499159959974846  Current G cost:  0.4792516971614915\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 357  Current D cost: 0.9916474541310649  Current G cost:  0.49572911815400167\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 358  Current D cost: 0.9516281371810589  Current G cost:  0.49572911815400167\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 359  Current D cost: 1.0298056676466925  Current G cost:  0.49572911815400167\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 360  Current D cost: 0.9903418053724289  Current G cost:  0.4822159975599754\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 361  Current D cost: 0.9847492343001075  Current G cost:  0.4822159975599754\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 362  Current D cost: 0.9810317282996799  Current G cost:  0.4822159975599754\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 363  Current D cost: 0.93176752407123  Current G cost:  0.4792481896697825\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 364  Current D cost: 0.959812043597569  Current G cost:  0.4792481896697825\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 365  Current D cost: 0.9544234968721252  Current G cost:  0.4792481896697825\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 366  Current D cost: 0.9232703559383246  Current G cost:  0.49267194879937115\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 367  Current D cost: 1.0096334431379264  Current G cost:  0.49267194879937115\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 368  Current D cost: 0.928854362993123  Current G cost:  0.49267194879937115\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 369  Current D cost: 0.946678790912099  Current G cost:  0.4831555659862633\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 370  Current D cost: 0.9993528956157154  Current G cost:  0.4831555659862633\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 371  Current D cost: 0.9462424624402095  Current G cost:  0.4831555659862633\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 372  Current D cost: 0.9546483507634324  Current G cost:  0.45573141259543787\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 373  Current D cost: 0.9843658364799639  Current G cost:  0.45573141259543787\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 374  Current D cost: 0.9530643682762752  Current G cost:  0.45573141259543787\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 375  Current D cost: 1.0192221572840063  Current G cost:  0.45468412445106876\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 376  Current D cost: 1.0109144326920871  Current G cost:  0.45468412445106876\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 377  Current D cost: 0.9491561158114262  Current G cost:  0.45468412445106876\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 378  Current D cost: 0.9811667004452633  Current G cost:  0.5042936342231072\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 379  Current D cost: 0.9582256482766867  Current G cost:  0.5042936342231072\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 380  Current D cost: 1.008039915233712  Current G cost:  0.5042936342231072\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 381  Current D cost: 0.9631765381656858  Current G cost:  0.46055721128975924\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 382  Current D cost: 0.9836950198221271  Current G cost:  0.46055721128975924\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 383  Current D cost: 0.9719568548467923  Current G cost:  0.46055721128975924\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 384  Current D cost: 1.0471022764067532  Current G cost:  0.46055163658289455\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 385  Current D cost: 0.9808447701473744  Current G cost:  0.46055163658289455\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 386  Current D cost: 0.9814212462764907  Current G cost:  0.46055163658289455\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 387  Current D cost: 0.9492498368906194  Current G cost:  0.4436696798282006\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 388  Current D cost: 1.0229215684297785  Current G cost:  0.4436696798282006\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 389  Current D cost: 0.9776759422133791  Current G cost:  0.4436696798282006\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 390  Current D cost: 0.9618055497973467  Current G cost:  0.48168216585163287\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 391  Current D cost: 1.0057009562282009  Current G cost:  0.48168216585163287\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 392  Current D cost: 0.9964067057834944  Current G cost:  0.48168216585163287\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 393  Current D cost: 1.0005000022797734  Current G cost:  0.4682412542068049\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 394  Current D cost: 1.0032725322180935  Current G cost:  0.4682412542068049\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 395  Current D cost: 0.9642143083614843  Current G cost:  0.4682412542068049\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 396  Current D cost: 0.966024554731544  Current G cost:  0.4804975741297999\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 397  Current D cost: 1.0272355631037458  Current G cost:  0.4804975741297999\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 398  Current D cost: 0.9707054656874374  Current G cost:  0.4804975741297999\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 399  Current D cost: 1.0432294068267514  Current G cost:  0.44071673569357295\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 400  Current D cost: 0.97664447078296  Current G cost:  0.44071673569357295\n",
            "16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAADnCAYAAABv/o9IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkGBhACSEBAsDICEkWBgACSHB8h9gmEU8ItWZKAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 401  Current D cost: 1.0023144137086695  Current G cost:  0.44071673569357295\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 402  Current D cost: 0.9852155060039924  Current G cost:  0.496076710695623\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 403  Current D cost: 0.9677597933986091  Current G cost:  0.496076710695623\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 404  Current D cost: 0.9930593480151771  Current G cost:  0.496076710695623\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 405  Current D cost: 1.0120155076834938  Current G cost:  0.47083143384541737\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 406  Current D cost: 1.0833138325876763  Current G cost:  0.47083143384541737\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 407  Current D cost: 0.9619132390080531  Current G cost:  0.47083143384541737\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 408  Current D cost: 0.9867568017170594  Current G cost:  0.46211184008326506\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 409  Current D cost: 1.016931442938271  Current G cost:  0.46211184008326506\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 410  Current D cost: 0.932939768274088  Current G cost:  0.46211184008326506\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 411  Current D cost: 0.9628073774570747  Current G cost:  0.4549395905173998\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 412  Current D cost: 0.9732522284223798  Current G cost:  0.4549395905173998\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 413  Current D cost: 0.9875882190029083  Current G cost:  0.4549395905173998\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 414  Current D cost: 0.9763354921420925  Current G cost:  0.4594103292601626\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 415  Current D cost: 0.9792864124056524  Current G cost:  0.4594103292601626\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 416  Current D cost: 0.9668465709796756  Current G cost:  0.4594103292601626\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 417  Current D cost: 0.92372424290564  Current G cost:  0.4623683328974667\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 418  Current D cost: 0.968508304879823  Current G cost:  0.4623683328974667\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 419  Current D cost: 0.962252714383241  Current G cost:  0.4623683328974667\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 420  Current D cost: 1.0091614694465263  Current G cost:  0.42030209646671246\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 421  Current D cost: 0.9951183302707197  Current G cost:  0.42030209646671246\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 422  Current D cost: 1.0272858775225695  Current G cost:  0.42030209646671246\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 423  Current D cost: 0.9917450063947079  Current G cost:  0.4915028100261194\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 424  Current D cost: 0.987931406632409  Current G cost:  0.4915028100261194\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 425  Current D cost: 1.0028934494174528  Current G cost:  0.4915028100261194\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 426  Current D cost: 0.9973110718258369  Current G cost:  0.4831130833876728\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 427  Current D cost: 1.0040968310428524  Current G cost:  0.4831130833876728\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 428  Current D cost: 1.0865313035339406  Current G cost:  0.4831130833876728\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 429  Current D cost: 1.0588457052774953  Current G cost:  0.43736381354077425\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 430  Current D cost: 1.0071125696231613  Current G cost:  0.43736381354077425\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 431  Current D cost: 0.9750768995425438  Current G cost:  0.43736381354077425\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 432  Current D cost: 1.003678849695071  Current G cost:  0.4534876983171212\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 433  Current D cost: 1.019070132799943  Current G cost:  0.4534876983171212\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 434  Current D cost: 0.9796047614415275  Current G cost:  0.4534876983171212\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 435  Current D cost: 0.9765514613917784  Current G cost:  0.456395200246972\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 436  Current D cost: 0.9761552163222575  Current G cost:  0.456395200246972\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 437  Current D cost: 1.0152833754128934  Current G cost:  0.456395200246972\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 438  Current D cost: 0.9963980156040633  Current G cost:  0.4694360583033212\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 439  Current D cost: 0.963707546710173  Current G cost:  0.4694360583033212\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 440  Current D cost: 0.9843778883342795  Current G cost:  0.4694360583033212\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 441  Current D cost: 0.9482019063774445  Current G cost:  0.4693995722017282\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 442  Current D cost: 1.0805659350691403  Current G cost:  0.4693995722017282\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 443  Current D cost: 1.0249644818960797  Current G cost:  0.4693995722017282\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 444  Current D cost: 1.0107498447917087  Current G cost:  0.47098495309921656\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 445  Current D cost: 0.9863264990471103  Current G cost:  0.47098495309921656\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 446  Current D cost: 0.9926640965332324  Current G cost:  0.47098495309921656\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 447  Current D cost: 1.0107275898830637  Current G cost:  0.49364123113707964\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 448  Current D cost: 0.9517323833476471  Current G cost:  0.49364123113707964\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 449  Current D cost: 0.9556439247724101  Current G cost:  0.49364123113707964\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 450  Current D cost: 1.0096562190738756  Current G cost:  0.4751395120894314\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 451  Current D cost: 0.9930827297201141  Current G cost:  0.4751395120894314\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 452  Current D cost: 1.0277378550571032  Current G cost:  0.4751395120894314\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 453  Current D cost: 0.9755253645374018  Current G cost:  0.4323391208513373\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 454  Current D cost: 1.0871278457723537  Current G cost:  0.4323391208513373\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 455  Current D cost: 0.9841533461708208  Current G cost:  0.4323391208513373\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 456  Current D cost: 0.9334794824519175  Current G cost:  0.48727516478318944\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 457  Current D cost: 0.9912179618417195  Current G cost:  0.48727516478318944\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 458  Current D cost: 0.979829080674641  Current G cost:  0.48727516478318944\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 459  Current D cost: 1.0220519766169187  Current G cost:  0.4737839024911583\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 460  Current D cost: 1.0469057905664503  Current G cost:  0.4737839024911583\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 461  Current D cost: 0.9952764606779552  Current G cost:  0.4737839024911583\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 462  Current D cost: 0.9873142146983563  Current G cost:  0.47773561899879813\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 463  Current D cost: 1.0365002738608917  Current G cost:  0.47773561899879813\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 464  Current D cost: 0.9725824293163221  Current G cost:  0.47773561899879813\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 465  Current D cost: 1.001890689458119  Current G cost:  0.4526184815129554\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 466  Current D cost: 1.0403386867978415  Current G cost:  0.4526184815129554\n",
            "stuff:  (128, 784)\n",
            "W4 before (346, 1)\n",
            "M$V$ (346, 1)\n",
            "W4 after (346, 1)\n",
            "Current Epoch:  1  Current Iter: 467  Current D cost: 1.0004666224129437  Current G cost:  0.4526184815129554\n",
            "stuff:  (128, 784)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-66adccaaacaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mInp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mDl1_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_W1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdupli_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_b1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mDl1_rA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDl1_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mDl2_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDl1_rA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_W2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdupli_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_b2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (96,128) (128,128) ",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: Current TensorFlow version is 2.2.0-rc2. To use TF 1.x instead,\nrestart your runtime (Ctrl+M .) and run \"%tensorflow_version 1.x\" before\nyou run \"import tensorflow\".\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FzrLFQvGIga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQmZ2XFXX890",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-949rVgZWeCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zYry6Fe6eL4m",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_59RtsZGIgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(5,7))\n",
        "plt.plot(forwardPropGen1, color = 'tab:blue', label = 'Forward Prop Gen 1')\n",
        "plt.plot(forwardPropDisc1,color = 'tab:green', label = 'Forward Prop Disc Real')\n",
        "plt.plot(forwardPropDisc2,color = 'tab:red', label = 'Forward Prop Disc Fake')\n",
        "plt.plot(gradientComputeDisc1,color = 'tab:gray', label = 'Gradient Discriminator Real')\n",
        "plt.plot(gradientComputeDisc2,color = 'tab:olive', label = 'Gradient Discriminator Real')\n",
        "plt.plot(backwardPropDisc,color = 'tab:pink', label = 'Backward Prop Disc')\n",
        "plt.plot(forwardPropGen2,color = 'tab:orange', label = 'Forward Prop Gen 2 (Train Gen)')\n",
        "plt.plot(forwardPropDisc3,color = 'tab:purple', label = 'Forward Prop Disc (Train Gen)')\n",
        "plt.plot(gradientComputeGen,color = 'tab:cyan', label = 'Gradient Compute Gen')\n",
        "plt.plot(backwardPropGen,color = 'tab:brown', label = 'Backward Prop Gen')\n",
        "plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Time in ms\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sub4goywbfRI",
        "colab": {}
      },
      "source": [
        "l=[]\n",
        "for i in range(15):\n",
        "    Z = np.random.normal(0., 1., size=[100, G_input])\n",
        "    Gl1 = Z.dot(G_W1) + G_b1\n",
        "    Gl1A = Lrelu(Gl1)\n",
        "    Gl2 = Gl1A.dot(G_W2) + G_b2\n",
        "    Gl2A = Lrelu(Gl2)\n",
        "    Gl3 = Gl2A.dot(G_W3) + G_b3\n",
        "    Gl3A = Lrelu(Gl3)\n",
        "    Gl4 = Gl3A.dot(G_W4) + G_b4\n",
        "    Gl4A = Lrelu(Gl4)\n",
        "    '''Gl5 = Gl4A.dot(G_W5) + G_b5\n",
        "    Gl5A = Lrelu(Gl5)\n",
        "    Gl6 = Gl5A.dot(G_W6) + G_b6\n",
        "    Gl6A = Lrelu(Gl6)\n",
        "    Gl7 = Gl6A.dot(G_W7) + G_b7\n",
        "    Gl7A = Lrelu(Gl7)\n",
        "    Gl8 = Gl7A.dot(G_W8) + G_b8\n",
        "    Gl8A = Lrelu(Gl8)\n",
        "    Gl9 = Gl8A.dot(G_W9) + G_b9\n",
        "    Gl9A = Lrelu(Gl9)\n",
        "    Gl10 = Gl9A.dot(G_W10) + G_b10\n",
        "    Gl10A = Lrelu(Gl10)'''\n",
        "    Gl11 = Gl4A.dot(G_W11) + G_b11\n",
        "    \n",
        "    current_fake_data = log(Gl11)\n",
        "    l.append(current_fake_data)\n",
        "\n",
        "fig = plot(l,\"TEST\")\n",
        "fig.savefig('Click_Me_{}.png'.format(str(iter).zfill(3)+\"_Ginput_\"+str(G_input)+ \"_hiddenone\"+str(hidden_input) + \"_hiddentwo\"+str(hidden_input2) + \"_LR_\" + str(learing_rate)), bbox_inches='tight')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FnpFQdTpbfRS",
        "colab": {}
      },
      "source": [
        "# This is currently not working. \n",
        "\n",
        "Z = np.random.normal(0., 1., size=[1, G_input])\n",
        "Gl1 = Z.dot(G_W1) + G_b1\n",
        "print(\"bias\", G_b1.shape)\n",
        "Gl1A = Lrelu(Gl1)\n",
        "Gl2 = Gl1A.dot(G_W2) + G_b2\n",
        "Gl2A = Lrelu(Gl2)\n",
        "Gl3 = Gl2A.dot(G_W3) + G_b3\n",
        "Gl3A = Lrelu(Gl3)\n",
        "Gl4 = Gl3A.dot(G_W4) + G_b4\n",
        "Gl4A = Lrelu(Gl4)\n",
        "'''Gl5 = Gl4A.dot(G_W5) + G_b5\n",
        "Gl5A = Lrelu(Gl5)\n",
        "Gl6 = Gl5A.dot(G_W6) + G_b6\n",
        "Gl6A = Lrelu(Gl6)\n",
        "Gl7 = Gl6A.dot(G_W7) + G_b7\n",
        "Gl7A = Lrelu(Gl7)\n",
        "Gl8 = Gl7A.dot(G_W8) + G_b8\n",
        "Gl8A = Lrelu(Gl8)\n",
        "Gl9 = Gl8A.dot(G_W9) + G_b9\n",
        "Gl9A = Lrelu(Gl9)\n",
        "Gl10 = Gl9A.dot(G_W10) + G_b10\n",
        "Gl10A = Lrelu(Gl10)'''\n",
        "Gl11 = Gl4A.dot(G_W11) + G_b11\n",
        "\n",
        "current_fake_data = log(Gl11)\n",
        "print(\"current_fake shape: \", current_fake_data.shape)\n",
        "\n",
        "Y = np.random.normal(0., 1., size=[1, G_input])\n",
        "Gl1 = Y.dot(G_W1) + G_b1\n",
        "Gl1A = Lrelu(Gl1)\n",
        "Gl2 = Gl1A.dot(G_W2) + G_b2\n",
        "Gl2A = Lrelu(Gl2)\n",
        "Gl3 = Gl2A.dot(G_W3) + G_b3\n",
        "Gl3A = Lrelu(Gl3)\n",
        "Gl4 = Gl3A.dot(G_W4) + G_b4\n",
        "Gl4A = Lrelu(Gl4)\n",
        "'''Gl5 = Gl4A.dot(G_W5) + G_b5\n",
        "Gl5A = Lrelu(Gl5)\n",
        "Gl6 = Gl5A.dot(G_W6) + G_b6\n",
        "Gl6A = Lrelu(Gl6)\n",
        "Gl7 = Gl6A.dot(G_W7) + G_b7\n",
        "Gl7A = Lrelu(Gl7)\n",
        "Gl8 = Gl7A.dot(G_W8) + G_b8\n",
        "Gl8A = Lrelu(Gl8)\n",
        "Gl9 = Gl8A.dot(G_W9) + G_b9\n",
        "Gl9A = Lrelu(Gl9)\n",
        "Gl10 = Gl9A.dot(G_W10) + G_b10\n",
        "Gl10A = Lrelu(Gl10)'''\n",
        "Gl11 = Gl4A.dot(G_W11) + G_b11\n",
        "\n",
        "s_data = log(Gl11)\n",
        "print(\"s_data shape: \", s_data.shape)\n",
        "print((s_data - current_fake_data).shape)\n",
        "fig = plot(s_data - current_fake_data,\"TEST\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RfjgFlc9bfRf",
        "colab": {}
      },
      "source": [
        "print((grad_r_w4_part_1 * grad_r_w4_part_2).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sXhuAW8zbfRs",
        "colab": {}
      },
      "source": [
        "print(len(l[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZA9tB9_2bfR2",
        "colab": {}
      },
      "source": [
        "plot([current_images],\"REAL\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "56R3Qb35bfSC",
        "colab": {}
      },
      "source": [
        "print(grad_r_w4_part_3.T.dot(grad_r_w4_part_1 * grad_r_w4_part_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4twoZKgvbfSk",
        "colab": {}
      },
      "source": [
        "    \n",
        "current_image = [np.expand_dims(images[i],axis=0) for i in range(50)]\n",
        "    \n",
        "current_images = np.vstack(current_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0b_-c-6TbfTC",
        "colab": {}
      },
      "source": [
        "print(grad_G_w11_part_2.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lGK_P4habfTp",
        "colab": {}
      },
      "source": [
        "len(current_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4KSfU_tGIh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3VPx9LnejKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rBatch.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJssxefyewd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Dl3_rA[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iG5V4Pve9L4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}