{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP6a76HPF4tzFyuzJNoLt7D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fluff18/ML/blob/master/WGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmwVgk3sVNJg",
        "colab_type": "code",
        "outputId": "dcadf0b7-8cc1-4db3-9b5b-617d8a64cdf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "from numpy import expand_dims\n",
        "from numpy import mean\n",
        "from numpy import ones\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.datasets.mnist import load_data\n",
        "from keras import backend\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.constraints import Constraint\n",
        "from matplotlib import pyplot\n",
        " \n",
        "# clip model weights to a given hypercube\n",
        "class ClipConstraint(Constraint):\n",
        "\t# set clip value when initialized\n",
        "\tdef __init__(self, clip_value):\n",
        "\t\tself.clip_value = clip_value\n",
        " \n",
        "\t# clip model weights to hypercube\n",
        "\tdef __call__(self, weights):\n",
        "\t\treturn backend.clip(weights, -self.clip_value, self.clip_value)\n",
        " \n",
        "\t# get the config\n",
        "\tdef get_config(self):\n",
        "\t\treturn {'clip_value': self.clip_value}\n",
        " \n",
        "# calculate wasserstein loss\n",
        "def wasserstein_loss(y_true, y_pred):\n",
        "\treturn backend.mean(y_true * y_pred)\n",
        " \n",
        "# define the standalone critic model\n",
        "def define_critic(in_shape=(28,28,1)):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# weight constraint\n",
        "\tconst = ClipConstraint(0.01)\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\t# downsample to 14x14\n",
        "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const, input_shape=in_shape))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# downsample to 7x7\n",
        "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# scoring, linear activation\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(1))\n",
        "\t# compile model\n",
        "\topt = RMSprop(lr=0.00005)\n",
        "\tmodel.compile(loss=wasserstein_loss, optimizer=opt)\n",
        "\treturn model\n",
        " \n",
        "# define the standalone generator model\n",
        "def define_generator(latent_dim):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\t# foundation for 7x7 image\n",
        "\tn_nodes = 128 * 7 * 7\n",
        "\tmodel.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Reshape((7, 7, 128)))\n",
        "\t# upsample to 14x14\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# upsample to 28x28\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# output 28x28x1\n",
        "\tmodel.add(Conv2D(1, (7,7), activation='tanh', padding='same', kernel_initializer=init))\n",
        "\treturn model\n",
        " \n",
        "# define the combined generator and critic model, for updating the generator\n",
        "def define_gan(generator, critic):\n",
        "\t# make weights in the critic not trainable\n",
        "\tcritic.trainable = False\n",
        "\t# connect them\n",
        "\tmodel = Sequential()\n",
        "\t# add generator\n",
        "\tmodel.add(generator)\n",
        "\t# add the critic\n",
        "\tmodel.add(critic)\n",
        "\t# compile model\n",
        "\topt = RMSprop(lr=0.00005)\n",
        "\tmodel.compile(loss=wasserstein_loss, optimizer=opt)\n",
        "\treturn model\n",
        " \n",
        "# load images\n",
        "def load_real_samples():\n",
        "\t# load dataset\n",
        "\t(trainX, trainy), (_, _) = load_data()\n",
        "\t# select all of the examples for a given class\n",
        "\tselected_ix = trainy == 7\n",
        "\tX = trainX[selected_ix]\n",
        "\t# expand to 3d, e.g. add channels\n",
        "\tX = expand_dims(X, axis=-1)\n",
        "\t# convert from ints to floats\n",
        "\tX = X.astype('float32')\n",
        "\t# scale from [0,255] to [-1,1]\n",
        "\tX = (X - 127.5) / 127.5\n",
        "\treturn X\n",
        " \n",
        "# select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\t# choose random instances\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\t# select images\n",
        "\tX = dataset[ix]\n",
        "\t# generate class labels, -1 for 'real'\n",
        "\ty = -ones((n_samples, 1))\n",
        "\treturn X, y\n",
        " \n",
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input\n",
        " \n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "\t# generate points in latent space\n",
        "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
        "\t# predict outputs\n",
        "\tX = generator.predict(x_input)\n",
        "\t# create class labels with 1.0 for 'fake'\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn X, y\n",
        " \n",
        "# generate samples and save as a plot and save the model\n",
        "def summarize_performance(step, g_model, latent_dim, n_samples=100):\n",
        "\t# prepare fake examples\n",
        "\tX, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "\t# scale from [-1,1] to [0,1]\n",
        "\tX = (X + 1) / 2.0\n",
        "\t# plot images\n",
        "\tfor i in range(10 * 10):\n",
        "\t\t# define subplot\n",
        "\t\tpyplot.subplot(10, 10, 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tpyplot.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
        "\t# save plot to file\n",
        "\tfilename1 = 'generated_plot_%04d.png' % (step+1)\n",
        "\tpyplot.savefig(filename1)\n",
        "\tpyplot.close()\n",
        "\t# save the generator model\n",
        "\tfilename2 = 'model_%04d.h5' % (step+1)\n",
        "\tg_model.save(filename2)\n",
        "\tprint('>Saved: %s and %s' % (filename1, filename2))\n",
        " \n",
        "# create a line plot of loss for the gan and save to file\n",
        "def plot_history(d1_hist, d2_hist, g_hist):\n",
        "\t# plot history\n",
        "\tpyplot.plot(d1_hist, label='crit_real')\n",
        "\tpyplot.plot(d2_hist, label='crit_fake')\n",
        "\tpyplot.plot(g_hist, label='gen')\n",
        "\tpyplot.legend()\n",
        "\tpyplot.savefig('plot_line_plot_loss.png')\n",
        "\tpyplot.close()\n",
        " \n",
        "# train the generator and critic\n",
        "def train(g_model, c_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=64, n_critic=5):\n",
        "\t# calculate the number of batches per training epoch\n",
        "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "\t# calculate the number of training iterations\n",
        "\tn_steps = bat_per_epo * n_epochs\n",
        "\t# calculate the size of half a batch of samples\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\t# lists for keeping track of loss\n",
        "\tc1_hist, c2_hist, g_hist = list(), list(), list()\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_steps):\n",
        "\t\t# update the critic more than the generator\n",
        "\t\tc1_tmp, c2_tmp = list(), list()\n",
        "\t\tfor _ in range(n_critic):\n",
        "\t\t\t# get randomly selected 'real' samples\n",
        "\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "\t\t\t# update critic model weights\n",
        "\t\t\tc_loss1 = c_model.train_on_batch(X_real, y_real)\n",
        "\t\t\tc1_tmp.append(c_loss1)\n",
        "\t\t\t# generate 'fake' examples\n",
        "\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\t\t# update critic model weights\n",
        "\t\t\tc_loss2 = c_model.train_on_batch(X_fake, y_fake)\n",
        "\t\t\tc2_tmp.append(c_loss2)\n",
        "\t\t# store critic loss\n",
        "\t\tc1_hist.append(mean(c1_tmp))\n",
        "\t\tc2_hist.append(mean(c2_tmp))\n",
        "\t\t# prepare points in latent space as input for the generator\n",
        "\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
        "\t\t# create inverted labels for the fake samples\n",
        "\t\ty_gan = -ones((n_batch, 1))\n",
        "\t\t# update the generator via the critic's error\n",
        "\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "\t\tg_hist.append(g_loss)\n",
        "\t\t# summarize loss on this batch\n",
        "\t\tprint('>%d, c1=%.3f, c2=%.3f g=%.3f' % (i+1, c1_hist[-1], c2_hist[-1], g_loss))\n",
        "\t\t# evaluate the model performance every 'epoch'\n",
        "\t\tif (i+1) % bat_per_epo == 0:\n",
        "\t\t\tsummarize_performance(i, g_model, latent_dim)\n",
        "\t# line plots of loss\n",
        "\tplot_history(c1_hist, c2_hist, g_hist)\n",
        " \n",
        "# size of the latent space\n",
        "latent_dim = 50\n",
        "# create the critic\n",
        "critic = define_critic()\n",
        "# create the generator\n",
        "generator = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(generator, critic)\n",
        "# load image data\n",
        "dataset = load_real_samples()\n",
        "print(dataset.shape)\n",
        "# train model\n",
        "train(generator, critic, gan_model, dataset, latent_dim)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "(6265, 28, 28, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">1, c1=-3.929, c2=0.068 g=-0.866\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">2, c1=-7.826, c2=1.231 g=-0.416\n",
            ">3, c1=-10.435, c2=1.010 g=-0.086\n",
            ">4, c1=-11.711, c2=0.987 g=-0.440\n",
            ">5, c1=-13.470, c2=0.979 g=-0.757\n",
            ">6, c1=-14.033, c2=0.887 g=-1.037\n",
            ">7, c1=-15.311, c2=1.205 g=-1.038\n",
            ">8, c1=-15.930, c2=0.960 g=-1.277\n",
            ">9, c1=-16.148, c2=0.862 g=-1.204\n",
            ">10, c1=-17.096, c2=0.671 g=-1.493\n",
            ">11, c1=-17.696, c2=0.905 g=-1.813\n",
            ">12, c1=-18.576, c2=0.952 g=-2.373\n",
            ">13, c1=-18.812, c2=0.836 g=-2.326\n",
            ">14, c1=-19.711, c2=0.674 g=-2.866\n",
            ">15, c1=-19.360, c2=0.785 g=-3.115\n",
            ">16, c1=-19.381, c2=0.577 g=-3.134\n",
            ">17, c1=-19.099, c2=0.560 g=-3.217\n",
            ">18, c1=-20.326, c2=0.069 g=-2.510\n",
            ">19, c1=-19.306, c2=0.132 g=-2.175\n",
            ">20, c1=-20.719, c2=-0.593 g=-1.451\n",
            ">21, c1=-20.289, c2=-0.736 g=-1.156\n",
            ">22, c1=-19.780, c2=-0.943 g=-0.574\n",
            ">23, c1=-20.679, c2=-1.599 g=0.298\n",
            ">24, c1=-20.135, c2=-1.875 g=1.168\n",
            ">25, c1=-19.931, c2=-2.431 g=2.055\n",
            ">26, c1=-20.971, c2=-2.562 g=2.485\n",
            ">27, c1=-20.373, c2=-2.764 g=3.167\n",
            ">28, c1=-20.501, c2=-3.438 g=3.767\n",
            ">29, c1=-20.675, c2=-3.257 g=4.276\n",
            ">30, c1=-20.964, c2=-3.609 g=4.296\n",
            ">31, c1=-21.161, c2=-3.840 g=4.527\n",
            ">32, c1=-20.844, c2=-3.774 g=4.176\n",
            ">33, c1=-21.785, c2=-3.640 g=3.761\n",
            ">34, c1=-21.127, c2=-3.448 g=3.411\n",
            ">35, c1=-21.796, c2=-3.783 g=3.192\n",
            ">36, c1=-21.639, c2=-4.162 g=3.149\n",
            ">37, c1=-22.218, c2=-4.481 g=3.617\n",
            ">38, c1=-21.848, c2=-4.539 g=4.107\n",
            ">39, c1=-21.447, c2=-4.801 g=4.749\n",
            ">40, c1=-21.646, c2=-5.636 g=5.323\n",
            ">41, c1=-22.541, c2=-5.582 g=5.836\n",
            ">42, c1=-22.125, c2=-5.973 g=6.388\n",
            ">43, c1=-23.317, c2=-6.760 g=7.321\n",
            ">44, c1=-22.149, c2=-7.336 g=8.035\n",
            ">45, c1=-22.773, c2=-6.997 g=7.902\n",
            ">46, c1=-23.055, c2=-7.725 g=8.174\n",
            ">47, c1=-22.596, c2=-7.534 g=8.465\n",
            ">48, c1=-22.712, c2=-7.704 g=8.517\n",
            ">49, c1=-22.534, c2=-8.012 g=9.230\n",
            ">50, c1=-22.692, c2=-8.965 g=9.975\n",
            ">51, c1=-22.964, c2=-8.871 g=9.134\n",
            ">52, c1=-23.129, c2=-8.950 g=9.139\n",
            ">53, c1=-23.209, c2=-8.806 g=9.115\n",
            ">54, c1=-22.975, c2=-8.531 g=8.663\n",
            ">55, c1=-24.104, c2=-9.525 g=8.908\n",
            ">56, c1=-23.250, c2=-9.808 g=8.817\n",
            ">57, c1=-25.177, c2=-10.070 g=9.449\n",
            ">58, c1=-23.739, c2=-9.502 g=9.723\n",
            ">59, c1=-24.034, c2=-10.032 g=10.058\n",
            ">60, c1=-24.475, c2=-10.563 g=9.903\n",
            ">61, c1=-23.687, c2=-10.014 g=9.681\n",
            ">62, c1=-23.734, c2=-12.160 g=9.004\n",
            ">63, c1=-24.256, c2=-11.336 g=10.601\n",
            ">64, c1=-25.361, c2=-11.859 g=11.060\n",
            ">65, c1=-23.895, c2=-11.517 g=11.666\n",
            ">66, c1=-25.057, c2=-11.598 g=11.144\n",
            ">67, c1=-24.978, c2=-12.363 g=10.849\n",
            ">68, c1=-24.075, c2=-12.146 g=9.815\n",
            ">69, c1=-26.212, c2=-13.691 g=9.529\n",
            ">70, c1=-25.391, c2=-13.725 g=10.425\n",
            ">71, c1=-24.641, c2=-12.263 g=10.531\n",
            ">72, c1=-25.511, c2=-11.875 g=10.650\n",
            ">73, c1=-26.014, c2=-12.436 g=11.428\n",
            ">74, c1=-25.252, c2=-13.349 g=10.670\n",
            ">75, c1=-25.683, c2=-14.443 g=9.934\n",
            ">76, c1=-27.374, c2=-14.456 g=9.603\n",
            ">77, c1=-26.026, c2=-15.528 g=7.944\n",
            ">78, c1=-26.232, c2=-15.669 g=10.567\n",
            ">79, c1=-26.934, c2=-14.180 g=8.772\n",
            ">80, c1=-26.324, c2=-13.027 g=10.350\n",
            ">81, c1=-27.430, c2=-15.023 g=9.795\n",
            ">82, c1=-26.980, c2=-14.849 g=12.163\n",
            ">83, c1=-27.466, c2=-14.278 g=10.720\n",
            ">84, c1=-26.742, c2=-14.793 g=14.344\n",
            ">85, c1=-25.971, c2=-16.097 g=11.969\n",
            ">86, c1=-27.005, c2=-15.781 g=13.880\n",
            ">87, c1=-26.893, c2=-16.462 g=15.712\n",
            ">88, c1=-26.983, c2=-15.693 g=14.974\n",
            ">89, c1=-27.108, c2=-17.087 g=13.752\n",
            ">90, c1=-27.922, c2=-17.804 g=16.061\n",
            ">91, c1=-27.404, c2=-17.578 g=15.463\n",
            ">92, c1=-27.874, c2=-19.251 g=16.655\n",
            ">93, c1=-27.459, c2=-16.077 g=19.070\n",
            ">94, c1=-27.801, c2=-16.945 g=17.321\n",
            ">95, c1=-25.787, c2=-17.104 g=21.648\n",
            ">96, c1=-26.788, c2=-19.322 g=18.275\n",
            ">97, c1=-27.540, c2=-19.545 g=19.050\n",
            ">Saved: generated_plot_0097.png and model_0097.h5\n",
            ">98, c1=-28.535, c2=-20.371 g=21.196\n",
            ">99, c1=-27.664, c2=-19.137 g=21.928\n",
            ">100, c1=-27.391, c2=-19.893 g=20.433\n",
            ">101, c1=-26.820, c2=-19.589 g=17.978\n",
            ">102, c1=-28.543, c2=-20.368 g=22.257\n",
            ">103, c1=-27.799, c2=-19.970 g=22.098\n",
            ">104, c1=-28.797, c2=-21.783 g=24.908\n",
            ">105, c1=-26.670, c2=-21.186 g=24.264\n",
            ">106, c1=-27.129, c2=-22.711 g=23.330\n",
            ">107, c1=-28.721, c2=-22.104 g=25.396\n",
            ">108, c1=-27.988, c2=-20.929 g=24.939\n",
            ">109, c1=-29.251, c2=-21.956 g=27.562\n",
            ">110, c1=-27.631, c2=-22.003 g=27.120\n",
            ">111, c1=-28.767, c2=-23.223 g=26.899\n",
            ">112, c1=-27.277, c2=-21.511 g=27.393\n",
            ">113, c1=-27.717, c2=-23.487 g=28.016\n",
            ">114, c1=-30.941, c2=-25.335 g=27.195\n",
            ">115, c1=-28.985, c2=-24.207 g=27.803\n",
            ">116, c1=-30.767, c2=-24.673 g=27.183\n",
            ">117, c1=-30.980, c2=-25.418 g=30.274\n",
            ">118, c1=-28.454, c2=-23.216 g=28.571\n",
            ">119, c1=-29.783, c2=-20.739 g=28.742\n",
            ">120, c1=-29.296, c2=-24.162 g=29.377\n",
            ">121, c1=-29.698, c2=-24.736 g=27.099\n",
            ">122, c1=-30.639, c2=-24.629 g=30.853\n",
            ">123, c1=-29.742, c2=-21.918 g=29.017\n",
            ">124, c1=-30.464, c2=-25.082 g=30.414\n",
            ">125, c1=-27.888, c2=-24.562 g=30.246\n",
            ">126, c1=-29.356, c2=-22.326 g=29.893\n",
            ">127, c1=-30.576, c2=-23.941 g=27.387\n",
            ">128, c1=-29.772, c2=-23.766 g=27.861\n",
            ">129, c1=-29.261, c2=-24.080 g=31.818\n",
            ">130, c1=-29.967, c2=-23.142 g=28.247\n",
            ">131, c1=-30.755, c2=-23.790 g=27.135\n",
            ">132, c1=-27.310, c2=-22.713 g=31.064\n",
            ">133, c1=-29.132, c2=-23.541 g=28.280\n",
            ">134, c1=-30.623, c2=-22.977 g=30.988\n",
            ">135, c1=-30.904, c2=-24.753 g=27.917\n",
            ">136, c1=-28.836, c2=-21.544 g=26.947\n",
            ">137, c1=-33.474, c2=-26.063 g=28.406\n",
            ">138, c1=-29.026, c2=-20.708 g=28.992\n",
            ">139, c1=-30.933, c2=-22.117 g=29.789\n",
            ">140, c1=-29.390, c2=-22.292 g=28.112\n",
            ">141, c1=-30.110, c2=-16.943 g=28.514\n",
            ">142, c1=-29.898, c2=-22.646 g=25.243\n",
            ">143, c1=-31.703, c2=-19.187 g=29.053\n",
            ">144, c1=-29.259, c2=-22.450 g=26.074\n",
            ">145, c1=-30.158, c2=-22.849 g=24.473\n",
            ">146, c1=-30.527, c2=-18.305 g=27.168\n",
            ">147, c1=-30.496, c2=-18.381 g=21.514\n",
            ">148, c1=-31.565, c2=-20.482 g=21.918\n",
            ">149, c1=-30.608, c2=-15.774 g=19.453\n",
            ">150, c1=-29.481, c2=-16.636 g=23.287\n",
            ">151, c1=-29.259, c2=-16.651 g=19.652\n",
            ">152, c1=-29.104, c2=-16.120 g=24.667\n",
            ">153, c1=-29.942, c2=-17.291 g=22.945\n",
            ">154, c1=-29.875, c2=-14.874 g=20.613\n",
            ">155, c1=-30.525, c2=-12.032 g=20.895\n",
            ">156, c1=-28.372, c2=-17.911 g=21.521\n",
            ">157, c1=-30.581, c2=-14.130 g=19.151\n",
            ">158, c1=-30.766, c2=-16.718 g=20.508\n",
            ">159, c1=-30.860, c2=-13.900 g=19.265\n",
            ">160, c1=-31.065, c2=-16.243 g=13.260\n",
            ">161, c1=-31.997, c2=-14.914 g=16.240\n",
            ">162, c1=-30.382, c2=-15.234 g=13.943\n",
            ">163, c1=-32.298, c2=-17.339 g=12.169\n",
            ">164, c1=-29.713, c2=-17.431 g=3.921\n",
            ">165, c1=-33.076, c2=-16.835 g=10.653\n",
            ">166, c1=-31.686, c2=-13.319 g=7.075\n",
            ">167, c1=-31.245, c2=-15.498 g=7.087\n",
            ">168, c1=-30.337, c2=-15.165 g=5.575\n",
            ">169, c1=-31.077, c2=-14.687 g=1.735\n",
            ">170, c1=-32.754, c2=-16.462 g=2.213\n",
            ">171, c1=-31.569, c2=-17.775 g=1.867\n",
            ">172, c1=-33.613, c2=-18.021 g=0.071\n",
            ">173, c1=-33.467, c2=-13.226 g=0.476\n",
            ">174, c1=-31.505, c2=-11.484 g=0.422\n",
            ">175, c1=-34.296, c2=-11.005 g=-3.318\n",
            ">176, c1=-31.105, c2=-9.450 g=-6.880\n",
            ">177, c1=-32.873, c2=-12.891 g=-3.449\n",
            ">178, c1=-32.225, c2=-14.599 g=-8.750\n",
            ">179, c1=-33.255, c2=-13.453 g=-9.029\n",
            ">180, c1=-33.808, c2=-11.272 g=-5.918\n",
            ">181, c1=-31.765, c2=-12.120 g=-8.154\n",
            ">182, c1=-32.389, c2=-8.418 g=-8.828\n",
            ">183, c1=-34.208, c2=-15.662 g=-14.531\n",
            ">184, c1=-34.341, c2=-13.264 g=-16.166\n",
            ">185, c1=-34.575, c2=-15.845 g=-14.599\n",
            ">186, c1=-34.582, c2=-11.990 g=-15.151\n",
            ">187, c1=-32.671, c2=-14.325 g=-19.316\n",
            ">188, c1=-34.754, c2=-6.600 g=-17.457\n",
            ">189, c1=-34.617, c2=-13.132 g=-22.766\n",
            ">190, c1=-32.630, c2=-19.572 g=-23.215\n",
            ">191, c1=-34.270, c2=-14.803 g=-24.098\n",
            ">192, c1=-37.464, c2=-12.911 g=-23.176\n",
            ">193, c1=-36.886, c2=-13.822 g=-24.077\n",
            ">194, c1=-38.397, c2=-14.443 g=-23.431\n",
            ">Saved: generated_plot_0194.png and model_0194.h5\n",
            ">195, c1=-36.276, c2=-9.272 g=-22.585\n",
            ">196, c1=-35.033, c2=-16.501 g=-27.642\n",
            ">197, c1=-35.436, c2=-12.152 g=-26.184\n",
            ">198, c1=-36.420, c2=-15.188 g=-27.296\n",
            ">199, c1=-36.443, c2=-13.119 g=-26.241\n",
            ">200, c1=-37.728, c2=-11.593 g=-30.124\n",
            ">201, c1=-36.718, c2=-12.497 g=-27.327\n",
            ">202, c1=-35.166, c2=-15.744 g=-32.512\n",
            ">203, c1=-34.900, c2=-9.625 g=-28.459\n",
            ">204, c1=-35.579, c2=-9.584 g=-30.954\n",
            ">205, c1=-36.469, c2=-6.935 g=-29.983\n",
            ">206, c1=-37.564, c2=-16.356 g=-35.160\n",
            ">207, c1=-37.094, c2=-9.686 g=-37.118\n",
            ">208, c1=-36.805, c2=-6.207 g=-35.427\n",
            ">209, c1=-38.562, c2=0.734 g=-35.961\n",
            ">210, c1=-38.384, c2=3.015 g=-36.512\n",
            ">211, c1=-37.034, c2=3.227 g=-38.834\n",
            ">212, c1=-36.904, c2=2.534 g=-37.465\n",
            ">213, c1=-34.315, c2=5.005 g=-36.161\n",
            ">214, c1=-40.268, c2=4.159 g=-33.715\n",
            ">215, c1=-36.769, c2=4.353 g=-33.107\n",
            ">216, c1=-40.236, c2=7.528 g=-31.136\n",
            ">217, c1=-36.667, c2=7.295 g=-31.784\n",
            ">218, c1=-38.608, c2=0.259 g=-31.358\n",
            ">219, c1=-41.099, c2=9.392 g=-34.462\n",
            ">220, c1=-41.701, c2=5.608 g=-33.357\n",
            ">221, c1=-40.895, c2=12.355 g=-31.675\n",
            ">222, c1=-40.665, c2=9.080 g=-32.239\n",
            ">223, c1=-40.435, c2=11.126 g=-33.958\n",
            ">224, c1=-41.159, c2=18.068 g=-31.902\n",
            ">225, c1=-43.515, c2=15.655 g=-32.618\n",
            ">226, c1=-43.465, c2=15.301 g=-32.151\n",
            ">227, c1=-43.514, c2=17.532 g=-34.387\n",
            ">228, c1=-47.520, c2=21.607 g=-30.839\n",
            ">229, c1=-48.484, c2=17.434 g=-30.597\n",
            ">230, c1=-46.135, c2=19.311 g=-30.326\n",
            ">231, c1=-49.131, c2=20.454 g=-26.542\n",
            ">232, c1=-48.501, c2=19.507 g=-26.179\n",
            ">233, c1=-50.879, c2=18.101 g=-26.470\n",
            ">234, c1=-49.527, c2=14.160 g=-22.466\n",
            ">235, c1=-50.997, c2=14.733 g=-18.484\n",
            ">236, c1=-52.078, c2=9.943 g=-16.523\n",
            ">237, c1=-51.389, c2=7.602 g=-15.432\n",
            ">238, c1=-53.753, c2=8.031 g=-11.913\n",
            ">239, c1=-55.029, c2=6.155 g=-11.941\n",
            ">240, c1=-55.551, c2=4.724 g=-11.584\n",
            ">241, c1=-54.588, c2=4.707 g=-9.592\n",
            ">242, c1=-59.102, c2=4.978 g=-7.292\n",
            ">243, c1=-57.311, c2=3.498 g=-5.152\n",
            ">244, c1=-58.972, c2=0.757 g=0.488\n",
            ">245, c1=-59.865, c2=-3.281 g=4.993\n",
            ">246, c1=-61.386, c2=-7.809 g=10.436\n",
            ">247, c1=-63.768, c2=-13.574 g=15.627\n",
            ">248, c1=-65.536, c2=-19.566 g=22.567\n",
            ">249, c1=-66.010, c2=-24.528 g=28.110\n",
            ">250, c1=-69.025, c2=-30.406 g=36.570\n",
            ">251, c1=-68.655, c2=-36.330 g=42.927\n",
            ">252, c1=-69.223, c2=-42.096 g=48.255\n",
            ">253, c1=-69.425, c2=-48.019 g=55.944\n",
            ">254, c1=-69.626, c2=-53.858 g=60.743\n",
            ">255, c1=-70.682, c2=-58.415 g=67.349\n",
            ">256, c1=-71.978, c2=-62.180 g=71.412\n",
            ">257, c1=-72.532, c2=-65.295 g=76.665\n",
            ">258, c1=-73.989, c2=-68.788 g=78.687\n",
            ">259, c1=-74.256, c2=-71.695 g=82.603\n",
            ">260, c1=-76.122, c2=-74.053 g=83.302\n",
            ">261, c1=-78.176, c2=-75.903 g=87.192\n",
            ">262, c1=-76.796, c2=-77.095 g=88.490\n",
            ">263, c1=-78.764, c2=-78.521 g=91.832\n",
            ">264, c1=-80.446, c2=-79.964 g=92.479\n",
            ">265, c1=-79.007, c2=-79.093 g=92.749\n",
            ">266, c1=-78.892, c2=-77.517 g=92.856\n",
            ">267, c1=-79.811, c2=-80.934 g=93.951\n",
            ">268, c1=-79.771, c2=-78.196 g=94.312\n",
            ">269, c1=-78.485, c2=-80.549 g=95.371\n",
            ">270, c1=-80.809, c2=-83.907 g=94.281\n",
            ">271, c1=-81.251, c2=-82.038 g=95.557\n",
            ">272, c1=-83.866, c2=-84.336 g=96.653\n",
            ">273, c1=-83.058, c2=-86.534 g=96.031\n",
            ">274, c1=-83.574, c2=-88.817 g=97.791\n",
            ">275, c1=-86.492, c2=-90.653 g=96.368\n",
            ">276, c1=-86.811, c2=-92.737 g=99.070\n",
            ">277, c1=-89.000, c2=-95.179 g=99.214\n",
            ">278, c1=-89.645, c2=-96.379 g=98.949\n",
            ">279, c1=-90.436, c2=-97.311 g=99.599\n",
            ">280, c1=-91.736, c2=-99.685 g=101.131\n",
            ">281, c1=-93.735, c2=-102.943 g=102.051\n",
            ">282, c1=-94.000, c2=-101.980 g=102.719\n",
            ">283, c1=-96.459, c2=-105.969 g=105.216\n",
            ">284, c1=-95.904, c2=-104.962 g=104.795\n",
            ">285, c1=-97.317, c2=-106.838 g=105.864\n",
            ">286, c1=-100.038, c2=-108.344 g=107.776\n",
            ">287, c1=-100.637, c2=-110.793 g=109.480\n",
            ">288, c1=-100.683, c2=-112.650 g=111.662\n",
            ">289, c1=-102.794, c2=-115.333 g=112.005\n",
            ">290, c1=-104.074, c2=-115.609 g=113.638\n",
            ">291, c1=-106.001, c2=-118.255 g=116.531\n",
            ">Saved: generated_plot_0291.png and model_0291.h5\n",
            ">292, c1=-106.419, c2=-120.115 g=117.795\n",
            ">293, c1=-106.803, c2=-122.637 g=118.154\n",
            ">294, c1=-107.046, c2=-123.792 g=122.237\n",
            ">295, c1=-108.656, c2=-124.243 g=121.681\n",
            ">296, c1=-110.035, c2=-126.701 g=124.829\n",
            ">297, c1=-111.406, c2=-128.990 g=126.978\n",
            ">298, c1=-112.773, c2=-131.598 g=127.735\n",
            ">299, c1=-112.866, c2=-133.500 g=130.347\n",
            ">300, c1=-114.546, c2=-135.506 g=132.867\n",
            ">301, c1=-117.974, c2=-136.482 g=134.677\n",
            ">302, c1=-118.385, c2=-139.360 g=135.804\n",
            ">303, c1=-118.908, c2=-140.209 g=138.746\n",
            ">304, c1=-120.282, c2=-141.185 g=139.530\n",
            ">305, c1=-121.176, c2=-142.767 g=141.565\n",
            ">306, c1=-123.360, c2=-144.280 g=143.682\n",
            ">307, c1=-124.018, c2=-145.406 g=145.979\n",
            ">308, c1=-124.657, c2=-147.768 g=147.581\n",
            ">309, c1=-127.320, c2=-148.864 g=150.124\n",
            ">310, c1=-127.171, c2=-149.418 g=150.763\n",
            ">311, c1=-129.981, c2=-150.805 g=152.847\n",
            ">312, c1=-130.295, c2=-152.237 g=154.324\n",
            ">313, c1=-132.070, c2=-153.273 g=155.527\n",
            ">314, c1=-133.909, c2=-154.922 g=157.376\n",
            ">315, c1=-134.763, c2=-156.117 g=157.852\n",
            ">316, c1=-135.589, c2=-157.926 g=160.238\n",
            ">317, c1=-135.464, c2=-158.943 g=161.647\n",
            ">318, c1=-138.087, c2=-160.022 g=162.293\n",
            ">319, c1=-138.392, c2=-160.711 g=163.111\n",
            ">320, c1=-138.857, c2=-161.941 g=164.961\n",
            ">321, c1=-140.756, c2=-161.738 g=165.053\n",
            ">322, c1=-141.779, c2=-162.193 g=165.954\n",
            ">323, c1=-143.122, c2=-160.767 g=165.546\n",
            ">324, c1=-142.783, c2=-159.487 g=165.513\n",
            ">325, c1=-143.404, c2=-160.008 g=166.057\n",
            ">326, c1=-144.899, c2=-160.799 g=166.413\n",
            ">327, c1=-145.549, c2=-160.126 g=166.689\n",
            ">328, c1=-146.267, c2=-158.490 g=165.375\n",
            ">329, c1=-146.660, c2=-156.064 g=165.180\n",
            ">330, c1=-147.365, c2=-157.748 g=165.031\n",
            ">331, c1=-148.834, c2=-159.249 g=165.381\n",
            ">332, c1=-148.331, c2=-161.758 g=165.936\n",
            ">333, c1=-148.510, c2=-164.113 g=167.457\n",
            ">334, c1=-149.810, c2=-163.469 g=166.698\n",
            ">335, c1=-150.391, c2=-159.670 g=162.218\n",
            ">336, c1=-150.233, c2=-149.278 g=158.856\n",
            ">337, c1=-150.569, c2=-146.618 g=155.150\n",
            ">338, c1=-149.720, c2=-146.432 g=155.344\n",
            ">339, c1=-149.825, c2=-148.881 g=155.602\n",
            ">340, c1=-150.540, c2=-150.599 g=157.779\n",
            ">341, c1=-149.299, c2=-154.561 g=159.929\n",
            ">342, c1=-150.241, c2=-157.278 g=161.555\n",
            ">343, c1=-150.285, c2=-159.104 g=163.373\n",
            ">344, c1=-151.204, c2=-161.520 g=165.506\n",
            ">345, c1=-151.956, c2=-162.680 g=167.523\n",
            ">346, c1=-152.775, c2=-165.015 g=167.424\n",
            ">347, c1=-153.498, c2=-165.644 g=169.399\n",
            ">348, c1=-154.298, c2=-166.235 g=170.588\n",
            ">349, c1=-155.127, c2=-167.712 g=171.878\n",
            ">350, c1=-155.229, c2=-167.701 g=172.167\n",
            ">351, c1=-155.787, c2=-167.384 g=173.565\n",
            ">352, c1=-156.553, c2=-166.334 g=173.363\n",
            ">353, c1=-154.977, c2=-164.786 g=173.866\n",
            ">354, c1=-156.184, c2=-164.709 g=174.414\n",
            ">355, c1=-155.815, c2=-161.105 g=173.691\n",
            ">356, c1=-153.797, c2=-158.491 g=174.155\n",
            ">357, c1=-153.223, c2=-155.142 g=174.203\n",
            ">358, c1=-151.869, c2=-147.701 g=170.445\n",
            ">359, c1=-150.277, c2=-139.960 g=167.838\n",
            ">360, c1=-146.816, c2=-133.439 g=164.065\n",
            ">361, c1=-146.080, c2=-129.439 g=160.026\n",
            ">362, c1=-144.175, c2=-127.959 g=158.257\n",
            ">363, c1=-142.311, c2=-125.983 g=157.007\n",
            ">364, c1=-141.756, c2=-134.127 g=158.274\n",
            ">365, c1=-141.949, c2=-125.279 g=159.602\n",
            ">366, c1=-135.957, c2=-105.305 g=154.870\n",
            ">367, c1=-129.465, c2=-78.880 g=146.190\n",
            ">368, c1=-122.073, c2=-53.995 g=132.423\n",
            ">369, c1=-117.401, c2=-46.230 g=116.148\n",
            ">370, c1=-109.231, c2=-7.797 g=88.661\n",
            ">371, c1=-112.959, c2=-1.835 g=64.279\n",
            ">372, c1=-107.125, c2=35.773 g=28.416\n",
            ">373, c1=-110.497, c2=83.761 g=-19.174\n",
            ">374, c1=-119.472, c2=86.939 g=-53.380\n",
            ">375, c1=-118.854, c2=92.747 g=-77.138\n",
            ">376, c1=-121.421, c2=94.745 g=-78.224\n",
            ">377, c1=-119.908, c2=93.566 g=-78.216\n",
            ">378, c1=-119.877, c2=92.481 g=-73.463\n",
            ">379, c1=-120.516, c2=91.584 g=-79.712\n",
            ">380, c1=-116.225, c2=86.522 g=-75.128\n",
            ">381, c1=-114.211, c2=85.995 g=-77.613\n",
            ">382, c1=-113.606, c2=80.731 g=-76.291\n",
            ">383, c1=-112.472, c2=79.755 g=-71.061\n",
            ">384, c1=-112.163, c2=74.558 g=-71.501\n",
            ">385, c1=-110.123, c2=77.257 g=-75.941\n",
            ">386, c1=-106.911, c2=75.963 g=-74.779\n",
            ">387, c1=-107.418, c2=74.102 g=-73.745\n",
            ">388, c1=-107.846, c2=73.291 g=-73.052\n",
            ">Saved: generated_plot_0388.png and model_0388.h5\n",
            ">389, c1=-105.553, c2=72.727 g=-70.075\n",
            ">390, c1=-104.602, c2=67.367 g=-74.187\n",
            ">391, c1=-103.552, c2=64.448 g=-71.827\n",
            ">392, c1=-101.023, c2=65.893 g=-74.766\n",
            ">393, c1=-101.885, c2=57.319 g=-66.472\n",
            ">394, c1=-98.954, c2=65.360 g=-70.538\n",
            ">395, c1=-96.450, c2=60.700 g=-65.007\n",
            ">396, c1=-95.315, c2=68.625 g=-70.485\n",
            ">397, c1=-97.038, c2=69.770 g=-72.654\n",
            ">398, c1=-95.858, c2=68.244 g=-73.586\n",
            ">399, c1=-94.012, c2=69.024 g=-73.539\n",
            ">400, c1=-90.892, c2=64.478 g=-72.847\n",
            ">401, c1=-93.348, c2=66.023 g=-70.028\n",
            ">402, c1=-92.950, c2=69.139 g=-72.190\n",
            ">403, c1=-94.889, c2=68.871 g=-67.284\n",
            ">404, c1=-98.055, c2=74.243 g=-70.509\n",
            ">405, c1=-94.293, c2=79.480 g=-68.595\n",
            ">406, c1=-98.108, c2=76.332 g=-70.741\n",
            ">407, c1=-95.855, c2=74.883 g=-68.195\n",
            ">408, c1=-97.550, c2=76.114 g=-66.504\n",
            ">409, c1=-95.132, c2=73.055 g=-68.495\n",
            ">410, c1=-93.637, c2=64.615 g=-62.907\n",
            ">411, c1=-95.878, c2=76.189 g=-72.022\n",
            ">412, c1=-95.084, c2=71.301 g=-68.388\n",
            ">413, c1=-92.020, c2=69.424 g=-71.552\n",
            ">414, c1=-86.419, c2=67.118 g=-67.879\n",
            ">415, c1=-87.626, c2=72.563 g=-72.652\n",
            ">416, c1=-92.374, c2=65.737 g=-66.928\n",
            ">417, c1=-91.322, c2=67.533 g=-73.162\n",
            ">418, c1=-89.606, c2=63.903 g=-64.584\n",
            ">419, c1=-89.551, c2=73.942 g=-69.288\n",
            ">420, c1=-89.991, c2=79.355 g=-69.832\n",
            ">421, c1=-92.602, c2=75.151 g=-73.527\n",
            ">422, c1=-93.426, c2=76.686 g=-70.344\n",
            ">423, c1=-94.590, c2=76.679 g=-75.519\n",
            ">424, c1=-91.528, c2=77.710 g=-66.662\n",
            ">425, c1=-92.170, c2=74.259 g=-65.736\n",
            ">426, c1=-92.464, c2=73.969 g=-67.099\n",
            ">427, c1=-93.180, c2=77.158 g=-68.014\n",
            ">428, c1=-90.936, c2=74.765 g=-66.796\n",
            ">429, c1=-89.407, c2=79.138 g=-72.435\n",
            ">430, c1=-92.502, c2=78.464 g=-68.256\n",
            ">431, c1=-94.233, c2=78.988 g=-67.220\n",
            ">432, c1=-93.657, c2=75.441 g=-62.423\n",
            ">433, c1=-91.461, c2=75.289 g=-64.646\n",
            ">434, c1=-90.794, c2=72.656 g=-66.040\n",
            ">435, c1=-91.439, c2=76.372 g=-71.689\n",
            ">436, c1=-91.688, c2=72.618 g=-61.497\n",
            ">437, c1=-91.430, c2=75.199 g=-57.676\n",
            ">438, c1=-91.061, c2=69.385 g=-61.753\n",
            ">439, c1=-90.111, c2=80.548 g=-62.474\n",
            ">440, c1=-89.764, c2=75.126 g=-64.490\n",
            ">441, c1=-92.442, c2=78.974 g=-61.312\n",
            ">442, c1=-90.396, c2=75.169 g=-61.547\n",
            ">443, c1=-88.871, c2=72.605 g=-60.980\n",
            ">444, c1=-91.954, c2=75.074 g=-66.535\n",
            ">445, c1=-92.539, c2=82.229 g=-67.559\n",
            ">446, c1=-86.776, c2=75.023 g=-64.622\n",
            ">447, c1=-94.488, c2=77.231 g=-65.589\n",
            ">448, c1=-92.674, c2=80.394 g=-61.958\n",
            ">449, c1=-91.992, c2=79.503 g=-67.703\n",
            ">450, c1=-91.395, c2=75.217 g=-62.094\n",
            ">451, c1=-91.430, c2=77.781 g=-63.404\n",
            ">452, c1=-90.034, c2=76.580 g=-58.692\n",
            ">453, c1=-90.423, c2=80.603 g=-64.742\n",
            ">454, c1=-89.949, c2=74.493 g=-57.103\n",
            ">455, c1=-90.152, c2=77.664 g=-56.172\n",
            ">456, c1=-90.098, c2=72.418 g=-54.755\n",
            ">457, c1=-88.632, c2=76.006 g=-60.821\n",
            ">458, c1=-89.183, c2=71.060 g=-61.549\n",
            ">459, c1=-87.980, c2=74.690 g=-49.535\n",
            ">460, c1=-85.743, c2=71.688 g=-57.621\n",
            ">461, c1=-85.474, c2=75.708 g=-57.505\n",
            ">462, c1=-87.157, c2=72.579 g=-55.366\n",
            ">463, c1=-89.452, c2=76.282 g=-60.856\n",
            ">464, c1=-83.817, c2=68.069 g=-57.419\n",
            ">465, c1=-84.999, c2=73.982 g=-57.648\n",
            ">466, c1=-87.148, c2=70.390 g=-60.550\n",
            ">467, c1=-86.018, c2=74.977 g=-53.712\n",
            ">468, c1=-84.519, c2=74.234 g=-56.843\n",
            ">469, c1=-85.024, c2=74.076 g=-58.149\n",
            ">470, c1=-83.435, c2=71.821 g=-54.335\n",
            ">471, c1=-84.486, c2=69.607 g=-52.783\n",
            ">472, c1=-84.462, c2=71.144 g=-56.052\n",
            ">473, c1=-83.915, c2=71.622 g=-58.184\n",
            ">474, c1=-85.311, c2=68.406 g=-54.833\n",
            ">475, c1=-83.957, c2=72.187 g=-54.951\n",
            ">476, c1=-83.620, c2=70.392 g=-60.240\n",
            ">477, c1=-84.542, c2=71.012 g=-53.636\n",
            ">478, c1=-80.623, c2=70.122 g=-59.438\n",
            ">479, c1=-82.968, c2=72.141 g=-50.714\n",
            ">480, c1=-78.946, c2=66.728 g=-51.266\n",
            ">481, c1=-80.502, c2=69.392 g=-51.967\n",
            ">482, c1=-81.354, c2=66.480 g=-47.228\n",
            ">483, c1=-81.927, c2=69.644 g=-54.000\n",
            ">484, c1=-81.631, c2=70.110 g=-58.657\n",
            ">485, c1=-79.715, c2=71.639 g=-48.990\n",
            ">Saved: generated_plot_0485.png and model_0485.h5\n",
            ">486, c1=-81.159, c2=66.570 g=-51.986\n",
            ">487, c1=-81.002, c2=70.914 g=-57.148\n",
            ">488, c1=-77.994, c2=68.772 g=-58.617\n",
            ">489, c1=-81.128, c2=70.776 g=-51.499\n",
            ">490, c1=-76.921, c2=66.563 g=-53.484\n",
            ">491, c1=-77.017, c2=68.122 g=-46.815\n",
            ">492, c1=-77.084, c2=65.618 g=-55.566\n",
            ">493, c1=-77.737, c2=67.994 g=-46.593\n",
            ">494, c1=-76.845, c2=66.097 g=-53.875\n",
            ">495, c1=-79.684, c2=69.877 g=-48.840\n",
            ">496, c1=-77.676, c2=66.278 g=-52.931\n",
            ">497, c1=-77.529, c2=67.409 g=-42.739\n",
            ">498, c1=-74.894, c2=63.651 g=-54.945\n",
            ">499, c1=-76.192, c2=66.458 g=-49.217\n",
            ">500, c1=-76.020, c2=64.080 g=-50.064\n",
            ">501, c1=-76.270, c2=62.654 g=-50.145\n",
            ">502, c1=-75.517, c2=65.154 g=-56.960\n",
            ">503, c1=-74.810, c2=65.064 g=-49.583\n",
            ">504, c1=-73.857, c2=60.609 g=-53.577\n",
            ">505, c1=-76.099, c2=68.051 g=-50.221\n",
            ">506, c1=-72.932, c2=63.063 g=-55.008\n",
            ">507, c1=-75.425, c2=65.857 g=-51.995\n",
            ">508, c1=-74.125, c2=57.786 g=-51.459\n",
            ">509, c1=-72.719, c2=63.918 g=-49.551\n",
            ">510, c1=-74.468, c2=62.283 g=-53.766\n",
            ">511, c1=-71.611, c2=65.109 g=-48.237\n",
            ">512, c1=-72.925, c2=59.129 g=-49.832\n",
            ">513, c1=-73.737, c2=61.524 g=-44.217\n",
            ">514, c1=-72.282, c2=59.375 g=-47.504\n",
            ">515, c1=-71.363, c2=61.630 g=-41.826\n",
            ">516, c1=-72.042, c2=61.406 g=-48.089\n",
            ">517, c1=-72.788, c2=62.105 g=-49.226\n",
            ">518, c1=-70.925, c2=56.421 g=-46.567\n",
            ">519, c1=-69.715, c2=60.450 g=-44.575\n",
            ">520, c1=-70.470, c2=55.130 g=-46.168\n",
            ">521, c1=-69.139, c2=58.074 g=-50.579\n",
            ">522, c1=-70.265, c2=56.313 g=-53.190\n",
            ">523, c1=-71.037, c2=59.551 g=-49.081\n",
            ">524, c1=-69.536, c2=57.025 g=-46.818\n",
            ">525, c1=-71.313, c2=58.991 g=-43.534\n",
            ">526, c1=-69.939, c2=57.487 g=-44.056\n",
            ">527, c1=-69.397, c2=59.260 g=-46.474\n",
            ">528, c1=-68.103, c2=54.363 g=-48.009\n",
            ">529, c1=-67.545, c2=56.605 g=-44.501\n",
            ">530, c1=-68.933, c2=53.819 g=-43.251\n",
            ">531, c1=-65.459, c2=53.461 g=-44.512\n",
            ">532, c1=-66.089, c2=55.508 g=-45.498\n",
            ">533, c1=-67.577, c2=55.396 g=-40.757\n",
            ">534, c1=-66.724, c2=52.399 g=-46.063\n",
            ">535, c1=-66.898, c2=54.980 g=-45.348\n",
            ">536, c1=-66.603, c2=50.247 g=-42.586\n",
            ">537, c1=-63.746, c2=53.095 g=-41.814\n",
            ">538, c1=-66.482, c2=54.478 g=-47.869\n",
            ">539, c1=-64.494, c2=55.257 g=-43.953\n",
            ">540, c1=-66.593, c2=50.849 g=-41.852\n",
            ">541, c1=-65.614, c2=50.668 g=-45.114\n",
            ">542, c1=-63.180, c2=51.201 g=-44.646\n",
            ">543, c1=-64.770, c2=51.352 g=-42.910\n",
            ">544, c1=-63.472, c2=45.555 g=-43.752\n",
            ">545, c1=-64.349, c2=49.973 g=-43.361\n",
            ">546, c1=-64.005, c2=49.218 g=-42.316\n",
            ">547, c1=-62.496, c2=54.580 g=-45.748\n",
            ">548, c1=-62.263, c2=48.464 g=-44.586\n",
            ">549, c1=-63.839, c2=48.927 g=-44.016\n",
            ">550, c1=-63.481, c2=45.036 g=-45.079\n",
            ">551, c1=-61.709, c2=48.734 g=-42.958\n",
            ">552, c1=-60.163, c2=45.428 g=-44.544\n",
            ">553, c1=-57.975, c2=46.759 g=-40.707\n",
            ">554, c1=-64.622, c2=46.414 g=-42.951\n",
            ">555, c1=-60.607, c2=43.819 g=-42.561\n",
            ">556, c1=-61.437, c2=41.098 g=-41.277\n",
            ">557, c1=-59.343, c2=44.619 g=-40.070\n",
            ">558, c1=-60.945, c2=43.275 g=-41.680\n",
            ">559, c1=-61.941, c2=44.627 g=-40.265\n",
            ">560, c1=-60.749, c2=43.895 g=-41.263\n",
            ">561, c1=-60.840, c2=42.488 g=-40.484\n",
            ">562, c1=-57.114, c2=43.314 g=-45.868\n",
            ">563, c1=-58.311, c2=45.546 g=-43.378\n",
            ">564, c1=-59.254, c2=47.024 g=-43.777\n",
            ">565, c1=-60.078, c2=49.120 g=-40.535\n",
            ">566, c1=-58.613, c2=45.300 g=-42.886\n",
            ">567, c1=-59.197, c2=47.221 g=-42.019\n",
            ">568, c1=-57.788, c2=42.507 g=-42.216\n",
            ">569, c1=-57.815, c2=42.321 g=-40.263\n",
            ">570, c1=-61.062, c2=40.814 g=-42.141\n",
            ">571, c1=-55.150, c2=40.133 g=-34.650\n",
            ">572, c1=-59.380, c2=38.263 g=-40.247\n",
            ">573, c1=-58.464, c2=45.398 g=-41.899\n",
            ">574, c1=-57.575, c2=39.921 g=-41.260\n",
            ">575, c1=-57.424, c2=44.928 g=-35.851\n",
            ">576, c1=-56.844, c2=40.688 g=-41.005\n",
            ">577, c1=-55.682, c2=44.279 g=-42.491\n",
            ">578, c1=-56.454, c2=44.456 g=-41.478\n",
            ">579, c1=-58.477, c2=42.857 g=-36.376\n",
            ">580, c1=-57.088, c2=39.701 g=-39.026\n",
            ">581, c1=-57.094, c2=42.433 g=-39.419\n",
            ">582, c1=-54.779, c2=41.796 g=-37.907\n",
            ">Saved: generated_plot_0582.png and model_0582.h5\n",
            ">583, c1=-58.846, c2=44.022 g=-35.117\n",
            ">584, c1=-54.761, c2=43.467 g=-39.943\n",
            ">585, c1=-55.628, c2=41.777 g=-39.061\n",
            ">586, c1=-52.195, c2=41.706 g=-35.241\n",
            ">587, c1=-57.352, c2=38.685 g=-39.076\n",
            ">588, c1=-55.214, c2=32.825 g=-38.454\n",
            ">589, c1=-53.315, c2=41.745 g=-30.700\n",
            ">590, c1=-54.357, c2=40.419 g=-35.377\n",
            ">591, c1=-56.832, c2=38.531 g=-33.314\n",
            ">592, c1=-54.654, c2=35.914 g=-39.246\n",
            ">593, c1=-56.195, c2=42.250 g=-36.269\n",
            ">594, c1=-52.621, c2=38.613 g=-35.804\n",
            ">595, c1=-55.629, c2=38.472 g=-35.484\n",
            ">596, c1=-54.467, c2=36.381 g=-35.031\n",
            ">597, c1=-51.867, c2=35.837 g=-35.176\n",
            ">598, c1=-51.900, c2=37.042 g=-36.399\n",
            ">599, c1=-54.604, c2=32.776 g=-36.415\n",
            ">600, c1=-54.059, c2=32.682 g=-34.724\n",
            ">601, c1=-52.141, c2=37.859 g=-37.743\n",
            ">602, c1=-51.191, c2=30.912 g=-32.201\n",
            ">603, c1=-53.652, c2=33.952 g=-35.581\n",
            ">604, c1=-53.337, c2=32.449 g=-38.321\n",
            ">605, c1=-52.870, c2=37.532 g=-31.684\n",
            ">606, c1=-49.688, c2=33.870 g=-34.299\n",
            ">607, c1=-55.386, c2=38.842 g=-39.994\n",
            ">608, c1=-53.998, c2=35.635 g=-33.699\n",
            ">609, c1=-54.678, c2=35.821 g=-34.220\n",
            ">610, c1=-50.949, c2=33.049 g=-36.072\n",
            ">611, c1=-53.284, c2=32.789 g=-38.932\n",
            ">612, c1=-48.047, c2=34.179 g=-37.539\n",
            ">613, c1=-51.303, c2=32.764 g=-33.126\n",
            ">614, c1=-50.715, c2=30.042 g=-36.336\n",
            ">615, c1=-51.540, c2=35.467 g=-32.506\n",
            ">616, c1=-51.474, c2=35.133 g=-39.682\n",
            ">617, c1=-52.927, c2=34.169 g=-40.304\n",
            ">618, c1=-52.580, c2=35.427 g=-36.275\n",
            ">619, c1=-50.184, c2=35.158 g=-28.954\n",
            ">620, c1=-52.426, c2=34.451 g=-34.841\n",
            ">621, c1=-52.648, c2=34.721 g=-28.522\n",
            ">622, c1=-51.449, c2=28.540 g=-37.903\n",
            ">623, c1=-49.864, c2=33.259 g=-35.834\n",
            ">624, c1=-55.373, c2=32.769 g=-40.491\n",
            ">625, c1=-51.253, c2=34.499 g=-36.066\n",
            ">626, c1=-52.205, c2=29.510 g=-37.137\n",
            ">627, c1=-52.680, c2=40.928 g=-31.859\n",
            ">628, c1=-50.697, c2=38.606 g=-34.352\n",
            ">629, c1=-49.037, c2=34.158 g=-32.853\n",
            ">630, c1=-52.467, c2=36.143 g=-38.590\n",
            ">631, c1=-48.503, c2=33.334 g=-37.982\n",
            ">632, c1=-51.261, c2=32.695 g=-37.613\n",
            ">633, c1=-53.422, c2=36.542 g=-34.764\n",
            ">634, c1=-49.294, c2=35.621 g=-36.408\n",
            ">635, c1=-51.911, c2=37.813 g=-38.041\n",
            ">636, c1=-47.777, c2=34.699 g=-39.409\n",
            ">637, c1=-51.201, c2=39.055 g=-32.520\n",
            ">638, c1=-51.988, c2=35.409 g=-30.424\n",
            ">639, c1=-51.097, c2=36.504 g=-34.081\n",
            ">640, c1=-48.166, c2=32.670 g=-33.307\n",
            ">641, c1=-50.584, c2=30.815 g=-32.860\n",
            ">642, c1=-47.968, c2=36.151 g=-35.588\n",
            ">643, c1=-49.952, c2=40.694 g=-35.008\n",
            ">644, c1=-51.753, c2=35.035 g=-33.979\n",
            ">645, c1=-48.012, c2=35.541 g=-31.927\n",
            ">646, c1=-48.788, c2=32.634 g=-33.114\n",
            ">647, c1=-49.247, c2=34.875 g=-28.497\n",
            ">648, c1=-49.380, c2=27.948 g=-30.261\n",
            ">649, c1=-49.116, c2=29.167 g=-27.028\n",
            ">650, c1=-49.202, c2=34.226 g=-35.561\n",
            ">651, c1=-50.848, c2=36.154 g=-31.262\n",
            ">652, c1=-46.645, c2=31.026 g=-28.803\n",
            ">653, c1=-48.438, c2=33.999 g=-31.235\n",
            ">654, c1=-48.283, c2=29.251 g=-28.786\n",
            ">655, c1=-48.761, c2=32.337 g=-29.629\n",
            ">656, c1=-49.393, c2=31.980 g=-32.976\n",
            ">657, c1=-48.627, c2=29.847 g=-23.805\n",
            ">658, c1=-47.996, c2=30.112 g=-33.338\n",
            ">659, c1=-51.517, c2=33.567 g=-28.981\n",
            ">660, c1=-48.495, c2=25.525 g=-32.046\n",
            ">661, c1=-47.506, c2=32.273 g=-31.153\n",
            ">662, c1=-50.001, c2=29.349 g=-32.140\n",
            ">663, c1=-46.746, c2=33.240 g=-30.868\n",
            ">664, c1=-46.636, c2=28.242 g=-31.190\n",
            ">665, c1=-44.043, c2=37.299 g=-25.452\n",
            ">666, c1=-52.168, c2=34.737 g=-30.335\n",
            ">667, c1=-47.735, c2=31.877 g=-28.670\n",
            ">668, c1=-46.936, c2=27.515 g=-29.213\n",
            ">669, c1=-49.050, c2=28.927 g=-31.963\n",
            ">670, c1=-47.260, c2=30.467 g=-29.744\n",
            ">671, c1=-44.616, c2=35.586 g=-23.274\n",
            ">672, c1=-47.761, c2=29.721 g=-24.421\n",
            ">673, c1=-48.344, c2=30.570 g=-29.580\n",
            ">674, c1=-47.372, c2=27.394 g=-28.208\n",
            ">675, c1=-49.563, c2=32.994 g=-34.559\n",
            ">676, c1=-46.886, c2=33.407 g=-28.705\n",
            ">677, c1=-47.741, c2=30.278 g=-28.350\n",
            ">678, c1=-43.483, c2=33.803 g=-26.220\n",
            ">679, c1=-47.403, c2=32.338 g=-22.184\n",
            ">Saved: generated_plot_0679.png and model_0679.h5\n",
            ">680, c1=-49.040, c2=26.050 g=-28.865\n",
            ">681, c1=-49.252, c2=33.905 g=-30.820\n",
            ">682, c1=-45.268, c2=31.961 g=-21.450\n",
            ">683, c1=-45.253, c2=31.425 g=-25.983\n",
            ">684, c1=-48.199, c2=30.310 g=-23.805\n",
            ">685, c1=-47.726, c2=33.642 g=-25.724\n",
            ">686, c1=-49.102, c2=30.750 g=-27.474\n",
            ">687, c1=-43.139, c2=33.995 g=-24.545\n",
            ">688, c1=-43.634, c2=29.860 g=-20.079\n",
            ">689, c1=-47.523, c2=35.346 g=-23.278\n",
            ">690, c1=-46.290, c2=24.475 g=-24.764\n",
            ">691, c1=-48.601, c2=28.803 g=-30.510\n",
            ">692, c1=-47.673, c2=37.067 g=-29.081\n",
            ">693, c1=-47.815, c2=36.154 g=-24.602\n",
            ">694, c1=-45.488, c2=27.906 g=-25.220\n",
            ">695, c1=-47.030, c2=30.623 g=-22.097\n",
            ">696, c1=-47.415, c2=29.585 g=-25.351\n",
            ">697, c1=-47.935, c2=32.902 g=-24.422\n",
            ">698, c1=-45.765, c2=29.401 g=-23.662\n",
            ">699, c1=-48.413, c2=31.807 g=-23.400\n",
            ">700, c1=-46.820, c2=31.575 g=-24.667\n",
            ">701, c1=-47.425, c2=36.108 g=-19.238\n",
            ">702, c1=-47.473, c2=35.793 g=-22.639\n",
            ">703, c1=-48.752, c2=33.201 g=-21.267\n",
            ">704, c1=-47.155, c2=34.928 g=-27.140\n",
            ">705, c1=-46.502, c2=36.812 g=-25.573\n",
            ">706, c1=-49.839, c2=34.083 g=-24.423\n",
            ">707, c1=-47.975, c2=35.252 g=-15.659\n",
            ">708, c1=-46.341, c2=28.464 g=-25.190\n",
            ">709, c1=-47.473, c2=30.476 g=-24.610\n",
            ">710, c1=-46.320, c2=31.622 g=-23.148\n",
            ">711, c1=-45.790, c2=32.418 g=-22.902\n",
            ">712, c1=-44.881, c2=30.119 g=-19.784\n",
            ">713, c1=-44.888, c2=29.801 g=-19.983\n",
            ">714, c1=-45.212, c2=27.901 g=-17.238\n",
            ">715, c1=-47.230, c2=29.084 g=-19.272\n",
            ">716, c1=-45.542, c2=29.449 g=-20.101\n",
            ">717, c1=-47.760, c2=30.515 g=-21.454\n",
            ">718, c1=-43.661, c2=31.037 g=-22.240\n",
            ">719, c1=-44.867, c2=28.714 g=-25.529\n",
            ">720, c1=-45.641, c2=33.835 g=-28.425\n",
            ">721, c1=-44.575, c2=36.372 g=-21.883\n",
            ">722, c1=-46.413, c2=32.412 g=-19.646\n",
            ">723, c1=-44.595, c2=34.511 g=-17.646\n",
            ">724, c1=-46.721, c2=30.643 g=-19.618\n",
            ">725, c1=-46.288, c2=31.369 g=-16.126\n",
            ">726, c1=-45.270, c2=29.137 g=-20.981\n",
            ">727, c1=-44.156, c2=27.861 g=-17.027\n",
            ">728, c1=-44.199, c2=29.772 g=-18.913\n",
            ">729, c1=-45.503, c2=30.262 g=-20.409\n",
            ">730, c1=-47.845, c2=33.682 g=-19.106\n",
            ">731, c1=-45.862, c2=31.944 g=-23.923\n",
            ">732, c1=-48.699, c2=32.488 g=-20.065\n",
            ">733, c1=-44.337, c2=31.893 g=-18.907\n",
            ">734, c1=-47.292, c2=29.981 g=-19.871\n",
            ">735, c1=-45.793, c2=32.813 g=-15.635\n",
            ">736, c1=-41.583, c2=29.450 g=-19.084\n",
            ">737, c1=-47.408, c2=30.255 g=-22.507\n",
            ">738, c1=-46.090, c2=31.793 g=-19.932\n",
            ">739, c1=-43.688, c2=30.831 g=-19.530\n",
            ">740, c1=-44.508, c2=32.435 g=-18.110\n",
            ">741, c1=-46.038, c2=30.926 g=-14.995\n",
            ">742, c1=-43.286, c2=30.312 g=-12.847\n",
            ">743, c1=-44.212, c2=29.028 g=-18.583\n",
            ">744, c1=-45.059, c2=28.705 g=-14.850\n",
            ">745, c1=-43.505, c2=31.166 g=-18.209\n",
            ">746, c1=-42.762, c2=26.365 g=-17.018\n",
            ">747, c1=-45.814, c2=23.901 g=-18.279\n",
            ">748, c1=-44.538, c2=26.900 g=-17.696\n",
            ">749, c1=-40.515, c2=30.586 g=-13.945\n",
            ">750, c1=-43.528, c2=29.232 g=-17.090\n",
            ">751, c1=-44.220, c2=26.345 g=-20.252\n",
            ">752, c1=-44.512, c2=29.091 g=-17.839\n",
            ">753, c1=-41.781, c2=27.524 g=-18.515\n",
            ">754, c1=-42.375, c2=30.504 g=-21.184\n",
            ">755, c1=-41.482, c2=30.558 g=-6.813\n",
            ">756, c1=-41.509, c2=27.116 g=-16.970\n",
            ">757, c1=-44.383, c2=27.558 g=-15.150\n",
            ">758, c1=-41.343, c2=26.540 g=-13.382\n",
            ">759, c1=-42.549, c2=25.982 g=-14.516\n",
            ">760, c1=-42.823, c2=27.273 g=-15.712\n",
            ">761, c1=-42.970, c2=27.365 g=-16.370\n",
            ">762, c1=-41.698, c2=26.968 g=-12.776\n",
            ">763, c1=-40.814, c2=26.207 g=-14.145\n",
            ">764, c1=-42.238, c2=24.111 g=-12.507\n",
            ">765, c1=-42.607, c2=30.019 g=-17.339\n",
            ">766, c1=-40.734, c2=30.304 g=-14.943\n",
            ">767, c1=-43.576, c2=29.455 g=-15.308\n",
            ">768, c1=-43.591, c2=28.360 g=-16.126\n",
            ">769, c1=-40.569, c2=27.588 g=-13.301\n",
            ">770, c1=-43.324, c2=28.645 g=-14.159\n",
            ">771, c1=-43.574, c2=23.706 g=-10.616\n",
            ">772, c1=-40.796, c2=22.292 g=-14.493\n",
            ">773, c1=-41.133, c2=22.957 g=-11.647\n",
            ">774, c1=-40.241, c2=25.206 g=-15.202\n",
            ">775, c1=-41.243, c2=25.384 g=-16.276\n",
            ">776, c1=-39.613, c2=26.298 g=-14.663\n",
            ">Saved: generated_plot_0776.png and model_0776.h5\n",
            ">777, c1=-38.774, c2=24.741 g=-13.404\n",
            ">778, c1=-41.301, c2=25.696 g=-15.341\n",
            ">779, c1=-41.925, c2=24.647 g=-12.569\n",
            ">780, c1=-40.371, c2=26.151 g=-8.230\n",
            ">781, c1=-38.832, c2=27.049 g=-16.561\n",
            ">782, c1=-39.145, c2=24.662 g=-11.727\n",
            ">783, c1=-41.890, c2=24.823 g=-12.058\n",
            ">784, c1=-40.808, c2=25.206 g=-10.356\n",
            ">785, c1=-41.293, c2=25.111 g=-14.846\n",
            ">786, c1=-41.212, c2=26.032 g=-12.656\n",
            ">787, c1=-40.174, c2=25.306 g=-12.091\n",
            ">788, c1=-39.425, c2=24.960 g=-12.459\n",
            ">789, c1=-43.242, c2=27.657 g=-18.609\n",
            ">790, c1=-41.341, c2=26.978 g=-13.637\n",
            ">791, c1=-41.233, c2=25.387 g=-15.096\n",
            ">792, c1=-42.229, c2=28.606 g=-16.675\n",
            ">793, c1=-41.664, c2=27.771 g=-19.883\n",
            ">794, c1=-40.891, c2=27.402 g=-9.310\n",
            ">795, c1=-41.055, c2=26.267 g=-15.734\n",
            ">796, c1=-37.801, c2=24.119 g=-9.954\n",
            ">797, c1=-39.805, c2=23.626 g=-13.520\n",
            ">798, c1=-39.694, c2=24.800 g=-12.268\n",
            ">799, c1=-38.996, c2=25.064 g=-15.706\n",
            ">800, c1=-41.611, c2=26.790 g=-14.855\n",
            ">801, c1=-40.313, c2=28.367 g=-13.817\n",
            ">802, c1=-40.515, c2=27.104 g=-13.316\n",
            ">803, c1=-40.726, c2=26.949 g=-18.698\n",
            ">804, c1=-41.127, c2=25.390 g=-17.672\n",
            ">805, c1=-39.501, c2=24.269 g=-11.646\n",
            ">806, c1=-40.334, c2=25.278 g=-9.674\n",
            ">807, c1=-40.205, c2=26.831 g=-9.449\n",
            ">808, c1=-41.445, c2=22.916 g=-15.829\n",
            ">809, c1=-40.033, c2=23.734 g=-8.406\n",
            ">810, c1=-43.237, c2=23.884 g=-13.483\n",
            ">811, c1=-39.245, c2=24.236 g=-13.756\n",
            ">812, c1=-39.875, c2=22.983 g=-11.927\n",
            ">813, c1=-39.405, c2=27.873 g=-11.572\n",
            ">814, c1=-42.065, c2=26.990 g=-18.427\n",
            ">815, c1=-38.435, c2=25.256 g=-10.961\n",
            ">816, c1=-39.564, c2=27.765 g=-14.973\n",
            ">817, c1=-41.032, c2=28.257 g=-16.252\n",
            ">818, c1=-38.461, c2=28.284 g=-14.339\n",
            ">819, c1=-40.526, c2=25.841 g=-16.466\n",
            ">820, c1=-40.588, c2=26.581 g=-17.293\n",
            ">821, c1=-37.640, c2=24.191 g=-11.816\n",
            ">822, c1=-40.513, c2=26.561 g=-14.092\n",
            ">823, c1=-41.089, c2=25.290 g=-13.657\n",
            ">824, c1=-41.139, c2=23.249 g=-11.172\n",
            ">825, c1=-39.146, c2=23.493 g=-10.980\n",
            ">826, c1=-39.336, c2=25.778 g=-10.274\n",
            ">827, c1=-38.893, c2=24.895 g=-19.015\n",
            ">828, c1=-38.429, c2=20.971 g=-9.040\n",
            ">829, c1=-40.504, c2=28.047 g=-11.739\n",
            ">830, c1=-40.162, c2=24.187 g=-13.597\n",
            ">831, c1=-37.363, c2=23.297 g=-12.624\n",
            ">832, c1=-37.380, c2=22.757 g=-6.873\n",
            ">833, c1=-40.369, c2=27.870 g=-13.797\n",
            ">834, c1=-40.806, c2=26.624 g=-12.224\n",
            ">835, c1=-40.059, c2=24.833 g=-16.837\n",
            ">836, c1=-40.067, c2=22.487 g=-6.770\n",
            ">837, c1=-38.971, c2=22.636 g=-14.124\n",
            ">838, c1=-38.550, c2=27.226 g=-11.501\n",
            ">839, c1=-39.828, c2=23.275 g=-7.294\n",
            ">840, c1=-38.732, c2=22.501 g=-10.361\n",
            ">841, c1=-40.856, c2=23.784 g=-8.868\n",
            ">842, c1=-40.054, c2=24.447 g=-13.979\n",
            ">843, c1=-40.395, c2=22.945 g=-11.206\n",
            ">844, c1=-39.776, c2=23.286 g=-15.702\n",
            ">845, c1=-38.108, c2=23.924 g=-8.862\n",
            ">846, c1=-37.768, c2=23.034 g=-13.882\n",
            ">847, c1=-37.597, c2=25.202 g=-9.865\n",
            ">848, c1=-39.045, c2=23.352 g=-13.136\n",
            ">849, c1=-38.267, c2=24.360 g=-15.178\n",
            ">850, c1=-38.968, c2=23.719 g=-7.849\n",
            ">851, c1=-39.041, c2=22.370 g=-10.036\n",
            ">852, c1=-39.788, c2=25.610 g=-11.488\n",
            ">853, c1=-38.927, c2=22.251 g=-12.643\n",
            ">854, c1=-39.112, c2=26.207 g=-16.904\n",
            ">855, c1=-40.796, c2=23.178 g=-12.839\n",
            ">856, c1=-39.446, c2=26.285 g=-6.429\n",
            ">857, c1=-38.309, c2=22.268 g=-10.141\n",
            ">858, c1=-37.512, c2=19.717 g=-7.373\n",
            ">859, c1=-39.381, c2=22.766 g=-12.321\n",
            ">860, c1=-38.709, c2=21.285 g=-8.091\n",
            ">861, c1=-37.861, c2=22.889 g=-8.594\n",
            ">862, c1=-39.420, c2=24.399 g=-8.568\n",
            ">863, c1=-38.805, c2=21.426 g=-13.040\n",
            ">864, c1=-41.082, c2=20.676 g=-12.709\n",
            ">865, c1=-38.542, c2=24.454 g=-9.054\n",
            ">866, c1=-36.702, c2=21.081 g=-9.178\n",
            ">867, c1=-36.631, c2=24.625 g=-12.995\n",
            ">868, c1=-40.213, c2=26.578 g=-15.933\n",
            ">869, c1=-39.066, c2=24.221 g=-7.234\n",
            ">870, c1=-38.588, c2=23.824 g=-11.390\n",
            ">871, c1=-40.817, c2=24.489 g=-10.560\n",
            ">872, c1=-36.944, c2=25.930 g=-12.910\n",
            ">873, c1=-38.198, c2=23.984 g=-4.645\n",
            ">Saved: generated_plot_0873.png and model_0873.h5\n",
            ">874, c1=-40.267, c2=23.518 g=-12.450\n",
            ">875, c1=-40.762, c2=22.944 g=-10.846\n",
            ">876, c1=-38.790, c2=23.535 g=-11.856\n",
            ">877, c1=-38.208, c2=21.122 g=-13.017\n",
            ">878, c1=-41.134, c2=25.473 g=-13.903\n",
            ">879, c1=-39.175, c2=24.542 g=-11.211\n",
            ">880, c1=-36.796, c2=22.564 g=-10.108\n",
            ">881, c1=-38.509, c2=22.400 g=-10.453\n",
            ">882, c1=-37.395, c2=20.095 g=-10.026\n",
            ">883, c1=-39.857, c2=20.845 g=-6.368\n",
            ">884, c1=-37.201, c2=20.395 g=-11.635\n",
            ">885, c1=-39.158, c2=21.707 g=-8.231\n",
            ">886, c1=-37.291, c2=23.794 g=-7.337\n",
            ">887, c1=-39.110, c2=23.612 g=-11.656\n",
            ">888, c1=-38.162, c2=22.126 g=-12.600\n",
            ">889, c1=-37.179, c2=22.048 g=-11.221\n",
            ">890, c1=-38.665, c2=25.265 g=-13.144\n",
            ">891, c1=-39.367, c2=22.877 g=-10.093\n",
            ">892, c1=-39.226, c2=22.602 g=-9.984\n",
            ">893, c1=-37.017, c2=18.413 g=-8.233\n",
            ">894, c1=-39.691, c2=24.803 g=-14.931\n",
            ">895, c1=-40.739, c2=23.978 g=-11.772\n",
            ">896, c1=-35.896, c2=23.415 g=-3.016\n",
            ">897, c1=-38.668, c2=23.693 g=-11.185\n",
            ">898, c1=-39.755, c2=21.312 g=-13.409\n",
            ">899, c1=-37.393, c2=21.141 g=-13.034\n",
            ">900, c1=-38.199, c2=23.246 g=-7.422\n",
            ">901, c1=-36.674, c2=20.331 g=-10.898\n",
            ">902, c1=-37.147, c2=18.628 g=-13.570\n",
            ">903, c1=-39.371, c2=22.556 g=-6.936\n",
            ">904, c1=-39.567, c2=23.531 g=-12.892\n",
            ">905, c1=-37.103, c2=22.412 g=-9.532\n",
            ">906, c1=-38.807, c2=21.855 g=-10.890\n",
            ">907, c1=-41.561, c2=21.679 g=-10.030\n",
            ">908, c1=-39.919, c2=25.068 g=-14.486\n",
            ">909, c1=-37.186, c2=21.362 g=-12.557\n",
            ">910, c1=-38.869, c2=21.439 g=-10.392\n",
            ">911, c1=-38.077, c2=22.584 g=-7.658\n",
            ">912, c1=-38.535, c2=23.985 g=-8.063\n",
            ">913, c1=-38.079, c2=21.819 g=-11.424\n",
            ">914, c1=-38.699, c2=21.505 g=-9.473\n",
            ">915, c1=-37.589, c2=19.895 g=-10.052\n",
            ">916, c1=-36.739, c2=20.886 g=-13.417\n",
            ">917, c1=-37.550, c2=20.851 g=-13.247\n",
            ">918, c1=-36.661, c2=19.472 g=-6.121\n",
            ">919, c1=-37.580, c2=22.846 g=-6.044\n",
            ">920, c1=-37.760, c2=23.926 g=-11.421\n",
            ">921, c1=-37.193, c2=22.291 g=-7.081\n",
            ">922, c1=-37.840, c2=22.191 g=-8.316\n",
            ">923, c1=-37.263, c2=22.763 g=-9.928\n",
            ">924, c1=-36.913, c2=22.438 g=-9.247\n",
            ">925, c1=-38.700, c2=22.226 g=-11.618\n",
            ">926, c1=-38.914, c2=22.965 g=-14.691\n",
            ">927, c1=-39.160, c2=23.139 g=-9.918\n",
            ">928, c1=-37.876, c2=20.732 g=-10.842\n",
            ">929, c1=-38.675, c2=20.607 g=-10.848\n",
            ">930, c1=-38.610, c2=24.576 g=-10.560\n",
            ">931, c1=-39.346, c2=18.025 g=-9.910\n",
            ">932, c1=-40.279, c2=20.978 g=-11.930\n",
            ">933, c1=-37.500, c2=21.822 g=-8.911\n",
            ">934, c1=-38.385, c2=16.307 g=-11.610\n",
            ">935, c1=-36.635, c2=20.104 g=-9.982\n",
            ">936, c1=-35.920, c2=24.081 g=-6.566\n",
            ">937, c1=-37.101, c2=23.705 g=-9.453\n",
            ">938, c1=-37.070, c2=21.635 g=-9.591\n",
            ">939, c1=-36.296, c2=18.774 g=-11.715\n",
            ">940, c1=-38.880, c2=23.869 g=-11.694\n",
            ">941, c1=-38.500, c2=24.147 g=-8.127\n",
            ">942, c1=-38.920, c2=25.040 g=-14.169\n",
            ">943, c1=-40.244, c2=25.065 g=-14.190\n",
            ">944, c1=-40.790, c2=25.395 g=-14.174\n",
            ">945, c1=-39.138, c2=20.217 g=-6.819\n",
            ">946, c1=-41.261, c2=26.225 g=-14.938\n",
            ">947, c1=-39.923, c2=25.936 g=-10.123\n",
            ">948, c1=-39.193, c2=23.363 g=-9.360\n",
            ">949, c1=-40.217, c2=23.308 g=-9.905\n",
            ">950, c1=-39.028, c2=23.138 g=-6.399\n",
            ">951, c1=-42.694, c2=22.826 g=-13.129\n",
            ">952, c1=-38.777, c2=25.550 g=-10.267\n",
            ">953, c1=-38.568, c2=24.206 g=-16.550\n",
            ">954, c1=-42.104, c2=25.373 g=-14.045\n",
            ">955, c1=-38.975, c2=24.819 g=-8.855\n",
            ">956, c1=-40.116, c2=25.661 g=-13.345\n",
            ">957, c1=-41.890, c2=24.591 g=-10.536\n",
            ">958, c1=-41.662, c2=25.849 g=-9.311\n",
            ">959, c1=-40.257, c2=19.292 g=-5.880\n",
            ">960, c1=-39.762, c2=22.757 g=-10.196\n",
            ">961, c1=-40.753, c2=22.408 g=-8.654\n",
            ">962, c1=-40.006, c2=22.270 g=-12.346\n",
            ">963, c1=-42.174, c2=24.943 g=-11.595\n",
            ">964, c1=-39.082, c2=24.911 g=-6.465\n",
            ">965, c1=-40.357, c2=23.909 g=-14.093\n",
            ">966, c1=-40.431, c2=19.188 g=-9.132\n",
            ">967, c1=-40.750, c2=22.872 g=-8.590\n",
            ">968, c1=-41.445, c2=23.595 g=-7.117\n",
            ">969, c1=-38.271, c2=24.186 g=-11.770\n",
            ">970, c1=-40.414, c2=24.889 g=-12.303\n",
            ">Saved: generated_plot_0970.png and model_0970.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3y_MZvje0eM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"generated_plot_0970.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}