{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbours:\n",
      "K value: 11\n",
      "[1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Confusion Matrix:\n",
      "[[ 0  3]\n",
      " [ 0 18]]\n",
      "Accuracy: 85.71428571428571%\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import operator \n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df=pd.read_csv(\"Andhra_dataset2.csv\")\n",
    "#len(df)\n",
    "df.isnull().sum()\n",
    "df.drop(['education'], axis = 1) \n",
    "\n",
    "#print(df)\n",
    "def mean_fill(df):\n",
    "    for col in df.columns: \n",
    "        mean = df[col].mean() #imputing item_weight with mean\n",
    "        df[col].fillna(mean, inplace =True)\n",
    "   # print(df)\n",
    "    \n",
    "#fill with mode\n",
    "def mode_fill(df):\n",
    "    for col in df.columns: \n",
    "        mode = df[col].mode() #imputing outlet size with mode\n",
    "        df[col].fillna(mode[0], inplace =True)\n",
    "   # print(df)\n",
    "    \n",
    "mode_fill(df)\n",
    "#mean_fill(df)\n",
    "df.drop(['education'], axis=1, inplace=True)\n",
    "df = pd.get_dummies(df)\n",
    "#print(df)\n",
    "df=df.values.tolist()\n",
    "#print(df)\n",
    "def minmax(df):\n",
    "    minmax = list()\n",
    "    stats = [[min(column), max(column)] for column in zip(*df)]\n",
    "    return stats\n",
    "mm=minmax(df)\n",
    "\n",
    "def normalize(df, minmax):\n",
    "    for row in df:\n",
    "        for i in range(len(row)-1):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "normalize(df,mm)\n",
    "#print(df)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df[i][8]=int((df[i][8]))\n",
    "\n",
    "def str_column_to_int(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "    lookup = dict()\n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    return lookup\n",
    "str_column_to_int(df, len(df[0])-1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train , test = train_test_split(df, test_size = 0.20)\n",
    "\n",
    "def Euclideandist(x,y, length):\n",
    "    d = 0.0\n",
    "    for i in range(length):\n",
    "        d += pow(float(x[i])- float(y[i]),2)\n",
    "    return math.sqrt(d)\n",
    "\n",
    "\n",
    "#Getting the K neighbours having the closest\n",
    "#Euclidean distance to the test instance\n",
    "def k_nearest(train, test, k):\n",
    "    dis = []\n",
    "    l = len(test)-1\n",
    "    for x in range(len(train)):\n",
    "        dist = Euclideandist(test, train[x], l)\n",
    "        dis.append((train[x], dist))\n",
    "    dis.sort(key=operator.itemgetter(1))\n",
    "    knn = []\n",
    "    for x in range(k):\n",
    "        knn.append(dis[x][0])\n",
    "    return knn\n",
    "\n",
    "#After sorting the neighbours based on their respective classes,\n",
    "#max voting to give the final class of the test instance\n",
    "def Results(knn):\n",
    "    abc={}\n",
    "    for x in range(len(knn)):\n",
    "        result=knn[x][-1]\n",
    "        if result in abc:\n",
    "            abc[result]+=1\n",
    "        else:\n",
    "            abc[result]=1\n",
    "    sortedval=sorted(abc.items(),key=operator.itemgetter(1),reverse=True)\n",
    "    return sortedval[0][0]\n",
    "\n",
    "def Accuracy(test, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(test)):\n",
    "        if test[x][-1] == predictions[x]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(test))) * 100.0\n",
    "\n",
    "predictions=[]\n",
    "k=11\n",
    "fp=0\n",
    "fn=0\n",
    "tp=0\n",
    "tn=0\n",
    "predicted_out1=[]\n",
    "actual_out1=[]\n",
    "#print(len(df[1]))\n",
    "for x in range(len(test)):\n",
    "    neigh = k_nearest(train, test[x], k)\n",
    "    result = Results(neigh)\n",
    "    predictions.append(result)\n",
    "    predicted_out1.append(result)\n",
    "    actual_out1.append(test[x][-1])\n",
    "    #print('> predicted='+ (result) + ', actual=' + repr(test[x][-1]))\n",
    "print(\"K-Nearest Neighbours:\")\n",
    "print(\"K value:\",k)\n",
    "print(actual_out1)\n",
    "print(predicted_out1)\n",
    "x=[]\n",
    "'''\n",
    "for i in df:\n",
    "    l=[]\n",
    "    l.append(i[-1])\n",
    "    x.append(l)\n",
    "print(x)\n",
    "'''\n",
    "cm=confusion_matrix(actual_out1,predicted_out1)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "accuracy = Accuracy(test, predictions)\n",
    "print('Accuracy: ' + repr(accuracy) + '%')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df[i][8]=int((df[i][8]))\n",
    "\n",
    "def str_column_to_int(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "    lookup = dict()\n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    return lookup\n",
    "str_column_to_int(df, len(df[0])-1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train , test = train_test_split(df, test_size = 0.20)\n",
    "\n",
    "\n",
    "class Neural_Network(object):\n",
    "    def __init__(self, W1=None, W2= None):\n",
    "        #define Parameters\n",
    "        self.inputLayerSize = 8\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayerSize = 10\n",
    "        \n",
    "        #weights\n",
    "        if(W1 is None and W2 is None):\n",
    "            self.W1 = np.random.randn(self.inputLayerSize, self.hiddenLayerSize)\n",
    "            self.W2 = np.random.randn(self.hiddenLayerSize, self.outputLayerSize)\n",
    "        else:\n",
    "            self.W1=W1\n",
    "            self.W2=W2\n",
    "            \n",
    "    def sigmoid(self, z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def relu(self, Z):\n",
    "        return np.maximum(0,Z)\n",
    "\n",
    "    def der_relu(self, dA, Z):\n",
    "        dZ = np.array(dA, copy = True)\n",
    "        dZ[Z <= 0] = 0;\n",
    "        return dZ;\n",
    "    \n",
    "    def forward(self, X):\n",
    "        #progate through the network\n",
    "        self.z2 = np.dot(X,self.W1)\n",
    "        self.a2 = self.tanh(self.z2)\n",
    "        self.z3 = np.dot(self.a2,self.W2)\n",
    "        y_hat = self.sigmoid(self.z3)\n",
    "        return y_hat\n",
    "    \n",
    "    def costFunction(self, X, y):\n",
    "        self.y_hat=self.forward(X)\n",
    "        J= 0.5*sum((y-self.y_hat)**2)\n",
    "        return J\n",
    "    \n",
    "    def der_sigmoid(self, z):\n",
    "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "    \n",
    "    def der_costFunction(self, X, y):\n",
    "        self.y_hat = self.forward(X)\n",
    "        delta3 = np.multiply(-(y-self.y_hat),self.der_tanh(self.z3))\n",
    "        djdW2 = np.dot(self.a2.T,delta3)\n",
    "        \n",
    "        delta2 = np.dot(delta3, self.W2.T)*self.der_sigmoid(self.z2)\n",
    "        djdW1 = np.dot(X.T, delta2)\n",
    "        return djdW1, djdW2\n",
    "    \n",
    "    def tanh(self,X):\n",
    "        return np.tanh(X)\n",
    "    \n",
    "    def der_tanh(self,X):\n",
    "        return 1.0- np.tanh(X)**2\n",
    "#print(df)\n",
    "X=[]\n",
    "for i in train:\n",
    "    X.append(i[:-1])\n",
    "#print(len(X[0]))\n",
    "#print(X)\n",
    "y=[]\n",
    "for i in train:\n",
    "    y.append(i[-1])\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X)\n",
    "y=np.asarray(y)\n",
    "y=np.reshape(y,(len(y),1))\n",
    "#print(X.shape)\n",
    "#print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Net:\n",
      "[1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Confusion Matrix:\n",
      "[[ 0  3]\n",
      " [ 0 18]]\n",
      "Accuracy= 90.47619047619048\n"
     ]
    }
   ],
   "source": [
    "NN=Neural_Network()\n",
    "max_iter = 100000\n",
    "iter = 0\n",
    "learningRate = 0.02\n",
    "while(iter<max_iter):\n",
    "    djdW1, djdW2 = NN.der_costFunction(X,y)\n",
    "    NN.W1 = NN.W1 -learningRate*djdW1\n",
    "    NN.W2 = NN.W2 -learningRate*djdW2\n",
    "    #print(NN.W1,NN.W2)\n",
    "    if(iter%10000 == 0):\n",
    "        #print(NN.costFunction(X,y))\n",
    "        NN.costFunction(X,y)\n",
    "    iter=iter+1\n",
    "#print(y)\n",
    "#print(NN.forward(X))\n",
    "def sse(y,yhat):\n",
    "    #print(yhat)\n",
    "    #print(y)\n",
    "    l=[]\n",
    "    for i,j in zip(y,yhat):\n",
    "        l.append(pow((i-j),2))\n",
    "    x=sum(l)\n",
    "    x=x/10000\n",
    "    return x\n",
    "\n",
    "    #return (sum(map(lambda a,b : pow(a[0]-b[0],2),zip(y,yhat)))/10000)\n",
    "\n",
    "def sigm(z):\n",
    "    return 1/(1 + np.exp(-z)) \n",
    "\n",
    "#print(sse(y,NN.forward(X)))\n",
    "bestW1=[]\n",
    "bestW2=[]\n",
    "min=10000\n",
    "for i in range(1,100):\n",
    "    NN=Neural_Network()\n",
    "    if min>sse(y,NN.forward(X)):\n",
    "        min=sse(y,NN.forward(X))\n",
    "        bestW1=NN.W1\n",
    "        bestW2=NN.W2\n",
    "        \n",
    "#Best Weights\n",
    "#print(bestW1)\n",
    "#print(bestW2)\n",
    "\n",
    "X=[]\n",
    "for i in test:\n",
    "    X.append(i[:-1])\n",
    "#print(len(X[0]))\n",
    "#print(X)\n",
    "y=[]\n",
    "for i in test:\n",
    "    y.append(i[-1])\n",
    "X=np.asarray(X)\n",
    "y=np.asarray(y)\n",
    "y=np.reshape(y,(len(y),1))\n",
    "#print(X.shape)\n",
    "#print(y.shape)\n",
    "\n",
    "Best_NN=Neural_Network(bestW1,bestW2)\n",
    "y_hat=Best_NN.forward(X)\n",
    "def Accuracy(test, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(test)):\n",
    "        if test[i][0] == round(predictions[i][0]):\n",
    "            correct += 1\n",
    "    return (correct/float(len(test))) * 100.0\n",
    "#print(y_hat)\n",
    "predicted_out2=[]\n",
    "for i in y_hat:\n",
    "    for j in i:\n",
    "        predicted_out2.append(int(round(j)))\n",
    "        #print(j)\n",
    "#print(predicted_out1)\n",
    "#print(predicted_out2)\n",
    "print(\"Neural Net:\")\n",
    "print(actual_out1)\n",
    "print(predicted_out2)\n",
    "cm=confusion_matrix(actual_out1,predicted_out2)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"Accuracy=\",Accuracy(y,y_hat))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "#final_output=[]\n",
    "#for i in range(len(a)):\n",
    "#    final_output[i]=(predicted_out1[i]+predicted_out2[i]+predicted_out3[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
