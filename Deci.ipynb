{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.33333333333333"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "eps = np.finfo(float).eps\n",
    "from numpy import log2 as log\n",
    "df = pd.read_csv(\"Cleaned_Andhra_dataset.csv\")\n",
    "sample_size = 30\n",
    "test_indices = random.sample(population=(df.index.tolist()),k=sample_size)\n",
    "train_data = df.drop(test_indices)\n",
    "# the loc method  location of test_indices and returns the data in that index\n",
    "test_data = df.loc[test_indices]\n",
    "test_data_target_value =  df.loc[test_indices]\n",
    "test_data = test_data.drop(['reslt'], axis = 1)\n",
    "# print(test_data_target_value)\n",
    "# print(test_data)\n",
    "# df = train_data\n",
    "\n",
    "# feature = ['age', 'weight1', 'history', 'HB', 'IFA', 'BP1', 'education', 'res', 'reslt']\n",
    "\n",
    "\n",
    "# In[346]:\n",
    "\n",
    "\n",
    "# this function finds the class entropy\n",
    "def find_entropy(df):\n",
    "   # print(df)\n",
    "#     takes the last element in the dataset that is the label(target value)\n",
    "    Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
    "    entropy = 0\n",
    "#     unique function retruns an array of unique elements ie.array([0, 1], dtype=int64)\n",
    "    values = df[Class].unique()\n",
    "    for value in values:\n",
    "        fraction = df[Class].value_counts()[value]/len(df[Class])\n",
    "        entropy += -fraction*np.log2(fraction)\n",
    "#         entrophy value returned is 0.8228368841492257 after two iterations\n",
    "   # print(entropy)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "# In[348]:\n",
    "\n",
    "\n",
    "def find_entropy_attribute(df,attribute):\n",
    "    Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
    "    target_variables = df[Class].unique()  #This gives all 'Yes' and 'No'\n",
    "   # print(attribute)\n",
    "    variables = df[attribute].unique()    #This gives different features in that attribute (like 'Hot','Cold' in Temperature)\n",
    "    entropy2 = 0\n",
    "    for variable in variables:\n",
    "        entropy = 0\n",
    "        for target_variable in target_variables:\n",
    "            num = len(df[attribute][df[attribute]==variable][df[Class] ==target_variable])\n",
    "            den = len(df[attribute][df[attribute]==variable])\n",
    "            fraction = num/(den+eps)\n",
    "            entropy += -fraction*log(fraction+eps)\n",
    "        fraction2 = den/len(df)\n",
    "    entropy2 += -fraction2*entropy\n",
    "    return abs(entropy2)\n",
    "\n",
    "\n",
    "# In[349]:\n",
    "\n",
    "\n",
    "def find_winner(df):\n",
    "    Entropy_att = []\n",
    "    IG = []\n",
    "    for key in df.keys()[:-1]:\n",
    "        #print(key)\n",
    "#         Entropy_att.append(find_entropy_attribute(df,key))\n",
    "        IG.append(find_entropy(df)-find_entropy_attribute(df,key))\n",
    "    return df.keys()[:-1][np.argmax(IG)]\n",
    "\n",
    "\n",
    "# In[350]:\n",
    "\n",
    "\n",
    "def get_subtable(df, node,value):\n",
    "    return df[df[node] == value].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# In[351]:\n",
    "\n",
    "\n",
    "def buildTree(df,tree=None): \n",
    "    Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
    "#     print(Class)\n",
    "    #Here we build our decision tree\n",
    "\n",
    "    #Get attribute with maximum information gain\n",
    "    node = find_winner(df)\n",
    "    \n",
    "    #Get distinct value of that attribute e.g Salary is node and Low,Med and High are values\n",
    "    attValue = np.unique(df[node])\n",
    "    \n",
    "    #Create an empty dictionary to create tree    \n",
    "    if tree is None:                    \n",
    "        tree={}\n",
    "        tree[node] = {}\n",
    "    \n",
    "   #We make loop to construct a tree by calling this function recursively. \n",
    "    #In this we check if the subset is pure and stops if it is pure. \n",
    "\n",
    "    for value in attValue:\n",
    "        \n",
    "        subtable = get_subtable(df,node,value)\n",
    "        clValue,counts = np.unique(subtable['reslt'],return_counts=True)                        \n",
    "        \n",
    "        if len(counts)==1:#Checking purity of subset\n",
    "            tree[node][value] = clValue[0]                                                    \n",
    "        else:        \n",
    "            tree[node][value] = buildTree(subtable) #Calling the function recursively \n",
    "                   \n",
    "    return tree\n",
    "  \n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "tree = buildTree(df)\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "#import pprint\n",
    "#pprint.pprint(tree)\n",
    "\n",
    "\n",
    "# In[365]:\n",
    "\n",
    "\n",
    "def predict(inst,tree):\n",
    "    #This function is used to predict for any input variable \n",
    "    \n",
    "    #Recursively we go through the tree that we built earlier\n",
    "\n",
    "    for nodes in tree.keys():        \n",
    "        \n",
    "        value = inst[nodes]\n",
    "        tree = tree[nodes][value]\n",
    "        prediction = 0\n",
    "            \n",
    "        if type(tree) is dict:\n",
    "            prediction = predict(inst, tree)\n",
    "        else:\n",
    "            prediction = tree\n",
    "            break;                            \n",
    "        \n",
    "    return prediction\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "prediction_list = []\n",
    "for i in range(len(test_data)):\n",
    "#     takes row by row the test data!\n",
    "#    print(test_data.iloc[i])\n",
    "    prediction_list.append(predict(test_data.iloc[i],df))\n",
    "#for j in prediction_list:\n",
    "   # print(j)\n",
    "    \n",
    "\n",
    "\n",
    "# In[381]:\n",
    "\n",
    "\n",
    "# Calculating Accuracy\n",
    "total_ones = 0\n",
    "for x in test_data_target_value['reslt']:\n",
    "    if x == 1:\n",
    "        total_ones += 1 \n",
    "total_ones\n",
    "sample_size\n",
    "\n",
    "accuracy = total_ones/sample_size\n",
    "accuracy *= 100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
